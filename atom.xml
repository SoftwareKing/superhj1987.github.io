<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Blog - srHang | 飒然]]></title>
  <link href="http://superhj1987.github.io/atom.xml" rel="self"/>
  <link href="http://superhj1987.github.io/"/>
  <updated>2015-12-21T18:59:23+08:00</updated>
  <id>http://superhj1987.github.io/</id>
  <author>
    <name><![CDATA[飒然Hang]]></name>
    <email><![CDATA[superhj1987@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[前端这些年]]></title>
    <link href="http://superhj1987.github.io/blog/2015/12/21/front-these-years/"/>
    <updated>2015-12-21T18:53:48+08:00</updated>
    <id>http://superhj1987.github.io/blog/2015/12/21/front-these-years</id>
    <content type="html"><![CDATA[<h2>前言</h2>

<p>本人一直从事的是服务端开发工作，写前端貌似有点跑题，不过自己初中也就是2000年左右的时候，引领我进入计算机大门的也的确是前端，后来也做过不少的前端工作。于是，就想着倚老卖老，从自己的角度写点前端的东西。但毕竟不是专业所长，有所纰漏在所难免。</p>

<!--more-->


<h2>正文</h2>

<p>还记得2000年左右的时候，那时的四大门户：新浪、搜狐、网易、中华网（是的，那时候还没腾讯啥事）。我第一次访问这些网站的时候就被震撼到了，一直很奇怪这是怎么写出来的。恰巧，初中开了一个计算机课，老师当时在给我们讲微软的office系列，里面有个软件叫frontpage，拖着拖着就能出来一个网页。幼稚的我恍然大悟:原来用这东西就能拖出来个新浪网啊。学会了拖网页，学校里家庭条件比较好、接触电脑比较早的同学还把自己的网页传到了网上的免费空间（网易的yeah.net免费空间），然后就俨然成了公众人物。毕竟，那个时候在我们那个小城市，家里有电脑的少，能上网的更少，能有自己的网站还能通过网络访问的则少之又少了。当然，开始大家拖出来的网页都是静态的页面（这里的静态指的是静止不动的。。。。），然后有些人发现，貌似加上一段代码，网页上就能有各种类似动画的效果。比如: 标题动态改变、鼠标后跟着一串文字、状态栏滚动字幕等等。frontpage已经不能满足这些了，这时候一款更加NB的软件出现在了我的眼前-dreamweaver。这款软件我后来一直用到了大学本科毕业，当然，从开始的完全依赖dw来拖页面，到后来把它当成了一个写代码的IDE。说起来，那个时候没有那么多前端框架，写个页面就是html+css+js。页面布局用table，然后table里面嵌套table。现在想想也是醉了，还记得当时还有个原则是最外面的table宽度要设置为960px，100%，居中。这算是我接触前端的第一个时代吧，那个时候国内貌似也就ie浏览器，兼容性的问题根本不存在，技术体系相对来说也比较简单。</p>

<p>后来，业界兴起了div+css的概念。说白了就是内容和样式要分开，div组织内容，css控制样式。与此同时，js技术也飞速发展中。jquery横空出世，成为了前端开发必不可少的一个框架。大家也在乐此不彼的收集着各种各样的jquery插件。那时候觉得jquery真是太好用了，觉得会写jquery插件的人好nb。除此之外，extjs也成为了开发web必不可少的框架，不知多少管理系统都长的一模一样。。。最让我记忆尤甚的是浏览器的兼容性问题，fixfox、chrome、sarari这些浏览器一下全火了起来，然后兼容性问题就成为了令广大前端开发者最头疼的一件事情，尤其是万恶的ie6。当时在做一个英国的项目的时候，甲方的boss竟然细致到1px都要度量的份上，于是无数个夜晚，我就在那里调整像素，还是要调整在多个浏览器下的像素。。。。不知是幸运还是不幸的我也由此接触到了n多浏览器兼容的问题，记得最深的一个就是ie6的1px问题。对于这些兼容性问题，自己当时总结了一下，基本上使用css reset初始化所有样式，然后使用css hack针对不同浏览器做兼容，其他的针对具体问题具体分析。同样的，js里也存在兼容性的问题，一个典型的就是解析json字符串，有些浏览器里是默认有JSON的方法的，但有些浏览器却没有，只能使用eval来做。这方面，jquery则做了很好的兼容。其实，到了这个时候，整个前端已经乱了，尤其因为微软的自我，ie给大家带来了数不清的麻烦。针对这种情况，W3C适时的提出了新的标准，以求统一浏览器的渲染，也推出了es想统一一下前端脚本语言。不过，由于某些原因，ie6在很长一段时间都曾是国内前端开发者的梦靥，其他兼容性问题也一直成为了遗留问题。此外，随着前端样式和脚本变得越来越多、越来越复杂，页面的性能优化变得被人重视起来，雅虎前端优化35条原则、CSSSprites这些技术应运而生。这算是我经历的第二代前端。主要以div+css+jquery+esxjs为代表，以chrome、firefox的崛起为表象，开始考虑前端的性能优化问题。其实想想，由于浏览器的多种多样，这一代的前端开发者真的挺苦逼的。</p>

<p>经历了两代前端，其实自己后面就没怎么关注过这一块了，顶多就是留意一下业界的新闻，技术体系也基本就停留在了第二代上。最近由于某些原因，需要带一下公司的前端团队，就恶补了一下最新的前端知识，发现自己还真的有点out了。发展到现在，前端工程师真正成为了一个举足轻重的职位。以前由于只有pc端的前端开发，很多人瞧不上前端，觉得前端不过就是做个表单验证，做个小动画，没啥技术含量。而现在由于移动互联网的兴起，移动端前端开发成了越来越重要的一部分。与此同时，“富前端”的概念也提了出来，就是让web程序的体验和本地程序体验尽可能一致，于是对前端开发者的要求也就变得越来越高。html5也适时的席卷了整个生态圈，如果说几年前h5还只是个噱头，那么现在h5在移动页面以及移动app混合开发中则已经举足轻重了。nodejs的出现，让“全栈工程师”这个名词盛行起来，逐步做到了前后端分离的可行性。此外，前端的性能调优、前端工程化、前端模块化等也成为了前端领域越来越火的研究方向。具体的技术上，前端框架以AngularJs、requirejs为代表，客户端混合开发以phonegap为代表，工具以grunt、gulp为代表。具体的技术体系，推荐阅读这篇文章：<a href="http://blog.csdn.net/borishuai/article/details/8676573">http://blog.csdn.net/borishuai/article/details/8676573</a>。</p>

<h2>结语</h2>

<p>不管前端怎么变，其核心只有一个：视图呈现。所有的前端技术都是围绕着这一点进行的。只不过有的是从速度上，有的是从交互上，有的则从开发效率上。</p>

<p>在公司的招聘中，发现前端工程师是一个相对难招的职业，尤其是好的前端工程师。那么怎么定义一个好的前端工程师呢？除了研发职位普遍具有的一些共性之外，以下几点，我觉得是前端的特质：</p>

<ul>
<li>有一定的审美观: 很难想象一个没有审美观的人开发出来的页面是如何让人觉得赏心悦目的。</li>
<li>耐心、细致：有时候前端显示的问题，真的需要一点又一点慢慢地找出来的，尤其是css方面。</li>
<li>有一定的产品思维：很多情况下，前端算是和用户直接打交道的（和客户端类似，开发出的东西是直接面向用户的）。因此，具有一定的产品思维，才能让你更好的优化交互。</li>
</ul>


<p>最后，打个广告^_^。中华万年历，携2亿用户急需优秀的人才加入，七险一金、待遇优厚。各种职位虚位以待。<a href="http://www.lagou.com/gongsi/j1826.html">http://www.lagou.com/gongsi/j1826.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2015图书阅读清单]]></title>
    <link href="http://superhj1987.github.io/blog/2015/11/20/2015book-to-read/"/>
    <updated>2015-11-20T17:13:46+08:00</updated>
    <id>http://superhj1987.github.io/blog/2015/11/20/2015book-to-read</id>
    <content type="html"><![CDATA[<h2>技术</h2>

<h3>1. 精益数据分析</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/26278639/">http://book.douban.com/subject/26278639/</a></li>
<li>说明：一本讲述数据驱动创业的书籍，比如在你的产品中如何区分虚荣指标，如何抓住关键指标等。对于每一个商业模式都有其特定的关键指标和底线。而且对于一个公司的几个阶段（移情、黏性、病毒性、营收、规模化）指标也不是相同的。商业模式+阶段决定了你需要关注的指标。</li>
<li>进度：100%</li>
</ul>


<h3>2. 推荐系统实践</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/10769749/">http://book.douban.com/subject/10769749/</a></li>
<li>说明：讲述了构建一个推荐系统的基本知识、算法以及架构等。基本涵盖了能实现一个基本的推荐系统所需的相关技术等。看完这本书，基本能对推荐系统入门。</li>
<li>进度：100%</li>
<li>备注：此书上大学时曾经看过，但当时由于没有实战环境，所以没啥印象。此次阅读是基于项目需要，但其中部分牵扯到具体算法的部分没有细看</li>
</ul>


<!--more-->


<h3>3. 集体智慧编程</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/3288908/">http://book.douban.com/subject/3288908/</a></li>
<li>说明：讲述集体智慧的书籍，也是推荐系统相关的一本书</li>
<li>进度：0%</li>
</ul>


<h3>4. 快学scala</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/19971952/">http://book.douban.com/subject/19971952/</a></li>
<li>说明：学习scala的一本书，应该算是快速指引</li>
<li>进度：20%</li>
<li>备注：scala的学习曲线很陡，之前找到twitter的scala school，但是发现讲的有点不到位。鉴于此，找一本经典的书籍快速入门一下也不错。</li>
</ul>


<h2>非技术</h2>

<h3>1. 他来了，请闭眼</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/25912734/">http://book.douban.com/subject/25912734/</a></li>
<li>说明：犯罪心理学&hellip;</li>
<li>进度：100%</li>
<li>备注：看了电视剧，不过瘾，就直接找书来看了</li>
</ul>


<h3>2. 三体</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/2567698/">http://book.douban.com/subject/2567698/</a></li>
<li>说明：不用多说了，今年最火的小说。一共有三部</li>
<li>进度：30%</li>
<li>备注：看到了第二部《黑暗森林》，然后一直没时间看后面了..</li>
</ul>


<h3>3. 藏地密码</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/2201813/">http://book.douban.com/subject/2201813/</a></li>
<li>说明：一共有十部，讲述了一群人为了一个共同的秘密，在藏地进行探险的故事。</li>
<li>进度：100%</li>
<li>备注：继鬼吹灯、盗墓笔记之后，又一部让我恨不得一口气看完的小说</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[搭建自己的github]]></title>
    <link href="http://superhj1987.github.io/blog/2015/11/13/your-own-github/"/>
    <updated>2015-11-13T10:27:40+08:00</updated>
    <id>http://superhj1987.github.io/blog/2015/11/13/your-own-github</id>
    <content type="html"><![CDATA[<p>说起github，大家应该都是非常熟悉的。正是github的兴起，带来了开源的一个高潮，也诞生了无数优秀的开源项目。最最著名的Linux也在github上有了自己的repository。当然，github的核心技术git也是李纳斯的代表作。</p>

<p>记得几年前由于项目的需要，曾尝试自己去搭建一套git服务给项目组使用，折腾了好久，才总算搭建了一个基础的系统, 刚刚能用，权限控制都没有(<a href="http://srhang.iteye.com/blog/1339110">http://srhang.iteye.com/blog/1339110</a>)。但最终因为git的上手门槛有点高，还是选择了svn。后来随着github的兴起，git才如火如荼地在国内火了起来。许多大的互联网公司，也都开始把项目由svn转到git。但如果仅仅是搭建一个git服务，那么github这种网站提供的可视化ui带来的便捷却也不复存在了。对于一些小的有钱的团队，使用github的收费私人repository倒也是一种解决办法。但是，对于大部分公司来说，还是不会把公司内部的代码放到这种公共服务上的。这种需求场景下，就诞生了很多github的克隆实现，以方便部署内网的github。</p>

<!--more-->


<p>说到github的克隆实现，最出名的莫过于<a href="https://gitlab.com">gitlab</a>。这是一个ROR的实现，应该是目前市面上最成熟的一个github克隆项目，功能也是最丰富的。它在原来最基础的git库管理、权限管理、用户管理的基础上又加入了诸如code review、ci等极大方便开发者的功能。基本把github克隆了一遍，还加上了github没有的功能。功能强大倒是强大，但是gitlab本身的部署非常复杂，需要安装很多依赖包和依赖组件，整个过程非常痛苦。虽然现在提供了集成安装包，但对操作系统又有要求，比如要求CentOS 6以上，CentOs 5的用户就享受不了这个便利了。。。一想到这么多事情，对于我这种懒人来说，还是没有选择gitlab。</p>

<p>在前东家的时候，git项目是从gitlab迁移到了gitbucket（其中的原因当然不仅仅是因为gitlab部署的繁琐）。说起<a href="https://gitbucket.github.io/gitbucket-news/">gitbucket</a>，在百度上也搜不出什么信息来。能搜到的估计也就github库的地址和其他一些简单介绍。这个项目是日本的同行使用scala开发的一个github克隆。所以，抛开编程方面，对于java系的程序员还是比较友好的，部署也只需要把war包往tomcat之类的容器里一扔就ok。这个对比gitlab那可是天壤之别。而谈到二次开发，scala语言的学习曲线还是非常陡的，所以对比起来，貌似gitlab的二次开发相比较起来还是容易一些的（gitlab的二次开发没参与过，这里只是猜测）。当然，gitbucket是一个相对年轻的项目，对比gitlab，功能还显得比较单薄，bug也不少。我自己在使用的过程中，fix过几个小bug并提交到了项目的主分支，但是还有不少bug被公司的同事吐槽中（实在没时间专门fix这个）。另外，不得不说的是，gitbucket的markdown解析引擎，作者不知道什么原因从之前的一个叫pegdown的替换成了自己实现的markedj，让我们公司的一堆md文档都显示的各种乱，实在无语。。。不得不去clone了markedj的代码，fix了其中的一些bug，部署在我们内网的maven库里。bug虽然挺多，但比起gitlab来，还是喜欢gitbucket部署升级的简单（去官网下个war包，扔到tomcat里，恭喜你，你就拥有了自己的github）。当然，也有纯粹个人对jvm系语言的偏爱的原因^_^。</p>

<p>其实，除了gitlab和gitbucket还有很多github的克隆实现。这篇文章列出了很多并做了简单介绍:
<a href="http://www.oschina.net/news/50222/git-code-platforms">http://www.oschina.net/news/50222/git-code-platforms</a></p>

<p>其实，开发工具这种东西，选择最适合自己以及自己团队的才是上上之选。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[系统负载能力浅析]]></title>
    <link href="http://superhj1987.github.io/blog/2015/09/09/load-analysis/"/>
    <updated>2015-09-09T18:42:58+08:00</updated>
    <id>http://superhj1987.github.io/blog/2015/09/09/load-analysis</id>
    <content type="html"><![CDATA[<p><strong><em>&mdash;本文于2015.11.13号最新更新&mdash;</em></strong></p>

<p>互联网时代，高并发是一个老生常谈的话题。无论对于一个web站点还是app应用，高峰时能承载的并发请求都是衡量一个系统性能的关键标志。像阿里双十一顶住了上亿的峰值请求、订单也确实体现了阿里的技术水平（当然有钱也是一个原因）。</p>

<p>那么，何为系统负载能力？怎么衡量？相关因素有哪些？又如何优化呢？</p>

<!--more-->


<h2>一. 衡量指标</h2>

<p>用什么来衡量一个系统的负载能力呢？有一个概念叫做每秒请求数（Requests per second），指的是每秒能够成功处理请求的数目。比如说，你可以配置tomcat服务器的maxConnection为无限大，但是受限于服务器系统或者硬件限制，很多请求是不会在一定的时间内得到响应的，这并不作为一个成功的请求，其中成功得到响应的请求数即为每秒请求数，反应出系统的负载能力。</p>

<p>通常的，对于一个系统，增加并发用户数量时每秒请求数量也会增加。然而，我们最终会达到这样一个点，此时并发用户数量开始“压倒”服务器。如果继续增加并发用户数量，每秒请求数量开始下降，而反应时间则会增加。这个并发用户数量开始“压倒”服务器的临界点非常重要，此时的并发用户数量可以认为是当前系统的最大负载能力。</p>

<h2>二. 相关因素</h2>

<p>一般的，和系统并发访问量相关的几个因素如下：</p>

<ul>
<li>带宽</li>
<li>硬件配置</li>
<li>系统配置</li>
<li>应用服务器配置</li>
<li>程序逻辑</li>
<li>系统架构</li>
</ul>


<p>其中，带宽和硬件配置是决定系统负载能力的决定性因素。这些只能依靠扩展和升级提高。我们需要重点关注的是在一定带宽和硬件配置的基础上，怎么使系统的负载能力达到最大。</p>

<h3>2.1 带宽</h3>

<p>毋庸置疑，带宽是决定系统负载能力的一个至关重要的因素，就好比水管一样，细的水管同一时间通过的水量自然就少（这个比喻解释带宽可能不是特别合适）。一个系统的带宽首先就决定了这个系统的负载能力，其单位为Mbps,表示数据的发送速度。</p>

<h3>2.2 硬件配置</h3>

<p>系统部署所在的服务器的硬件决定了一个系统的最大负载能力，也是上限。一般说来，以下几个配置起着关键作用：</p>

<ul>
<li>cpu频率/核数：cpu频率关系着cpu的运算速度，核数则影响线程调度、资源分配的效率。</li>
<li>内存大小以及速度：内存越大，那么可以在内存中运行的数据也就越大，速度自然而然就快；内存的速度从原来的几百hz到现在几千hz，决定了数据读取存储的速度。</li>
<li>硬盘速度：传统的硬盘是使用磁头进行寻址的，io速度比较慢，使用了SSD的硬盘，其寻址速度大大较快。</li>
</ul>


<p>很多系统的架构设计、系统优化，最终都会加上这么一句：使用ssd存储解决了这些问题。</p>

<p>可见，硬件配置是决定一个系统的负载能力的最关键因素。</p>

<h3>2.3 系统配置</h3>

<p>一般来说，目前后端系统都是部署在Linux主机上的。所以抛开win系列不谈，对于Linux系统来说一般有以下配置关系着系统的负载能力。</p>

<ul>
<li>文件描述符数限制：Linux中所有东西都是文件，一个socket就对应着一个文件描述符，因此系统配置的最大打开文件数以及单个进程能够打开的最大文件数就决定了socket的数目上限。</li>
<li>进程/线程数限制: 对于apache使用的prefork等多进程模式，其负载能力由进程数目所限制。对tomcat多线程模式则由线程数所限制。</li>
<li>tcp内核参数：网络应用的底层自然离不开tcp/ip，Linux内核有一些与此相关的配置也决定了系统的负载能力。</li>
</ul>


<h4>2.3.1 文件描述符数限制</h4>

<ul>
<li><p>系统最大打开文件描述符数：/proc/sys/fs/file-max中保存了这个数目,修改此值</p>

<pre><code>  临时性
      echo 1000000 &gt; /proc/sys/fs/file-max
  永久性：在/etc/sysctl.conf中设置
      fs.file-max = 1000000
</code></pre></li>
<li><p>进程最大打开文件描述符数：这个是配单个进程能够打开的最大文件数目。可以通过ulimit -n查看/修改。如果想要永久修改，则需要修改/etc/security/limits.conf中的nofile。</p></li>
</ul>


<p>通过读取/proc/sys/fs/file-nr可以看到当前使用的文件描述符总数。另外，对于文件描述符的配置，需要注意以下几点：</p>

<ul>
<li>所有进程打开的文件描述符数不能超过/proc/sys/fs/file-max</li>
<li>单个进程打开的文件描述符数不能超过user limit中nofile的soft limit</li>
<li>nofile的soft limit不能超过其hard limit</li>
<li>nofile的hard limit不能超过/proc/sys/fs/nr_open</li>
</ul>


<h4>2.3.2 进程/线程数限制</h4>

<ul>
<li>进程数限制：ulimit -u可以查看/修改单个用户能够打开的最大进程数。/etc/security/limits.conf中的noproc则是系统的最大进程数。</li>
<li><p>线程数限制</p>

<ul>
<li>可以通过/proc/sys/kernel/threads-max查看系统总共可以打开的最大线程数。</li>
<li>单个进程的最大线程数和PTHREAD_THREADS_MAX有关，此限制可以在/usr/include/bits/local_lim.h中查看,但是如果想要修改的话，需要重新编译。</li>
<li>这里需要提到一点的是，Linux内核2.4的线程实现方式为linux threads，是轻量级进程，都会首先创建一个管理线程，线程数目的大小是受PTHREAD_THREADS_MAX影响的。但Linux2.6内核的线程实现方式为NPTL,是一个改进的LWP实现，最大一个区别就是，线程公用进程的pid（tgid），线程数目大小只受制于资源。</li>
<li>线程数的大小还受线程栈大小的制约：使用ulimit -s可以查看/修改线程栈的大小，即每开启一个新的线程需要分配给此线程的一部分内存。减小此值可以增加可以打开的线程数目。</li>
</ul>
</li>
</ul>


<h4>2.3.3 tcp内核参数</h4>

<p>在一台服务器CPU和内存资源额定有限的情况下，最大的压榨服务器的性能，是最终的目的。在节省成本的情况下，可以考虑修改Linux的内核TCP/IP参数，来最大的压榨服务器的性能。如果通过修改内核参数也无法解决的负载问题，也只能考虑升级服务器了，这是硬件所限，没有办法的事。</p>

<pre><code>netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
</code></pre>

<p>使用上面的命令，可以得到当前系统的各个状态的网络连接的数目。如下：</p>

<pre><code>LAST_ACK 14
SYN_RECV 348
ESTABLISHED 70
FIN_WAIT1 229
FIN_WAIT2 30
CLOSING 33
TIME_WAIT 18122
</code></pre>

<p>这里，TIME_WAIT的连接数是需要注意的一点。此值过高会占用大量连接，影响系统的负载能力。需要调整参数，以尽快的释放time_wait连接。</p>

<p>一般tcp相关的内核参数在/etc/sysctl.conf文件中。为了能够尽快释放time_wait状态的连接，可以做以下配置：</p>

<ul>
<li>net.ipv4.tcp_syncookies = 1 //表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；</li>
<li>net.ipv4.tcp_tw_reuse = 1 //表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；</li>
<li>net.ipv4.tcp_tw_recycle = 1 //表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭；</li>
<li>net.ipv4.tcp_fin_timeout = 30 //修改系統默认的 TIMEOUT 时间。</li>
</ul>


<p>这里需要注意的一点就是当打开了tcp_tw_recycle，就会检查时间戳，移动环境下的发来的包的时间戳有些时候是乱跳的，会把带了“倒退”的时间戳的包当作是“recycle的tw连接的重传数据，不是新的请求”，于是丢掉不回包，造成大量丢包。另外，当前面有LVS，并且采用的是NAT机制时，开启tcp_tw_recycle会造成一些异常，可见：<a href="http://www.pagefault.info/?p=416">http://www.pagefault.info/?p=416</a>。如果这种情况下仍然需要开启此选项，那么可以考虑设置net.ipv4.tcp_timestamps=0，忽略掉报文的时间戳即可。</p>

<p>此外，还可以通过优化tcp/ip的可使用端口的范围，进一步提升负载能力。，如下：</p>

<ul>
<li>net.ipv4.tcp_keepalive_time = 1200 //表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。</li>
<li>net.ipv4.ip_local_port_range = 10000 65000 //表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为10000到65000。（注意：这里不要将最低值设的太低，否则可能会占用掉正常的端口！）</li>
<li>net.ipv4.tcp_max_syn_backlog = 8192 //表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。</li>
<li>net.ipv4.tcp_max_tw_buckets = 5000 //表示系统同时保持TIME_WAIT的最大数量，如果超过这个数字，TIME_WAIT将立刻被清除并打印警告信息。默认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于Squid，效果却不大。此项参数可以控制TIME_WAIT的最大数量，避免Squid服务器被大量的TIME_WAIT拖死。</li>
</ul>


<h3>2.4 应用服务器配置</h3>

<p>说到应用服务器配置，这里需要提到应用服务器的几种工作模式,也叫并发策略。</p>

<ul>
<li>multi process:多进程方式，一个进程处理一个请求。</li>
<li>prefork：类似于多进程的方式，但是会预先fork出一些进程供后续使用，是一种进程池的理念。</li>
<li>worker：一个线程对应一个请求，相比多进程的方式，消耗资源变少，但同时一个线程的崩溃会引起整个进程的崩溃，稳定性不如多进程。</li>
<li>master/worker：采用的是非阻塞IO的方式，只有两种进程：worker和master,master负责worker进程的创建、管理等，worker进程采用基于事件驱动的多路复用IO处理请求。mater进程只需要一个，woker进程根据cpu核数设置数目。</li>
</ul>


<p>前三者是传统应用服务器apache和tomcat采用的方式，最后一种是nginx采用的方式。当然这里需要注意的是应用服务器和nginx这种做反向代理服务器（暂且忽略nginx+cgi做应用服务器的功能）的区别。应用服务器是需要处理应用逻辑的，有时候是耗cup资源的；而反向代理主要用作IO，是IO密集型的应用。使用事件驱动的这种网络模型，比较适合IO密集型应用，而并不适合CPU密集型应用。对于后者，多进程/线程则是一个更好地选择。</p>

<p>当然，由于nginx采用的基于事件驱动的多路IO复用的模型，其作为反向代理服务器时，可支持的并发是非常大的。淘宝tengine团队曾有一个测试结果是“24G内存机器上，处理并发请求可达200万”。</p>

<h4>2.4.1 nginx/tengine</h4>

<p>ngixn是目前使用最广泛的反向代理软件，而tengine是阿里开源的一个加强版nginx,其基本实现了nginx收费版本的一些功能，如：主动健康检查、session sticky等。对于nginx的配置，需要注意的有这么几点：</p>

<ul>
<li>worker数目要和cpu（核）的数目相适应</li>
<li>keepalive timout要设置适当</li>
<li>worker_rlimit_nofile最大文件描述符要增大</li>
<li>upstream可以使用http 1.1的keepalive</li>
</ul>


<p>典型配置可见：<a href="https://github.com/superhj1987/awesome-config/blob/master/nginx/nginx.conf">https://github.com/superhj1987/awesome-config/blob/master/nginx/nginx.conf</a></p>

<h4>2.4.2 tomcat</h4>

<p>tomcat的关键配置总体上有两大块：jvm参数配置和connector参数配置。</p>

<ul>
<li><p>jvm参数配置：</p>

<ul>
<li>堆的最小值：Xms</li>
<li>堆的最大值：Xmx</li>
<li>新生代大小: Xmn</li>
<li>永久代大小: XX:PermSize：</li>
<li>永久代最大大小: XX:MaxPermSize：</li>
<li>栈大小：-Xss或-XX:ThreadStackSize</li>
</ul>


<p>  这里对于栈大小有一点需要注意的是：在Linux x64上ThreadStackSize的默认值就是1024KB，给Java线程创建栈会用这个参数指定的大小。如果把-Xss或者-XX:ThreadStackSize设为0，就是使用“系统默认值”。而在Linux x64上HotSpot VM给Java栈定义的“系统默认”大小也是1MB。所以普通Java线程的默认栈大小怎样都是1MB。这里有一个需要注意的地方就是java的栈大小和之前提到过的操作系统的操作系统栈大小（ulimit -s）：这个配置只影响进程的初始线程；后续用pthread_create创建的线程都可以指定栈大小。HotSpot VM为了能精确控制Java线程的栈大小，特意不使用进程的初始线程（primordial thread）作为Java线程。</p>

<p>  其他还要根据业务场景，选择使用那种垃圾回收器，回收的策略。另外，当需要保留GC信息时，也需要做一些设置。</p>

<p>  典型配置可见：<a href="https://github.com/superhj1987/awesome-config/blob/master/tomcat/java_opts.conf">https://github.com/superhj1987/awesome-config/blob/master/tomcat/java_opts.conf</a></p></li>
<li><p>connector参数配置</p>

<ul>
<li>protocol: 有三个选项：bio；nio；apr。建议使用apr选项，性能为最高。</li>
<li>connectionTimeout：连接的超时时间</li>
<li>maxThreads：最大线程数，此值限制了bio的最大连接数</li>
<li>minSpareThreads: 最大空闲线程数</li>
<li>acceptCount：可以接受的最大请求数目（未能得到处理的请求排队）</li>
<li>maxConnection: 使用nio或者apr时，最大连接数受此值影响。</li>
</ul>


<p>  典型配置可见：<a href="https://github.com/superhj1987/awesome-config/blob/master/tomcat/connector.conf">https://github.com/superhj1987/awesome-config/blob/master/tomcat/connector.conf</a></p>

<p>  一般的当一个进程有500个线程在跑的话，那性能已经是很低很低了。Tomcat默认配置的最大请求数是150。当某个应用拥有250个以上并发的时候，应考虑应用服务器的集群。</p>

<p>  另外，并非是无限调大maxTreads和maxConnection就能无限调高并发能力的。线程越多，那么cpu花费在线程调度上的时间越多，同时，内存消耗也就越大，那么就极大影响处理用户的请求。受限于硬件资源，并发值是需要设置合适的值的。</p></li>
</ul>


<p>对于tomcat这里有一个争论就是：<strong><em>使用大内存tomcat好还是多个小的tomcat集群好？</em></strong>（针对64位服务器以及tomcat来说）</p>

<p>其实，这个要根据业务场景区别对待的。通常，大内存tomcat有以下问题：</p>

<ul>
<li>一旦发生full gc，那么会非常耗时</li>
<li>一旦gc，dump出的堆快照太大，无法分析</li>
</ul>


<p>因此，如果可以保证一定程度上程序的对象大部分都是朝生夕死的，老年代不会发生gc,那么使用大内存tomcat也是可以的。但是在伸缩性和高可用却比不上使用小内存（相对来说）tomcat集群。</p>

<p>使用小内存tomcat集群则有以下优势：</p>

<ul>
<li>可以根据系统的负载调整tc的数量，以达到资源的最大利用率，</li>
<li>可以防止单点故障。</li>
</ul>


<h4>2.4.3 数据库</h4>

<h5>mysql</h5>

<p>mysql是目前最常用的关系型数据库，支持复杂的查询。但是其负载能力一般，很多时候一个系统的瓶颈就发生在mysql这一点，当然有时候也和sql语句的效率有关。比如，牵扯到联表的查询一般说来效率是不会太高的。</p>

<p>影响数据库性能的因素一般有以下几点：</p>

<ul>
<li>硬件配置：这个无需多说</li>
<li>数据库设置：max_connection的一些配置会影响数据库的连接数</li>
<li>数据表的设计：使用冗余字段避免联表查询；使用索引提高查询效率</li>
<li>查询语句是否合理：这个牵扯到的是个人的编码素质。比如，查询符合某个条件的记录，我见过有人把记录全部查出来，再去逐条对比</li>
<li>引擎的选择：myisam和innodb两者的适用场景不同，不存在绝对的优劣</li>
</ul>


<p>抛开以上因素，当数据量单表突破千万甚至百万时（和具体的数据有关），需要对mysql数据库进行优化，一种常见的方案就是分表：</p>

<ul>
<li>垂直分表：在列维度的拆分</li>
<li>水平分表：行维度的拆分</li>
</ul>


<p>此外，对于数据库，可以使用读写分离的方式提高性能，尤其是对那种读频率远大于写频率的业务场景。这里采用master/slave的方式实现读写分离，前面用程序控制或者加一个proxy层。可以选择使用MySQL Proxy，编写lua脚本来实现基于proxy的mysql读写分离也可以通过程序来控制。</p>

<p>现在很多大的公司对这些分表、主从分离、分布式都基于mysql做了自己的二次开发，形成了自己公司的一套分布式数据库系统。比如阿里的TDDL，网易的DDB等。当然，很多大公司也研发了自己的mysql分支，比较出名的就是姜承尧带领研发的InnoSQL。</p>

<h5>redis</h5>

<p>当然，对于系统中并发很高并且访问很频繁的数据，关系型数据库还是不能妥妥应对。这时候就需要缓存数据库出马以隔离对mysql的访问,防止mysql崩溃。</p>

<p>其中，redis是目前用的比较多的缓存数据库（当然，也有直接把redis当做数据库使用的）。redis是单线程基于内存的数据库，读写性能远远超过mysql。一般情况下，对redis做读写分离主从同步就可以应对大部分场景的应用。但是这样的方案缺少ha，尤其对于分布式应用，是不可接受的。目前，redis集群的实现方案有以下几个：</p>

<ul>
<li>redis cluster:这是一种去中心化的方案，是redis的官方实现。是一种非常“重”的方案，已经不是Redis单实例的“简单、可依赖”了。目前应用案例还很少，貌似国内的芒果台用了，结局不知道如何。</li>
<li><a href="https://github.com/twitter/twemproxy">twemproxy</a>：这是twitter开源的redis和memcached的proxy方案。比较成熟，目前的应用案例比较多，但也有一些缺陷，尤其在运维方面。比如无法平滑的扩容/缩容，运维不友好等。</li>
<li><a href="https://github.com/wandoulabs/codis">codis</a>: 这个是豌豆荚开源的redis proxy方案，能够兼容twemproxy，并且对其做了很多改进。由豌豆荚于2014年11月开源，基于Go和C开发。现已广泛用于豌豆荚的各种Redis业务场景。现在比Twemproxy快近100%。目前据我所知除了豌豆荚之外，hulu也在使用这套方案。当然，其升级项目<a href="https://github.com/reborndb/reborn">reborndb</a>号称比codis还要厉害。</li>
</ul>


<h3>2.5 系统架构</h3>

<p>影响性能的系统架构一般会有这几方面：</p>

<ul>
<li>负载均衡</li>
<li>同步 or 异步</li>
<li>28原则</li>
</ul>


<h4>2.5.1 负载均衡</h4>

<p>负载均衡在服务端领域中是一个很关键的技术。可以分为以下两种：</p>

<ul>
<li>硬件负载均衡</li>
<li>软件负载均衡</li>
</ul>


<p>其中，硬件负载均衡的性能无疑是最优的，其中以F5为代表。但是，与高性能并存的是其成本的昂贵。所以对于很多初创公司来说，一般是选用软件负载均衡的方案。</p>

<p>软件负载均衡中又可以分为四层负载均衡和七层负载均衡。
上文在应用服务器配置部分讲了nginx的反向代理功能即七层的一种成熟解决方案，主要针对的是七层http协议（虽然最新的发布版本已经支持四层负载均衡）。对于四层负载均衡，目前应用最广泛的是lvs。其是阿里的章文嵩博士带领的团队所研发的一款linux下的负载均衡软件，本质上是基于iptables实现的。分为三种工作模式：</p>

<ul>
<li>NAT: 修改数据包destination ip，in和out都要经过lvs。</li>
<li>DR：修改数据包mac地址，lvs和realserver需要在一个vlan。</li>
<li>IP TUUNEL：修改数据包destination ip和源ip，realserver需要支持ip tunnel协议。lvs和realserver不需要在一个vlan。</li>
</ul>


<p>三种模式各有优缺点，目前还有阿里开源的一个FULL NAT是在NAT原来的DNAT上加入了SNAT的功能。</p>

<p>此外，haproxy也是一款常用的负载均衡软件。但限于对此使用较少，在此不做讲述。</p>

<h4>2.5.2 同步 or 异步</h4>

<p>对于一个系统，很多业务需要面对使用同步机制或者是异步机制的选择。比如，对于一篇帖子，一个用户对其分享后，需要记录用户的分享记录。如果你使用同步模式（分享的同时记录此行为），那么响应速度肯定会受到影响。而如果你考虑到分享过后，用户并不会立刻去查看自己的分享记录，牺牲这一点时效性，可以先完成分享的动作，然后异步记录此行为，会提高分享请求的响应速度（当然，这里可能会有事务准确性的问题）。有时候在某些业务逻辑上，在充分理解用户诉求的基础上，是可以牺牲某些特性来满足用户需求的。</p>

<p>这里值得一提的是，很多时候对于一个业务流程，是可以拆开划分为几个步骤的，然后有些步骤完全可以异步并发执行，能够极大提高处理速度。</p>

<h4>2.5.3 28原则</h4>

<p>对于一个系统，20%的功能会带来80%的流量。这就是28原则的意思，当然也是我自己的一种表述。因此在设计系统的时候，对于80%的功能，其面对的请求压力是很小的，是没有必要进行过度设计的。但是对于另外20%的功能则是需要设计再设计、reivew再review，能够做负载均衡就做负载均衡，能够缓存就缓存，能够做分布式就分布式，能够把流程拆开异步化就异步化。</p>

<p>当然，这个原则适用于生活中很多事物。</p>

<h2>三. 一般架构</h2>

<p>一般的java后端系统应用架构如下图所示：lvs+nginx+tomcat+mysql/ddb+redis/codis</p>

<p><img src="http://superhj1987.github.io/images/web-arch.jpg" alt="web-arch" /></p>

<pre><code>如需转载，请注明来自: http://superhj1987.github.com/blog

版权声明：本文为博主原创文章，未经博主允许不得转载
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[make、ant、mvn的命令行参数传递]]></title>
    <link href="http://superhj1987.github.io/blog/2015/07/09/mvn-ant-make-transfer-params/"/>
    <updated>2015-07-09T11:48:47+08:00</updated>
    <id>http://superhj1987.github.io/blog/2015/07/09/mvn-ant-make-transfer-params</id>
    <content type="html"><![CDATA[<p>在使用make、ant、mvn的时候，怎样传递命令行参数呢。比如</p>

<ul>
<li>在makefile中读取make后面跟的参数</li>
<li>在build.xml中读取ant后面跟的参数</li>
<li>在pom.xml中读取mvn后跟的参数</li>
</ul>


<h2>1. make</h2>

<p>执行命令</p>

<pre><code>make name=test
</code></pre>

<p>在makefile中</p>

<pre><code>${name}
</code></pre>

<h2>2. ant</h2>

<p>执行命令</p>

<pre><code>ant -Dname=test
</code></pre>

<p>在build.xml中</p>

<pre><code>${name}
</code></pre>

<h2>3. mvn</h2>

<p>执行命令</p>

<pre><code>mvn -Dname=test
</code></pre>

<p>在build.xml中</p>

<pre><code>${name}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hbase关键的几个点]]></title>
    <link href="http://superhj1987.github.io/blog/2015/06/10/hbase-about/"/>
    <updated>2015-06-10T10:59:59+08:00</updated>
    <id>http://superhj1987.github.io/blog/2015/06/10/hbase-about</id>
    <content type="html"><![CDATA[<h2>一. 什么时候需要HBase</h2>

<ol>
<li><p>半结构化或非结构化数据</p>

<p> 对于数据结构字段不够确定或杂乱无章很难按一个概念去进行抽取的数据适合用HBase。当业务发展需要存储author的email，phone，address信息时RDBMS需要停机维护，而HBase支持动态增加.</p></li>
<li><p>记录非常稀疏</p>

<p> RDBMS的行有多少列是固定的，为null的列浪费了存储空间。而如上文提到的，HBase为null的Column不会被存储，这样既节省了空间又提高了读性能。</p></li>
<li><p>多版本数据</p>

<p> 如上文提到的根据Row key和Column key定位到的Value可以有任意数量的版本值，因此对于需要存储变动历史记录的数据，用HBase就非常方便了。比如上例中的author的Address是会变动的，业务上一般只需要最新的值，但有时可能需要查询到历史值。</p></li>
<li><p>超大数据量</p>

<p> 当数据量越来越大，RDBMS数据库撑不住了，就出现了读写分离策略，通过一个Master专门负责写操作，多个Slave负责读操作，服务器成本倍增。随着压力增加，Master撑不住了，这时就要分库了，把关联不大的数据分开部署，一些join查询不能用了，需要借助中间层。随着数据量的进一步增加，一个表的记录越来越大，查询就变得很慢，于是又得搞分表，比如按ID取模分成多个表以减少单个表的记录数。经历过这些事的人都知道过程是多么的折腾。采用HBase就简单了，只需要加机器即可，HBase会自动水平切分扩展，跟Hadoop的无缝集成保障了其数据可靠性（HDFS）和海量数据分析的高性能（MapReduce）</p></li>
</ol>


<h2>二. HTable一些基本概念</h2>

<ol>
<li><p>Row key</p>

<p> 行主键， HBase不支持条件查询和Order by等查询，读取记录只能按Row key（及其range）或全表扫描，因此Row key需要根据业务来设计以利用其存储排序特性（Table按Row key字典序排序如1,10,100,11,2）提高性能。</p></li>
<li><p>Column Family（列族）</p>

<p> 在表创建时声明，每个Column Family为一个存储单元。在上例中设计了一个HBase表blog，该表有两个列族：article和author。</p></li>
<li><p>Column（列）</p>

<p> HBase的每个列都属于一个列族，以列族名为前缀，如列article:title和article:content属于article列族，author:name和author:nickname属于author列族。</p>

<p> Column不用创建表时定义即可以动态新增，同一Column Family的Columns会群聚在一个存储单元上，并依Column key排序，因此设计时应将具有相同I/O特性的Column设计在一个Column Family上以提高性能。</p></li>
<li><p>Timestamp</p>

<p> HBase通过row和column确定一份数据，这份数据的值可能有多个版本，不同版本的值按照时间倒序排序，即最新的数据排在最前面，查询时默认返回最新版本。如上例中row key=1的author:nickname值有两个版本，分别为1317180070811对应的“一叶渡江”和1317180718830对应的“yedu”（对应到实际业务可以理解为在某时刻修改了nickname为yedu，但旧值仍然存在）。Timestamp默认为系统当前时间（精确到毫秒），也可以在写入数据时指定该值。</p></li>
<li><p>Value</p>

<p> 每个值通过4个键唯一索引，tableName+RowKey+ColumnKey+Timestamp=>value，例如上例中{tableName=’blog’,RowKey=’1’,ColumnName=’author:nickname’,Timestamp=’ 1317180718830’}索引到的唯一值是“yedu”。</p></li>
<li>存储类型

<ul>
<li>TableName 是字符串</li>
<li>RowKey 和 ColumnName 是二进制值（Java 类型 byte[]）</li>
<li>Timestamp 是一个 64 位整数（Java 类型 long）</li>
<li>value 是一个字节数组（Java类型 byte[]）。</li>
</ul>
</li>
</ol>


<p>将HTable的存储结构理解为</p>

<p><img src="http://superhj1987.github.io/images/blog_images/hbase_data.jpg" alt="hbase-data" /></p>

<p>即HTable按Row key自动排序，每个Row包含任意数量个Columns，Columns之间按Column key自动排序，每个Column包含任意数量个Values。理解该存储结构将有助于查询结果的迭代。</p>

<h2>三. 模式设计应遵循的原则</h2>

<ol>
<li><p>列族的数量以及列族的势</p>

<p> 列族的数量越少越好，牵扯到了hbase的flushing；同一个表中不同列族所存储的记录数量的差别也需要考虑（列族的势），会造成记录数量少的列族的数据分散在多个region上，影响查询效率。</p></li>
<li><p>行键的设计</p>

<p> 避免使用时序或者单调（递增/递减）行键，否则会导致连续到来的数据会被分配到统一region中。</p></li>
<li><p>尽量最小化行键和列族的大小</p>

<p> 避免hbase的索引过大，加重系统存储的负担</p></li>
<li><p>版本的数量</p>

<p> HColumnDescriptor设置版本的数量，避免设置过大，版本保留过多。</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于Spring mvc中modelattribute无法制定别名的解决方案]]></title>
    <link href="http://superhj1987.github.io/blog/2015/01/21/springm-mvc-model-attribute-alias/"/>
    <updated>2015-01-21T12:00:00+08:00</updated>
    <id>http://superhj1987.github.io/blog/2015/01/21/springm-mvc-model-attribute-alias</id>
    <content type="html"><![CDATA[<p>最近由于项目需要，发现spring mvc在绑定参数时有这么一个缺陷。</p>

<p><strong>Url</strong>: <a href="http://localhost:8080/api/test?user_name=testUser">http://localhost:8080/api/test?user_name=testUser</a></p>

<p><strong>Controller</strong>:</p>

<pre>
@Controller
@RequestMapping("/api")
public class ApiController extends BaseController {

    @RequestMapping(value = "/test", headers = "Accept=application/json")
    public void authUser(ModelMap modelMap, Account acc) {
        ResultPack.packOk(modelMap);
    }
}

public class Account{
    private static final long serialVersionUID = 750752375611621980L;

    private long id;
    private String userName;
    private String password;
    private AccountType type = AccountType.ADMIN;
    private long timeTag;
    private int status = 1;
    ...
    ...
}
</pre>


<p>user_name无法映射到acc的userName上。如果使用json的方式，可以使用JsonProperty注解来解决。否则，spring貌似没提供解决方案。</p>

<p>于是追踪了一下spring mvc的源代码，发现可以通过重写ServletModelAttributeMethodProcessor来支持这个功能。</p>

<p><strong>Github</strong>:  <a href="https://github.com/superhj1987/spring-mvc-model-attribute-alias">https://github.com/superhj1987/spring-mvc-model-attribute-alias</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2014这一年]]></title>
    <link href="http://superhj1987.github.io/blog/2015/01/15/2014-final-note/"/>
    <updated>2015-01-15T16:08:48+08:00</updated>
    <id>http://superhj1987.github.io/blog/2015/01/15/2014-final-note</id>
    <content type="html"><![CDATA[<p>突然发觉已经是2015年的1月15号了，即兴补上一篇2014年的总结吧。</p>

<p>2014年全国、全世界发生了很多事情。政府大规模的反腐揪出了一个个贪得无厌的官僚，让人们不禁拍手称快，觉得看到了国家的希望。但是腐败的根本在于体制，体制不进行变革，那么倒下一个贪官，还有另一批贪官起来，顶多是在这段时间收敛一下。其实，从某种意义来说，贪腐还不是危害最大的，如果你给人民做了贡献，带来了好处，至少我们受益了；但要只是贪污而无作为，那么真的是让人不齿了。不知道从什么时候起，自己对体制内的东西都有点反感，提到体制内，首先想到的就是背景、亲戚、老爹、关系，而不是能力。尤其是自己亲身体会或者道听途说到体制内很多万恶的潜规则之后，更是加深了这种感觉。真心希望在习大大的努力之下，能彻底破除体制内多少年形成的各种弊病，让“中国梦”真的可以成为所有人的“中国梦”。除了反腐，14年最大的事情莫过于世界杯了，对于我这种对足球仅存在巴西、罗纳尔多、亨利这些字眼的人来说，也就趁机给自己一个放纵的理由，晚上看世界杯、喝啤酒、吃烧烤，顺便买个足彩，也算充实了一下每天三点一线的生活。至于谁最好拿了冠军，说实话还真的没那么关心。</p>

<!--more-->


<p>举国、举世界的那些大事，对于我这种小屁民来说，也就只能调侃一下，过过嘴瘾。对于自己，2014也发生了不少事情。年初在家人的支持下，买了人生第一辆汽车，让我这个已经四年驾龄的“老司机”终于有了私家车。说来也巧，我压根不知道杭州会启动摇号买车政策的，没想到，刚买完没过多久，竟然宣布限号了，而且是在之前无数次声明“不限号”的情况下，这又显示出政府的老辣了。。。拿到新车，经历了开始的几次“摩擦”之后，自己也算慢慢上手了，到后来从杭州一路开到北京，也算能彻底摆脱“新手”的头衔了。买完车，一般的大事就是要买房子了，其实自己并没打算很快就买房的，但是2014年中开始，房子的价格貌似一降再降，让我总有一种再不买价格就回升的感觉。在纠结了无数次的情况下，终于狠下心付了首付（父母也倾囊相助），也算拥有了自己的小房子。买车买房两件大事都解决的同时，我却没想到最大的事情也来了。在自己已经打算彻底定居在杭州的情况下，老同学极力邀请自己加入他们公司打拼一下。当时虽然对自身的状况已经稍有微词，但还不至于想离职的地步。说起这个机会，自己在2011年的时候就险些加入他们，后来又折腾了两次。所以，早就认为和这次机会擦肩而过了，也就没再做指望。这一次机会又来到自己面前，而且是一个极其微妙的时间点。丰厚的年终奖、升职、股票摆在自己的面前，车子、房子也限制着自己。很多因素都告诉我不要去。纠结了n久，和父母、女友商议了无数次。我最后意识到在这种局面之下，还是要听从一下自己的内心的。大公司的生活固然待遇优厚、生活舒适，但是还未到30就已经学会享受也不是一件好事情，去一个未知的公司博一次，也许自己能收获意想不到的东西。衡量许久，也算做出了人生又一次极其重要的选择，决意北上博一下了。很多人可能会认为是给的待遇足够好。但说实话，虽然工资不错，但是由于年终奖的损失，如果和我不离职拿到的相比，2014年最后到手的是只可能少不可能多的。不过，加入创业公司，看重的是未来，对于眼前这些东西，并没有那么重要。</p>

<p>11月中旬，一路北上，来到了我一直持排斥态度的帝都。自己第一次长途开车，竟然顺利地到达了北京，也算是一种成功吧。</p>

<p>进入新的公司，一个未知前途的创业公司，截然不同的运作方式让我一开始有点措手不及。相比之前在大公司，小公司更需要一个人的快速成长以及自我约束，以及那种随叫随到、不怕脏累的奋斗精神。而技术层面，要尽最大化压榨硬件资源，用有限的硬件资源达到最大的性能。这些都让自己的架构方式和代码编写不得不去改变、去适应，这也算是一种成长吧。公司的基础架构、公共组件、项目管理、技术体系、项目架构都是一个初级的水平，改变这些是一个很难很长的路，但又不得不做。到现在，在做这些改变的过程中，自己的基础知识得到了巩固、架构能力也有了一定的提升，技术视野也开阔了一些。熟悉了公司的流程和整体的氛围，也算融入了这个团队，要做的还有很多，阻力也有很多。一切都在逼迫自己去学习、去思考、去提高。这也是与以前相比，给自己最大动力的事情。</p>

<p>2015年，工作上希望自己能做到这些</p>

<ul>
<li>合理设计并实现整个公司的基础架构</li>
<li>构建合理的项目管理流程、监督机制</li>
<li>提升团队的整体水平</li>
<li>保证产品的研发进度以及线上稳定性</li>
<li>招一些优秀的人加入</li>
</ul>


<p>自身方面，希望能做到这些：</p>

<ul>
<li>提升自身的技术水平和视野</li>
<li>深入学习一门技术：docker netty kafka rabbitmq elasticsearch solr</li>
<li>阅读至少五本非技术书籍</li>
</ul>


<p>Stay hungry,stay foolish!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spring mvc的controller传递HttpServletResponse参数的一点事]]></title>
    <link href="http://superhj1987.github.io/blog/2014/12/09/spring-mvc-httpservletresponse/"/>
    <updated>2014-12-09T10:05:41+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/12/09/spring-mvc-httpservletresponse</id>
    <content type="html"><![CDATA[<pre>
    @RequestMapping(value = "cardDown", method = RequestMethod.GET, headers = "Accept=text/html")
    public void cardDown(ModelMap modelMap, HttpServletRequest request, HttpServletResponse response, String id, int status){
    ......
    }
</pre>


<p>之前在使用Spring mvc的时候发现这么一回事：在spring mvc的controller的参数里如果有HttpServletResponse(类似上面的代码),那么必须有返回值框架才会去在执行完handler后去搜索相应的viewResolver和view从而展现数据。如果没有返回值，那么默认就是返回null的。我初步推测框架的处理过程大致如此：如果controller参数里传递HttpServletResposne的话，框架就认为视图由handler自己生成可以不参于这个过程,但是如果handler有返回值的话，那么仍然认为还需要参与到视图生成的过程中。</p>

<!--more-->


<p>翻了一下spring mvc的代码，验证了自己的想法。在DispatchServlet的921行</p>

<pre>
// Actually invoke the handler.
mv = ha.handle(processedRequest, response, mappedHandler.getHandler());
</pre>


<p>这里的mv就是视图生成的结果。接着经历下面的过程：</p>

<ol>
<li>AbstractHandlerMethodAdapter.handle</li>
<li>RequestMappingHandlerAdapter.handleInternal</li>
<li><p>RequestMappingHandlerAdapter.invokeHandleMethod</p>

<p> 这地方有一个关键的变量mavContainer
 <pre>
 ModelAndViewContainer mavContainer = new ModelAndViewContainer();
 </pre>
 mavContainer有一个属性requestHandled，其标志着此次请求是否是由handler自己控制的。默认为false。</p></li>
<li><p>ServletInvocableHandlerMethod.invokeAndHandle</p></li>
<li>InvocableHandlerMethod.invokeForRequest</li>
<li><p>InvocableHandlerMethod.getMethodArgumentValues</p>

<p> 这个方法的功能在名字上大体就能看出来：获取controller中每一个参数的值。关键的地方在于
 <pre>
 args[i] = argumentResolvers.resolveArgument(parameter, mavContainer, request, dataBinderFactory);
 </pre>
 这一行代码关联的是对每一中paramerter的处理类。接下来的调用见7</p></li>
<li><p>HandlerMethodArgumentResolverComposite.resolveArgument</p>

<p> <pre>
 HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter);
 Assert.notNull(resolver, &ldquo;Unknown parameter type [&rdquo; + parameter.getParameterType().getName() + &ldquo;]&rdquo;);
 return resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);
 </pre></p>

<p> 这里的代码就三行，第一步是根据参数不同，获取不同的argumentResolver。当参数为HttpServletResponse的时候，就会调用ServletResponseMethodArgumentResolver.resolveArgument</p></li>
<li><p>ServletResponseMethodArgumentResolver.resolveArgument</p>

<p> 最核心的一段代码来了</p>

<p> <pre>
 if (mavContainer != null) {
     mavContainer.setRequestHandled(true);
 }
 </pre></p>

<p> 这里就把mavContainer的requestHandled设置为了true.</p></li>
<li><p>回到4，调用完InvocableHandlerMethod.invokeForRequest</p>

<p> <pre>
 if (returnValue == null) {
     if (isRequestNotModified(webRequest) || hasResponseStatus() || mavContainer.isRequestHandled()) {
         mavContainer.setRequestHandled(true);
         return;
     }
 }else if (StringUtils.hasText(this.responseReason)) {
     mavContainer.setRequestHandled(true);
     return;
 }</p>

<p> mavContainer.setRequestHandled(false);
 </pre></p>

<p> 当handler的返回值为null的时候，直接返回。否则将mavContainer的requestHandled设置为false。</p></li>
<li><p>接着回到3，调用完ServletInvocableHandlerMethod.invokeAndHandle后，接着调用getModelAndView(mavContainer, modelFactory, webRequest)</p></li>
<li><p>ServletInvocableHandlerMethod.getModelAndView</p>

<p><pre>
modelFactory.updateModel(webRequest, mavContainer);</p>

<p>if (mavContainer.isRequestHandled()) {
    return null;
}
</pre></p>

<p>这里当mavContainer的requestHandled被设置为true时,视图返回null。</p></li>
</ol>


<p>整个大体的流程就是这样的，如果需要使用HttpServletResponse同时还需要框架控制视图生成的话，可以给controller method一个返回值（随便什么都行）。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于工作]]></title>
    <link href="http://superhj1987.github.io/blog/2014/11/26/work-note-new/"/>
    <updated>2014-11-26T17:57:05+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/11/26/work-note-new</id>
    <content type="html"><![CDATA[<p>离开上一个公司快半个月了。想想，自己坚持从杭州离开，从一个大公司离开，来到这个自己一直很排斥的城市，加入一个尚不知前景的创业公司。是对还是错?</p>

<p>在前东家的时候，周围优秀的人太多，不管怎么样自己都能学到很多知识，遇到疑问的时候也能有人解答。所以在前东家的几年自己成长了很多。有怨言的仅仅是那一直落后于业界的工资待遇以及刚入职时候坑人的80%，其他的都是自己很满意的，也是自己会感恩的一家公司。自己起初也是打算在那里沉淀几年技术再去创业的。至于选择离开，问问自己，是为了钱吗？其实在杭州能给我开出这种待遇的公司很多；为了职位吗？其实现在的自己水平还处于很低的一个水准，学习才是主旋律。也许仅仅是那种不甘心和挑战带来的机会吧。要知道，选择这条路意味着从此以后需要依靠自己的学习能力，自我提高，自我成长；选择这条路意味着压力、责任和冒险。自己到这里的期望是什么呢？成为技术领头人，带着一个技术团队从一个没有什么业界水准的初级团队成长为一个业界有地位的杰出团队，这也是现在能追求的最大化吧。人生总是面临很多选择，选择一个就意味着不能回头。自己能把握的只有成为更好的自己，不能把握的只能顺其自然。</p>

<p>在一个极具挑战的环境下，汲取各种知识，培养自己的架构思维，尽快的成长为合格甚至顶尖的架构师，这也许是现在能带给自己最大的机会。这也是自己当初这么坚决来这里的原因吧。Stay hungry,stay foolish,把握现在，充实自己，一切顺其自然。^_^</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ShellShock这点事]]></title>
    <link href="http://superhj1987.github.io/blog/2014/09/29/shell-shock/"/>
    <updated>2014-09-29T21:49:46+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/09/29/shell-shock</id>
    <content type="html"><![CDATA[<h2>前言</h2>

<p>在微博上看到最近安全界爆出了一个危害比之前的“心脏流血”（Heartbleed Bug）还要大很多的Bash代码注入漏洞：CVE-2014-6271 “shellshock”漏洞，然后随之而来一系列相关漏洞。详情可以看这些链接：<a href="http://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2014-6271">CVE-2014-6271</a> 、<a href="http://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2014-7169">CVE-2014-7169</a>、<a href="https://access.redhat.com/security/cve/CVE-2014-7186">CVE-2014-7186</a>、<a href="https://access.redhat.com/security/cve/CVE-2014-7187">CVE-2014-7187</a>、<a href="https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2014-6277">CVE-2014-6277</a>。世界上Linux服务器的占有份额是很大的，而bash又是Linux不可或缺的一个部分。可想而知，这个漏洞的破坏力有多大。这个从名字上就可以看出来，ShellShock是医学上的一种严重的疾病，中文叫做“弹震症”，指的是受到爆炸冲击后导致浑身颤抖、思维混乱等症状。这个命名很形象地反映了问题的严重性。</p>

<!--more-->


<h2>漏洞的原理是什么</h2>

<p>参照shellshock官网<a href="https://shellshocker.net/">https://shellshocker.net/</a>，测试本机是否受这个漏洞的影响，先要执行一段shell代码：</p>

<pre>
env x='() { :;}; echo vulnerable' bash -c ""
</pre>


<p>如果发现有以下输出说明你系统受到这个漏洞的影响。</p>

<pre>
vulnerable
</pre>


<p>为什么会这样呢？看一下代码，首先设置一个环境变量x，x指向的是一个函数，这个函数仅仅有一句:;的代码，就是返回true。后面跟着的echo vulnerable，按说是不应该为执行的。后面的bash -c &hellip;，这里使用bash命令开启了子shell，子shell会在启动的时候继承父shell的环境变量，于是在继承x这个变量的时候，就把echo vulnerable这行执行了。结果就是打印出了vulnerable。</p>

<p>官网上提到如果这一步就发现自己收到了影响，那么先update bash吧。</p>

<p>在升级完bash后，并非就高枕无忧了，又有人发现了更NB的利用这个漏洞的办法。执行下面的shell代码：</p>

<pre>
env X='() { (shellshocker.net)=>\' bash -c "echo date"; cat echo ; rm -f echo
</pre>


<p>如果这行代码，打印出了日期（可能会伴有一些错误），那么说明你仍然没有逃脱这个漏洞的影响。</p>

<pre>
bash: X: line 1: syntax error near unexpected token `='
bash: X: line 1: `'
bash: error importing function definition for `X'
2014年 9月29日 星期一 21时04分30秒 CST
</pre>


<p>update bash之后，只是让子shell继承父shell的时候不去执行后面的语句。但是这个代码变态之处在于它故意使用（shellshocker.net）=让shell报错，后面的>\则留在了缓冲区中，子shell继承到了>\,然后执行echo date，此时相当于下面的代码：</p>

<pre>
>\
echo date
</pre>


<p>\是命令换行的，于是就相当于>echo date，>是重定向符号，最后其实等价于date  > echo，这样最终把命令给执行了。</p>

<p>此外，官网还列出了其他的exploit，都是利用了子进程对环境变量的继承：</p>

<ol>
<li><p>Exploit 3 (???)</p>

<p> Here is another variation of the exploit. Please leave a comment below if you know the CVE of this exploit.
 <pre>
env -i X=&lsquo; () { }; echo hello&rsquo; bash -c &lsquo;date&rsquo;
</pre></p>

<p>  If the above command outputs &ldquo;hello&rdquo;, you are vulnerable.</p></li>
<li><p>Exploit 4 (CVE-2014-7186)</p></li>
<li><p>Exploit 5 (CVE-2014-7187)</p></li>
</ol>


<h2>怎样利用这个漏洞</h2>

<p>看了上面说的bash漏洞，那我们怎样来利用呢？举一个典型的列子，现在有很多网站是使用的apache运行在Linux系统上的，也是以子进程的方式来运行web程序的，其中用户端传来的HTTP_USER_AGENT、HTTP_HEADER等是会传递到子进程中的，而且这些变量是用户端任意可以指定的，如果按照开始讲的那样传递一个x过来，但是并不仅仅是echo一个字符串，那危害。。。可想而知。如下面的一个http请求（如果不是仅仅ping一个ip地址）：</p>

<pre>
http-user-agent = shellshock-scan () http-header = Cookie:() { :; }; ping -c 163.com
http-header = Host:() { :; }; ping -c 163.com
http-header = Referer:() { :; }; ping -c 163.com
</pre>


<p>除此之外，现在已经有利用这个漏洞攻击DHCP客户端、VoIP设备、Git版本控制系统、qmail等的成功例子了，可以说有Linux的地方就有shellshock的“用武之地”，包括Mac os。这篇文章总结了现在发现的各种各样的攻击方式：<a href="http://www.fireeye.com/blog/uncategorized/2014/09/shellshock-in-the-wild.html">http://www.fireeye.com/blog/uncategorized/2014/09/shellshock-in-the-wild.html</a></p>

<p>看到这里，可能有人会说：”让你们天天说Linux有多安全”。其实Windows也逃不开这个漏洞的危害，很多windows系统里都有bash环境，即使没有bash环境，只要你的系统使用了含有bash的组件（如负载均衡、CDN）也难逃shellshock的魔掌。</p>

<h2>总结</h2>

<p>修复Shellshock漏洞就像打地鼠，堵了一头另一头又冒出，修复一部分，很快就有其他的攻击方式出现，层出不穷，问题的关键其实还是在于bash在设计的时候对于环境变量的依赖。只要存在对环境变量的导出，那么攻击者就可以使用各种方式诱骗bash视其为命令，进行执行。</p>

<h3>参考文章</h3>

<ul>
<li><a href="http://www.oschina.net/news/55694/shellshock-flaw">http://www.oschina.net/news/55694/shellshock-flaw</a></li>
<li><a href="http://news.cnblogs.com/n/504675/">http://news.cnblogs.com/n/504675/</a></li>
<li><a href="http://weibo.com/p/1005051401527553/weibo">http://weibo.com/p/1005051401527553/weibo</a></li>
<li><a href="https://shellshocker.net/">https://shellshocker.net/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM内存GC的骗局（转载）]]></title>
    <link href="http://superhj1987.github.io/blog/2014/09/25/jvm-cheat/"/>
    <updated>2014-09-25T21:29:52+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/09/25/jvm-cheat</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<p>在日常程序开发中，很多JAVA程度员不太关心内存的使用情况。当然，如果程序员运气较好或者系统没有大规模的被测试或者被用户使用时，这个问题或许永远不出现，使得程序员一直认为内存反正是无限的，可以一直使用。确实，JVM的垃圾回收器会帮我们处理好所有的事情，可如果运气不是那么好，不幸就有可能发生在我们的身上，比如：进程会抛出OOM异常，不再接收新的请求；响应时间在固定时间段内变长，超时或者不响应，CPU使用率时常像过山车一样等。内存使用在大部分的工作时间可以正常工作，这样会导致很多的人对JAVA应用的内存使用情况不明了或者得不到充分的性能测试，而导致程序无法正常工作。出现上面的情况程序员一般会比较好的较快的发现问题或能总结一定的规律。</p>

<!--more-->


<h2>问题</h2>

<p>有时候JVM还会发生欺骗你的场景， JVM不停的在垃圾回收，可是每次回收完后堆却还是满的，很明显程序内存被使用完了，已经无法正常工作了，但JVM就是不抛出OutOfMemoryError(OOM)这个异常来告诉程序员内部发出了什么，只是不停的做老好人尝试帮我们做垃圾回收，把服务器的资源耗光了，但是此时服务器已经无法响应用户的正常请求了，让我们一起来看看这些情况发生时候的现象，体会一下被欺骗的感觉。</p>

<h2>现状：</h2>

<p>同事在模拟用户不停的发送请求给某系统，在运行一段时间后，突然，系统上邮件报告测试用例请求失败，登录测试系统的服务器，首先看下JVM的参数设置，如下：</p>

<p>-server –Xms4g –Xmx4g -XX:MaxPermSize=256m  -verbose:gc -XX:+PrintGCDetails -Xloggc:$CATALINA_BASE/logs/gc.log -XX:+PrintGCTimeStamp，再使用TOP命令看看服务器发生了什么。</p>

<p>观察一段时间后，CPU一直运行在100%，于是想当然的认为可能是那段程序里面触发了BUG,有可能是正则表达式或者某段代码里面有个死循环的坑跳进去，没有出来。这不是很简单的事吗？直接使用jstack + pid 把堆栈打出来即可，直接操作吧，界面上马上输出操作日志，从堆栈日志可以看出，所有的线程都被BLOCKED住了，然后堆栈里面也找不到任何业务的相关代码，难道直觉出错了，感觉一下子不太好了，但是至少可以排查到不是上面的二种原因了，好吧，那再看看应用的GC的情况，部分日志如下。</p>

<p>1403682.561: [GC [PSYoungGen: 1375104K->11376K(1386176K)] 4145665K->2782002K(4182400K), 0.0174410 secs] [Times: user=0.27 sys=0.00, real=0.02 secs]</p>

<p>1407799.743: [GC [PSYoungGen: 1386160K->11632K(1386432K)] 4156786K->2793538K(4182656K), 0.0285330 secs] [Times: user=0.48 sys=0.00, real=0.03 secs]</p>

<p>1409230.024: [GC [PSYoungGen: 1386416K->10688K(1377984K)] 4168322K->2803822K(4174208K), 0.0265000 secs] [Times: user=0.43 sys=0.00, real=0.02 secs]</p>

<p>1409230.051: [Full GC [PSYoungGen: 10688K->7014K(1377984K)] [PSOldGen: 2793134K->2796224K(2796224K)] 2803822K->2803238K(4174208K) [PSPermGen: 48439K->48439K(262144K)], 7.8892780 secs] [Times: user=7.92 sys=0.00, real=7.89 secs]</p>

<p>1410502.582: [Full GC [PSYoungGen: 1366336K->85344K(1377984K)] [PSOldGen: 2796224K->2796224K(2796224K)] 4162560K->2881568K(4174208K) [PSPermGen: 48577K->48577K(262144K)], 8.2720110 secs] [Times: user=8.29 sys=0.00, real=8.27 secs]</p>

<p>PS：这里使用-XX:+PrintGCDateStamps替代-XX:+PrintGCTimeStamp,可以打印出真实时间戳。</p>

<h2>解释一下：</h2>

<p>第一行：
1403682.561: [GC [PSYoungGen: 1375104K->11376K(1386176K)] 4145665K->2782002K(4182400K), 0.0174410 secs] [Times: user=0.27 sys=0.00, real=0.02 secs]</p>

<p>发生的时间点，：JVM运行的时间长度，以度为单位，也可以格式化成固定的时间格式</p>

<p>PSYoungGen：发生了何种类型的GC，此处代表发生了年轻代的GC</p>

<p>1375104K：回收前的大小</p>

<p>11376K：回收后的大小</p>

<p>1386176K：YOUNG代的大小</p>

<p>4145665 K：回收前总的占用大小</p>

<p>2782002K：回收后的占用大小</p>

<p>4182400K：总占用大小</p>

<p>0.27和0.00：代表在用户态(user)和系统状(sys)的CPU运行时间</p>

<p>0.02 secs：代表实际的GC的运行时间</p>

<p>注：上面总的运行时间小于用户态和系统态的时间总和，是由于后者仅指CPU的运行时间，包括等待或IO阻塞的时间，而且现在的GC是采用多线程收集的，同时机器也是多个CPU，因此，大部分是二者之和要比前面的值大，如果是采用串形化收集器( serial collector)的话，二者时间几乎相差不多。关于各种收集器的差别，后续有时间再安排详细总结。</p>

<p>接下来的二行，不再重复说明，第四行有Full字样，代表JVM发生了Full GC，不过多了二个分区的收集，PSOldGen：老生代的回收前后空间大小及总空间；PSPermGen：持久代的回收前后空间大小和总空间。从第三行，可以看出老空间的使用率达到饱和，从而触发了FULL GC，但是很遗憾的是第五行后又接着发生了FULL GC，后面的都是一直在持续进行，但是系统一直不抛出OOM异常或者进程退出，导致这台机器服务进程一直存在，但是基本无法正常工作。</p>

<p>GC，无论Young GC还是Full GC，每次都会导致JVM STW(STOP WORLD)暂停用户的业务工作，来处理垃圾回收任务，短时间内无法响应用户请求，特别是大量的Full GC会导致系统响应速度降低，另外还有OOM的巨大风险。Young GC频繁，就算GC采用多线程回收方式，尽管回收的时候非常短，但是如果GC次数和频率很高，因此对应用的影响是不可忽视的。 Full GC 包括整个分区的垃圾回收，包括新生代、旧生代、持久代等。因此其回收成本高，应用也会暂停更长时间，无法及时响应用户的请求，所以需要特别注意这个种情况，一般来讲，排除主动的调用GC操作外，JVM会在以下几种情况发生Full GC。</p>

<ol>
<li><p>旧生代内存不足</p></li>
<li><p>持久代内存不足</p></li>
<li><p>统计新生代 GC晋升到旧生代的平均大小大于旧生代的剩余空间</p></li>
</ol>


<h2>解决</h2>

<p>知道发生的原因后，就可以使用JMAP -heap直接看一下JVM内存的对像值，或者使用JMAP -dump直接JVM的堆栈DUMP出来，使用MAT打开分析就行。如果这种现像发生之后，DUMP出来的文件会较大，有些会达到十多个G，因为一般不直接在工作机器上进行，需要把文件转发到其他的非线上服务并且内存足够的机器上分析，最后可以用MAT把分析后的文件打开即可，打开后，首页会给出可疑的建议对象实例，直接跳转到列表中，打开折叠细节即可看到真面目，里面包括了三十多万个对象，找相关的人员对根据业务需要，直接把不需要的实例在使用完后移除，其他几行的问题类似处理就即可。</p>

<h2>总结</h2>

<p>从上面GC的发生的情况来看，JVM一次次不停的努力的帮我们进行GC操作，直到把CPU全部占光，但是就是不直接抛出异常直接告诉我们内存不够了，感觉把我们带了到一个巨大的庞氏骗局，也许我们把JVM的内存加大，这个坑还将帮我们隐藏下去，如果程序设置了定时重启之类的操作，这个坑就永远发现不了。一般产品开发人员非常希望应用程序能在用户发觉之前发现这个问题，JVM无法判断出这个问题，因为也就不能帮我们抛出几乎OOM的异常，不过可以通过调整GCTimeLimit和GCHeapFreeLimit参数来重新定义何时抛出OutOfMemoryError错误。GCTimeLimit 的默认值是98%，也就是说如果98%时间都用花在GC上，则会抛出OutOfMemoryError。GCHeapFreeLimit 是回收后可用堆的大小。默认值是2%。当然最好的办法就是开发工程师开始就很清楚如何使用相关的容器类的正确用法，并且在上线前能经过充分的测试或运行。本文只是引用GC方面的一个具体的安全来说明GC是怎么骗人的，关于GC和JVM内存相关的细节如何及时的发现此类的问题，有机会再通过示例和大家探讨学习。</p>

<p>注：以上资料仅以HOTSPOT VM 1.7.65 版本参考。</p>

<p>参考资料：</p>

<p>JVM <a href="http://docs.oracle.com/javase/8/docs/technotes/guides/vm/gc-ergonomics.html">http://docs.oracle.com/javase/8/docs/technotes/guides/vm/gc-ergonomics.html</a></p>

<p>HotSpot JVM就是个庞氏骗局 <a href="http://it.deepinmind.com/gc/2014/04/01/hotspot-jvm-ponzi-scheme.html">http://it.deepinmind.com/gc/2014/04/01/hotspot-jvm-ponzi-scheme.html</a></p>

<p>Java内存泄露分析 <a href="http://doc.hz.netease.com/pages/viewpage.action?pageId=36468038">http://doc.hz.netease.com/pages/viewpage.action?pageId=36468038</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx源码分析之启动过程]]></title>
    <link href="http://superhj1987.github.io/blog/2014/09/24/nginx-bootstrap/"/>
    <updated>2014-09-24T17:38:57+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/09/24/nginx-bootstrap</id>
    <content type="html"><![CDATA[<p>nginx的启动过程代码主要分布在src/core以及src/os/unix目录下。启动流程的函数调用序列：main(src/core/nginx.c)→ngx_init_cycle(src/core/ngx_cycle.c)→ngx_master_process_cycle(src/os/)。nginx的启动过程就是围绕着这三个函数进行的。</p>

<p>main函数的处理过程总体上可以概括如下：</p>

<!--more-->


<ol>
<li>简单初始化一些数据接结构和模块：ngx_debug_init、ngx_strerror_init、ngx_time_init、ngx_regex_init、ngx_log_init、ngx_ssl_init等</li>
<li>获取并处理命令参数：ngx_get_options。</li>
<li><p>初始化ngx_cycle_t结构体变量init_cycle，设置其log、pool字段等。
 <pre>
 ngx_memzero(&amp;init_cycle, sizeof(ngx_cycle_t));
 init_cycle.log = log;
 ngx_cycle = &amp;init_cycle;</p>

<p> init_cycle.pool = ngx_create_pool(1024, log);
 if (init_cycle.pool == NULL) {
     return 1;
 }
</pre></p></li>
<li>保存参数，设置全局变量：ngx_argc ngx_os_argv ngx_argv ngx_environ</li>
<li>处理控制台命令行参数，设置init_cycle的字段。这些字段包括：conf_prefix、prefix（-p prefix）、conf_file(-c filename)、conf_param(-g directives)。此外，还设置init_cyle.log.log_level=NGX_LOG_INFO。</li>
<li>调用ngx_os_init来设置一些和操作系统相关的全局变量：ngx_page_size、ngx_cacheline_size、ngx_ncpu、ngx_max_sockets、ngx_inherited_nonblocking。</li>
<li>调用ngx_crc32_table_init初始化ngx_crc32_table_short。用于后续做crc校验。</li>
<li>调用ngx_add_inherited_sockets(&amp;init_cycle)→ngx_set_inherited_sockets，初始化init_cycle的listening字段（一个ngx_listening_t的数组）。</li>
<li>对所有模块进行计数
 <pre>
 ngx_max_module = 0;
 for (i = 0; ngx_modules[i]; i++) {
     ngx_modules[i]->index = ngx_max_module++;
 }
</pre></li>
<li>调用ngx_init_cycle进行模块的初始化，当解析配置文件错误时，退出程序。这个函数传入init_cycle然后返回一个新的ngx_cycle_t。</li>
<li>调用ngx_signal_process、ngx_init_signals处理信号。</li>
<li>在daemon模式下，调用ngx_daemon以守护进程的方式运行。这里可以在./configure的时候加入参数&ndash;with-debug，并在nginx.conf中配置:
<pre>
master_process  off; # 简化调试 此指令不得用于生产环境
daemon          off; # 简化调试 此指令可以用到生产环境
</pre>
可以取消守护进程模式以及master线程模型。</li>
<li>调用ngx_create_pidfile创建pid文件，把master进程的pid保存在里面。</li>
<li><p>根据进程模式来分别调用相应的函数
<pre>
if (ngx_process == NGX_PROCESS_SINGLE) {
    ngx_single_process_cycle(cycle);</p>

<p>} else {
    ngx_master_process_cycle(cycle);
}
</pre>
多进程的情况下，调用ngx_master_process_cycle。单进程的情况下调用ngx_single_process_cycle完成最后的启动工作。</p></li>
</ol>


<p>整个启动过程中一个关键的变量init_cycle，其数据结构ngx_cycle_t如下所示：</p>

<pre>
struct ngx_cycle_s {
    void                  ****conf_ctx;
    ngx_pool_t               *pool;

    ngx_log_t                *log;
    ngx_log_t                 new_log;

    ngx_connection_t        **files;
    ngx_connection_t         *free_connections;
    ngx_uint_t                free_connection_n;

    ngx_queue_t               reusable_connections_queue;

    ngx_array_t               listening;
    ngx_array_t               paths;
    ngx_list_t                open_files;
    ngx_list_t                shared_memory;

    ngx_uint_t                connection_n;
    ngx_uint_t                files_n;

    ngx_connection_t         *connections;
    ngx_event_t              *read_events;
    ngx_event_t              *write_events;

    ngx_cycle_t              *old_cycle;

    ngx_str_t                 conf_file;
    ngx_str_t                 conf_param;
    ngx_str_t                 conf_prefix;
    ngx_str_t                 prefix;
    ngx_str_t                 lock_file;
    ngx_str_t                 hostname;
};
</pre>


<p>它保存了一次启动过程需要的一些资源。</p>

<p>ngx_init_cycle函数的处理过程如下：</p>

<ol>
<li>调用ngx_timezone_update()、ngx_timeofday、ngx_time_update()来更新时区、时间等，做时间校准，用来创建定时器等。</li>
<li><p>创建pool,赋给一个新的cycle（ngx_cycle_t）。这个新的cycle的一些字段从旧的cycle传递过来，比如：log,conf_prefix,prefix,conf_file,conf_param。
 <pre>
 cycle->conf_prefix.len = old_cycle->conf_prefix.len;
 cycle->conf_prefix.data = ngx_pstrdup(pool, &amp;old_cycle->conf_prefix);
 if (cycle->conf_prefix.data == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }</p>

<p> cycle->prefix.len = old_cycle->prefix.len;
 cycle->prefix.data = ngx_pstrdup(pool, &amp;old_cycle->prefix);
 if (cycle->prefix.data == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }</p>

<p> cycle->conf_file.len = old_cycle->conf_file.len;
 cycle->conf_file.data = ngx_pnalloc(pool, old_cycle->conf_file.len + 1);
 if (cycle->conf_file.data == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }
 ngx_cpystrn(cycle->conf_file.data, old_cycle->conf_file.data,
             old_cycle->conf_file.len + 1);</p>

<p> cycle->conf_param.len = old_cycle->conf_param.len;
 cycle->conf_param.data = ngx_pstrdup(pool, &amp;old_cycle->conf_param);
 if (cycle->conf_param.data == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }
 </pre>
还有一些字段会首先判断old_cycle中是否存在，如果存在，则申请同样大小的空间，并初始化。这些字段如下：
 <pre>
 n = old_cycle->paths.nelts ? old_cycle->paths.nelts : 10;</p>

<p> //paths
 cycle->paths.elts = ngx_pcalloc(pool, n * sizeof(ngx_path_t *));
 if (cycle->paths.elts == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }</p>

<p> cycle->paths.nelts = 0;
 cycle->paths.size = sizeof(ngx_path_t *);
 cycle->paths.nalloc = n;
 cycle->paths.pool = pool;</p>

<p> //open_files
 if (old_cycle->open_files.part.nelts) {
     n = old_cycle->open_files.part.nelts;
     for (part = old_cycle->open_files.part.next; part; part = part->next) {
         n += part->nelts;
     }</p>

<p> } else {
     n = 20;
 }</p>

<p> //shared_memory
 if (old_cycle->shared_memory.part.nelts) {
     n = old_cycle->shared_memory.part.nelts;
     for (part = old_cycle->shared_memory.part.next; part; part = part->next)
     {
         n += part->nelts;
     }</p>

<p> } else {
     n = 1;
 }</p>

<p> //listening
 n = old_cycle->listening.nelts ? old_cycle->listening.nelts : 10;</p>

<p> cycle->listening.elts = ngx_pcalloc(pool, n * sizeof(ngx_listening_t));
 if (cycle->listening.elts == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }</p>

<p> cycle->listening.nelts = 0;
 cycle->listening.size = sizeof(ngx_listening_t);
 cycle->listening.nalloc = n;
 cycle->listening.pool = pool;
</pre></p>

<p>  此外，new_log.log_level重新赋值的为NGX_LOG_ERR；old_cycle为传递进来的cycle；hostname为gethostname;初始化resuable_connection_queue。</p>

<p>  这里有一个关键变量的初始化：conf_ctx。初始化为ngx_max_module个void *指针。说明其实所有模块的配置结构的指针。</p></li>
<li><p>调用所有模块的create_conf，返回的配置结构指针放到conf_ctx数组中，索引为ngx_modules[i]->index。</p></li>
<li>从命令行和配置文件读取配置更新到conf_ctx中。ngx_conf_param是读取命令行中的指令，ngx_conf_parse是把读取配置文件。ngx_conf_param最后也是通过调用ngx_cong_parse来读取配置的。ngx_conf_parse函数中有一个for循环，每次都调用ngx_conf_read_token取得一个配置指令，然后调用ngx_conf_handler来处理这条指令。ngx_conf_handler每次会遍历所有模块的指令集，查找这条配置指令并分析其合法性，如果正确则创建配置结构并把指针加入到cycle.conf_ctx中。
 遍历指令集的过程首先是遍历所有的核心类模块，若是 event类的指令，则会遍历到ngx_events_module，这个模块是属于核心类的，其钩子set又会嵌套调用ngx_conf_parse去遍历所有的event类模块，同样的，若是http类指令，则会遍历到ngx_http_module，该模块的钩子set进一步遍历所有的http类模块，mail类指令会遍历到ngx_mail_module，该模块的钩子进一步遍历到所有的mail类模块。要特别注意的是：这三个遍历过程中会在适当的时机调用event类模块、http类模块和mail类模块的创建配置和初始化配置的钩子。从这里可以看出，event、http、mail三类模块的钩子是配置中的指令驱动的。</li>
<li>调用core module的init_conf。</li>
<li><p>读取核心模块ngx_core_module的配置结构，调用ngx_create_pidfile创建pid文件。
 <pre>
 ccf = (ngx_core_conf_t *) ngx_get_conf(cycle->conf_ctx, ngx_core_module);
</pre></p>

<p>  这里代码中有一句注释：
  <pre>
   we do not create the pid file in the first ngx_init_cycle() call
   because we need to write the demonized process pid
</pre>
  当不是第一次初始化cycles时才会调用ngx_create_pidfile写入pid。</p></li>
<li>调用ngx_test_lockfile,ngx_create_paths并打开error_log文件复制给cycle->new_log.file。</li>
<li>遍历cycle的open_files.part.elts，打开每一个文件。open_files填充的文件数据是读取配置文件时写入的。</li>
<li>创建共享内存。这里和对open_files类似。先预分配空间，再填充数据。</li>
<li>处理listening sockets，遍历cycle->listening数组与old_cycle->listenning进行比较，设置cycle->listening的一些状态信息，调用ngx_open_listening_sockets启动所有监听socket，循环调用socket、bind、listen完成服务端监听监听socket的启动。并调用ngx_configure_listening_sockets配置监听socket,根据ngx_listening_t中的状态信息设置socket的读写缓存和TCP_DEFER_ACCEPT。</li>
<li>调用每个module的init_module。</li>
<li>关闭或者删除一些残留在old_cycle中的资源，首先释放不用的共性内存，关闭不使用的监听socket，再关闭不适用的打开文件。最后把old_cycle放入ngx_old_cycles。最后再设定一个定时器，定期回调ngx_cleaner_event清理ngx_old_cycles。周期设置为30000ms。</li>
</ol>


<p>接下来是进程的启动，包括master和worker进程。main函数最后调用ngx_master_process_cycle来启动master进程模式(这里对单进程模式不做讲述)。</p>

<ol>
<li>设置一些信号，如下：
 <pre>
 sigaddset(&amp;set, SIGCHLD);
 sigaddset(&amp;set, SIGALRM);
 sigaddset(&amp;set, SIGIO);
 sigaddset(&amp;set, SIGINT);
 sigaddset(&amp;set, ngx_signal_value(NGX_RECONFIGURE_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_REOPEN_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_NOACCEPT_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_TERMINATE_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_SHUTDOWN_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_CHANGEBIN_SIGNAL));
</pre></li>
<li>调用ngx_setproctitle设置进程标题：&#8221;master process&#8221; + ngx_argv[0&hellip;]</li>
<li>启动worker进程,数量为ccf->worker_processes。
 <pre>
 ngx_start_worker_processes(cycle, ccf->worker_processes,
                            NGX_PROCESS_RESPAWN);
</pre></li>
<li>启动文件cache管理进程。
 <pre>
 ngx_start_cache_manager_processes(cycle, 0);
</pre>
 这里的cahche在一些模块中是需要的，如fastcgi模块等,这些模块会把文件cache路径添加到cycle->paths中，文件cache管理进程会定期调用这些模块的文件cache处理钩子处理一下文件cache。</li>
<li>master主循环，主要是循环处理信号量。在循环过程中，判断相应的条件然后进入相应的处理。这里的相关标志位基本都是在信号处理函数中赋值的。
 <pre>
 for ( ;; ) {
  // delay用来设置等待worker退出的时间，master接收了退出信号后首先发送退出信号给worker，
  // 而worker退出需要一些时间
  if (delay) {
      delay = 2;
          &hellip;
      itv.it_interval.tv_sec = 0;
      itv.it_interval.tv_usec = 0;
      itv.it_value.tv_sec = delay / 1000;
      itv.it_value.tv_usec = (delay % 1000 ) * 1000;
      // 设置定时器
      if (setitimer(ITIMER_REAL, &amp;itv, NULL) == -1) {
          ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
          “setitimer() failed”);
      }
  }
  ngx_log_debug0(NGX_LOG_DEBUG_EVENT, cycle->log, 0, “sigsuspend”);
  // 挂起信号量，等待定时器
  sigsuspend(&amp;set);
  ngx_time_update(0, 0);
  ngx_log_debug0(NGX_LOG_DEBUG_EVENT, cycle->log, 0, “wake up”);
  // 收到了SIGCHLD信号，有worker退出（ngx_reap==1）
  if (ngx_reap) {
      ngx_reap = 0;
      ngx_log_debug0(NGX_LOG_DEBUG_EVENT, cycle->log, 0, “reap children”);
      // 处理所有worker，如果有worker异常退出则重启这个worker，如果所有worker都退出
      // 返回0赋值给live
      live = ngx_reap_children(cycle);
  }
  // 如果worker都已经退出，
  // 并且收到了NGX_CMD_TERMINATE命令或者SIGTERM信号或者SIGINT信号(ngx_terminate=1)
  // 或者NGX_CMD_QUIT命令或者SIGQUIT信号(ngx_quit=1)，则master退出
  if (!live &amp;&amp; (ngx_terminate || ngx_quit)) {
      ngx_master_process_exit(cycle);
  }
  // 收到了NGX_CMD_TERMINATE命令或者SIGTERM信号或者SIGINT信号，
  // 通知所有worker退出，并且等待worker退出
  if (ngx_terminate) {
      // 设置延时
      if (delay == 0) {
          delay = 50;
      }
      if (delay > 1000) {
          // 延时已到，给所有worker发送SIGKILL信号，强制杀死worker
          ngx_signal_worker_processes(cycle, SIGKILL);
      } else {
          // 给所有worker发送SIGTERM信号，通知worker退出
          ngx_signal_worker_processes(cycle,
          ngx_signal_value(NGX_TERMINATE_SIGNAL));
      }
      continue;
  }
  // 收到了NGX_CMD_QUIT命令或者SIGQUIT信号
  if (ngx_quit) {
      // 给所有worker发送SIGQUIT信号
      ngx_signal_worker_processes(cycle,
      ngx_signal_value(NGX_SHUTDOWN_SIGNAL));
      // 关闭所有监听的socket
      ls = cycle->listening.elts;
      for (n = 0; n &lt; cycle->listening.nelts; n++) {
          if (ngx_close_socket(ls[n].fd) == -1) {
              ngx_log_error(NGX_LOG_EMERG, cycle->log, ngx_socket_errno,
                  ngx_close_socket_n ” %V failed”,&amp;ls[n].addr_text);
          }
      }
      cycle->listening.nelts = 0;
  continue;
  }
  // 收到了SIGHUP信号
  if (ngx_reconfigure) {
      ngx_reconfigure = 0;
      // 代码已经被替换，重启worker，不需要重新初始化配置
      if (ngx_new_binary) {
          ngx_start_worker_processes(cycle, ccf->worker_processes,
              NGX_PROCESS_RESPAWN);
          ngx_start_cache_manager_processes(cycle, 0);
          ngx_noaccepting = 0;
          continue;
      }
      ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, “reconfiguring”);
      // 重新初始化配置
      cycle = ngx_init_cycle(cycle);
      if (cycle == NULL) {
          cycle = (ngx_cycle_t ) ngx_cycle;
          continue;
      }
      // 重启worker
      ngx_cycle = cycle;
      ccf = (ngx_core_conf_t *) ngx_get_conf(cycle->conf_ctx,
      ngx_core_module);
      ngx_start_worker_processes(cycle, ccf->worker_processes,
          NGX_PROCESS_JUST_RESPAWN);
      ngx_start_cache_manager_processes(cycle, 1);
      live = 1;
      ngx_signal_worker_processes(cycle,
          ngx_signal_value(NGX_SHUTDOWN_SIGNAL));
  }
  // 当ngx_noaccepting=1的时候会把ngx_restart设为1，重启worker
  if (ngx_restart) {
      ngx_restart = 0;
      ngx_start_worker_processes(cycle, ccf->worker_processes,
          NGX_PROCESS_RESPAWN);
      ngx_start_cache_manager_processes(cycle, 0);
      live = 1;
  }
  // 收到SIGUSR1信号，重新打开log文件
  if (ngx_reopen) {
      ngx_reopen = 0;
      ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, “reopening logs”);
      ngx_reopen_files(cycle, ccf->user);
      ngx_signal_worker_processes(cycle,
      ngx_signal_value(NGX_REOPEN_SIGNAL));
  }
  // 收到SIGUSR2信号，热代码替换
  if (ngx_change_binary) {
      ngx_change_binary = 0;
      ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, “changing binary”);
      // 调用execve执行新的代码
      ngx_new_binary = ngx_exec_new_binary(cycle, ngx_argv);
  }
  // 收到SIGWINCH信号，不再接收请求，worker退出，master不退出
  if (ngx_noaccept) {
      ngx_noaccept = 0;
      ngx_noaccepting = 1;
      ngx_signal_worker_processes(cycle,
      ngx_signal_value(NGX_SHUTDOWN_SIGNAL));
  }
}
</pre>
信号处理函数是在main函数中进行的初始化：ngx_init_signals(cycle->log)。其中的signal handler代码如下所示：</li>
</ol>


<pre>
void
ngx_signal_handler(int signo)
{
    char            *action;
    ngx_int_t        ignore;
    ngx_err_t        err;
    ngx_signal_t    *sig;

    ignore = 0;

    err = ngx_errno;

    for (sig = signals; sig->signo != 0; sig++) {
        if (sig->signo == signo) {
            break;
        }
    }

    ngx_time_sigsafe_update();

    action = "";

    switch (ngx_process) {

    case NGX_PROCESS_MASTER:
    case NGX_PROCESS_SINGLE:
        switch (signo) {

        case ngx_signal_value(NGX_SHUTDOWN_SIGNAL):
            ngx_quit = 1;
            action = ", shutting down";
            break;

        case ngx_signal_value(NGX_TERMINATE_SIGNAL):
        case SIGINT:
            ngx_terminate = 1;
            action = ", exiting";
            break;

        case ngx_signal_value(NGX_NOACCEPT_SIGNAL):
            if (ngx_daemonized) {
                ngx_noaccept = 1;
                action = ", stop accepting connections";
            }
            break;

        case ngx_signal_value(NGX_RECONFIGURE_SIGNAL):
            ngx_reconfigure = 1;
            action = ", reconfiguring";
            break;

        case ngx_signal_value(NGX_REOPEN_SIGNAL):
            ngx_reopen = 1;
            action = ", reopening logs";
            break;

        case ngx_signal_value(NGX_CHANGEBIN_SIGNAL):
            if (getppid() > 1 || ngx_new_binary > 0) {

                /*
                 * Ignore the signal in the new binary if its parent is
                 * not the init process, i.e. the old binary's process
                 * is still running.  Or ignore the signal in the old binary's
                 * process if the new binary's process is already running.
                 */

                action = ", ignoring";
                ignore = 1;
                break;
            }

            ngx_change_binary = 1;
            action = ", changing binary";
            break;

        case SIGALRM:
            ngx_sigalrm = 1;
            break;

        case SIGIO:
            ngx_sigio = 1;
            break;

        case SIGCHLD:
            ngx_reap = 1;
            break;
        }

        break;

    case NGX_PROCESS_WORKER:
    case NGX_PROCESS_HELPER:
        switch (signo) {

        case ngx_signal_value(NGX_NOACCEPT_SIGNAL):
            if (!ngx_daemonized) {
                break;
            }
            ngx_debug_quit = 1;
        case ngx_signal_value(NGX_SHUTDOWN_SIGNAL):
            ngx_quit = 1;
            action = ", shutting down";
            break;

        case ngx_signal_value(NGX_TERMINATE_SIGNAL):
        case SIGINT:
            ngx_terminate = 1;
            action = ", exiting";
            break;

        case ngx_signal_value(NGX_REOPEN_SIGNAL):
            ngx_reopen = 1;
            action = ", reopening logs";
            break;

        case ngx_signal_value(NGX_RECONFIGURE_SIGNAL):
        case ngx_signal_value(NGX_CHANGEBIN_SIGNAL):
        case SIGIO:
            action = ", ignoring";
            break;
        }

        break;
    }

    ngx_log_error(NGX_LOG_NOTICE, ngx_cycle->log, 0,
                  "signal %d (%s) received%s", signo, sig->signame, action);

    if (ignore) {
        ngx_log_error(NGX_LOG_CRIT, ngx_cycle->log, 0,
                      "the changing binary signal is ignored: "
                      "you should shutdown or terminate "
                      "before either old or new binary's process");
    }

    if (signo == SIGCHLD) {
        ngx_process_get_status();
    }

    ngx_set_errno(err);
}
</pre>


<p>创建worker子进程的函数是ngx_start_worker_processes。</p>

<pre>
static void
ngx_start_worker_processes(ngx_cycle_t *cycle, ngx_int_t n, ngx_int_t type)
{
    ngx_int_t      i;
    ngx_channel_t  ch;

    ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "start worker processes");

    ch.command = NGX_CMD_OPEN_CHANNEL; //传递给其他worker子进程的命令：打开通信管道

    //创建n个worker进程
    for (i = 0; i < n; i++) {

        //创建worker子进程并初始化相关资源和属性
        ngx_spawn_process(cycle, ngx_worker_process_cycle,
                          (void *) (intptr_t) i, "worker process", type);

        /*master父进程向所有已经创建的worker子进程（不包括本子进程）广播消息
        包括当前worker子进程的进程id、在进程表中的位置和管道句柄，这些worker子进程收到消息后，会更新这些消息到自己进程空间的进程表，以此实现两个worke子进程之间的通信。
        */
        ch.pid = ngx_processes[ngx_process_slot].pid;
        ch.slot = ngx_process_slot;
        ch.fd = ngx_processes[ngx_process_slot].channel[0];

        ngx_pass_open_channel(cycle, &ch);
    }
}
</pre>


<p>这里ngx_pass_open_channel，即遍历所有worker进程，跳过自己和异常的worker，把消息发送给各个worker进程。worker进程的管道可读事件捕捉函数是ngx_channel_handler(ngx_event_t *ev)，在这个函数中，会读取message，然后解析，并根据不同给的命令做不同的处理。</p>

<p>这里有一个关键的函数是ngx_pid_t ngx_spawn_process(ngx_cycle_t <em>cycle, ngx_spawn_proc_pt proc, void </em>data,char *name, ngx_int_t respawn)。proc是子进程的执行函数，data是其参数，name是进程名。</p>

<p>这个函数的任务：</p>

<ol>
<li>有一个ngx_processes全局数组，包含了所有的子进程，这里会fork出子进程并放入相应的位置，并设置这个进程的相关属性。</li>
<li>创建socketpair，并设置相关属性</li>
<li>子啊子进程中执行传递进来的函数。</li>
</ol>


<pre>
u_long     on;
ngx_pid_t  pid;
ngx_int_t  s; //fork的子进程在ngx_processes中的位置

//如果传递进来的respawn>0，说明是要替换进程ngx_processes[respawn]，可安全重用该进程表项。
if (respawn >= 0) {
   s = respawn;
} else {
   遍历进程表，找到空闲的slot
   for (s = 0; s < ngx_last_process; s++) {
        if (ngx_processes[s].pid == -1) {
                break;
            }
        }

        //达到最大进程限制报错
        if (s == NGX_MAX_PROCESSES) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, 0,
                          "no more than %d processes can be spawned",
                          NGX_MAX_PROCESSES);
            return NGX_INVALID_PID;
        }
    }
</pre>


<p></p>

<p>接下来创建一对socketpair句柄，然后初始化相关属性。</p>

<pre>
    if (respawn != NGX_PROCESS_DETACHED) { //NGX_PROCESS_DETACHED是热代码替换

        /* Solaris 9 still has no AF_LOCAL */

        //建立socketpair
        if (socketpair(AF_UNIX, SOCK_STREAM, 0, ngx_processes[s].channel) == -1)
        {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "socketpair() failed while spawning \"%s\"", name);
            return NGX_INVALID_PID;
        }

        。。。

        //设置非阻塞模式
        if (ngx_nonblocking(ngx_processes[s].channel[0]) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          ngx_nonblocking_n " failed while spawning \"%s\"",
                          name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        if (ngx_nonblocking(ngx_processes[s].channel[1]) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          ngx_nonblocking_n " failed while spawning \"%s\"",
                          name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        //打开异步模式
        on = 1;
        if (ioctl(ngx_processes[s].channel[0], FIOASYNC, &on) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "ioctl(FIOASYNC) failed while spawning \"%s\"", name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        //设置异步io所有者
        if (fcntl(ngx_processes[s].channel[0], F_SETOWN, ngx_pid) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "fcntl(F_SETOWN) failed while spawning \"%s\"", name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        //当exec后关闭句柄
        if (fcntl(ngx_processes[s].channel[0], F_SETFD, FD_CLOEXEC) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "fcntl(FD_CLOEXEC) failed while spawning \"%s\"",
                           name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        if (fcntl(ngx_processes[s].channel[1], F_SETFD, FD_CLOEXEC) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "fcntl(FD_CLOEXEC) failed while spawning \"%s\"",
                           name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        //设置当前子进程的句柄
        ngx_channel = ngx_processes[s].channel[1];

    } else {
        ngx_processes[s].channel[0] = -1;
        ngx_processes[s].channel[1] = -1;
    }
</pre>


<p>接下来就是fork子进程，并设置进程相关参数。</p>

<pre>
    //设置进程在进程表中的slot
    ngx_process_slot = s;

    pid = fork();

    switch (pid) {

    case -1:
        ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                      "fork() failed while spawning \"%s\"", name);
        ngx_close_channel(ngx_processes[s].channel, cycle->log);
        return NGX_INVALID_PID;

    case 0:
        //子进程，执行传递进来的子进程函数
        ngx_pid = ngx_getpid();
        proc(cycle, data);
        break;

    default:
        break;
    }

    ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "start %s %P", name, pid);

    ngx_processes[s].pid = pid;
    ngx_processes[s].exited = 0;

    if (respawn >= 0) { //使用原来的子进程即可
        return pid;
    }

    //初始化进程结构
    ngx_processes[s].proc = proc;
    ngx_processes[s].data = data;
    ngx_processes[s].name = name;
    ngx_processes[s].exiting = 0;

    switch (respawn) {

    case NGX_PROCESS_NORESPAWN:
        ngx_processes[s].respawn = 0;
        ngx_processes[s].just_spawn = 0;
        ngx_processes[s].detached = 0;
        break;

    case NGX_PROCESS_JUST_SPAWN:
        ngx_processes[s].respawn = 0;
        ngx_processes[s].just_spawn = 1;
        ngx_processes[s].detached = 0;
        break;

    case NGX_PROCESS_RESPAWN:
        ngx_processes[s].respawn = 1;
        ngx_processes[s].just_spawn = 0;
        ngx_processes[s].detached = 0;
        break;

    case NGX_PROCESS_JUST_RESPAWN:
        ngx_processes[s].respawn = 1;
        ngx_processes[s].just_spawn = 1;
        ngx_processes[s].detached = 0;
        break;

    case NGX_PROCESS_DETACHED:
        ngx_processes[s].respawn = 0;
        ngx_processes[s].just_spawn = 0;
        ngx_processes[s].detached = 1;
        break;
    }

    if (s == ngx_last_process) {
        ngx_last_process++;
    }   
</pre>


<p>最后看一下，worker进程执行的函数static void
ngx_worker_process_cycle(ngx_cycle_t <em>cycle, void </em>data)。</p>

<ol>
<li><p>调用ngx_worker_process_init初始化；</p>

<ul>
<li>设置ngx_process=NGX_PROCESS_WORKER</li>
<li>全局性的设置，包括执行环境、优先级、限制、setgid、setuid、信号初始化</li>
<li>调用所有模块的init_process钩子</li>
<li>关闭不使用的管道句柄，关闭当前的worker子进程的channel[0]句柄和继承来的其他进程的channel[1]句柄。使用其他进程的channel[0]句柄发送消息，使用本进程的channel[1]句柄监听事件。</li>
</ul>
</li>
<li><p>进行线程相关的操作。（如果有线程模式）</p></li>
<li>主循环处理各种状态，类似master进程的主循环。</li>
</ol>


<pre>   
for ( ;; ) {

        if (ngx_exiting) { //退出状态，关闭所有连接

            c = cycle->connections;

            for (i = 0; i < cycle->connection_n; i++) {

                /* THREAD: lock */

                if (c[i].fd != -1 && c[i].idle) {
                    c[i].close = 1;
                    c[i].read->handler(c[i].read);
                }
            }

            if (ngx_event_timer_rbtree.root == ngx_event_timer_rbtree.sentinel)
            {
                ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "exiting");

                ngx_worker_process_exit(cycle);
            }
        }

        ngx_log_debug0(NGX_LOG_DEBUG_EVENT, cycle->log, 0, "worker cycle");

        ngx_process_events_and_timers(cycle); //处理事件和计时

        if (ngx_terminate) { //收到NGX_CMD_TERMINATE命令，清理进城后退出，并调用所有模块的exit_process钩子。
            ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "exiting");

            ngx_worker_process_exit(cycle);
        }

        if (ngx_quit) {
            ngx_quit = 0;
            ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0,
                          "gracefully shutting down");
            ngx_setproctitle("worker process is shutting down");

            if (!ngx_exiting) {
                //关闭监听socket，并设置退出状态
                ngx_close_listening_sockets(cycle);
                ngx_exiting = 1;
            }
        }

        if (ngx_reopen) { //重新打开log
            ngx_reopen = 0;
            ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "reopening logs");
            ngx_reopen_files(cycle, -1);
        }
    }
</pre>


<p>总结一下，nginx的启动过程可以划分为两个部分，</p>

<ol>
<li>读取配置文件并设置全局的配置结构信息以及每个模块的配置结构信息，调用模块的 create_conf钩子和init_conf钩子。</li>
<li>创建进程和进程间通信机制，master进程负责管理各个worker子进程，通过 socketpair向子进程发送消息，各个worker子进程服务利用事件机制处理请求，通过socketpair与其他子进程通信（发送消息或者接收消息），进程启动的各个适当时机会调用模块的init_module钩子、init_process钩子、exit_process钩子和 exit_master钩子，init_master钩子没有被调用过。nginx的worker子进程继承了父进程的全局变量之后，子进程和父进程就会独立处理这些全局变量，有些全局量需要在父子进程之间同步就要通过通信方式了，比如 ngx_processes（进程表）的同步。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx负载均衡]]></title>
    <link href="http://superhj1987.github.io/blog/2014/08/27/nginx-loabbalance/"/>
    <updated>2014-08-27T14:32:50+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/08/27/nginx-loabbalance</id>
    <content type="html"><![CDATA[<h2>一、特点</h2>

<h3>1.1 应用情况</h3>

<p>Nginx做为一个强大的Web服务器软件，具有高性能、高并发性和低内存占用的特点。此外，其也能够提供强大的反向代理功能。俄罗斯大约有超过20%的虚拟主机采用Nginx作为反向代理服务器,在国内也有腾讯、新浪、网易等多家网站在使用Nginx作为反向代理服务器。据Netcraft统计，世界上最繁忙的网站中有11.48%使用Nginx作为其服务器或者代理服务器。基于反向代理的功能，Nginx作为负载均衡主要有以下几点理由：</p>

<ol>
<li><p>高并发连接</p></li>
<li><p>内存消耗少</p></li>
<li><p>配置文件非常简单</p></li>
<li><p>成本低廉</p></li>
<li><p>支持Rewrite重写规则</p></li>
<li><p>内置的健康检查功能</p></li>
<li><p>节省带宽</p></li>
<li><p>稳定性高</p></li>
</ol>


<!--more-->


<h3>1.2 架构</h3>

<p><img src="http://superhj1987.github.io/images/ngx_arch.jpg" alt="" /></p>

<p>nginx在启动后，会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程。工作进程以非特权用户运行。</p>

<p>master进程主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程。</p>

<p>worker进程则是处理基本的网络事件。多个worker进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。</p>

<p>开发模型：epoll和kqueue。</p>

<p>支持的事件机制：kqueue、epoll、rt signals、/dev/poll 、event ports、select以及poll。</p>

<p>支持的kqueue特性包括EV_CLEAR、EV_DISABLE、NOTE_LOWAT、EV_EOF，可用数据的数量，错误代码.</p>

<p>支持sendfile、sendfile64和sendfilev;文件AIO；DIRECTIO;支持Accept-filters和TCP_DEFER_ACCEP.</p>

<h3>1.3 性能</h3>

<p>Nginx的高并发，官方测试支持5万并发连接。实际生产环境能到2-3万并发连接数。10000个非活跃的HTTP keep-alive 连接仅占用约2.5MB内存。三万并发连接下，10个Nginx进程，消耗内存150M。淘宝tengine团队说测试结果是“24G内存机器上，处理并发请求可达200万”。</p>

<h2>二、负载均衡</h2>

<h3>2.1 协议支持</h3>

<p>Nginx工作在网络的7层，可以针对http应用本身来做分流策略。支持七层HTTP、HTTPS协议的负载均衡。对四层协议的支持需要第三方插件-yaoweibin的ngx_tcp_proxy_module实现了tcp upstream。</p>

<p><a href="https://github.com/yaoweibin/nginx_tcp_proxy_module">https://github.com/yaoweibin/nginx_tcp_proxy_module</a></p>

<p>此外，nginx本身也逐渐在完善对其他协议的支持：</p>

<ul>
<li><p>Nginx 1.3.13 开发版支持WebSocket代理。</p></li>
<li><p>Nginx 1.3.15开发版支持SPDY。</p></li>
</ul>


<h3>2.2 均衡策略</h3>

<p>nginx的负载均衡策略可以划分为两大类：内置策略和扩展策略。内置策略包含加权轮询和ip hash，在默认情况下这两种策略会编译进nginx内核，只需在nginx配置中指明参数即可。扩展策略有很多，如fair、通用hash、consistent hash等，默认不编译进nginx内核。</p>

<ol>
<li><p>加权轮询（weighted round robin）</p>

<p> 轮询的原理很简单，首先我们介绍一下轮询的基本流程。如下是处理一次请求的流程图：</p>

<p> <img src="http://superhj1987.github.io/images/ngx_wr_process.jpg" alt="" /></p>

<p> 图中有两点需要注意，第一，如果可以把加权轮询算法分为先深搜索和先广搜索，那么nginx采用的是先深搜索算法，即将首先将请求都分给高权重的机器，直到该机器的权值降到了比其他机器低，才开始将请求分给下一个高权重的机器；第二，当所有后端机器都down掉时，nginx会立即将所有机器的标志位清成初始状态，以避免造成所有的机器都处在timeout的状态，从而导致整个前端被夯住。</p></li>
<li><p>ip hash</p>

<p> ip hash是nginx内置的另一个负载均衡的策略，流程和轮询很类似，只是其中的算法和具体的策略有些变化，如下图所示：</p>

<p> <img src="http://superhj1987.github.io/images/ngx_iphash_process.jpg" alt="" /></p>

<p> ip hash算法的核心实现如下：</p>

<p> <pre>
 for(i = 0;i &lt; 3;i++){
     hash = (hash * 113 + iphp->addr[i]) % 6271;
 }</p>

<p> p = hash % iphp->rrp.peers->number;
 </pre></p>

<p> 从代码中可以看出，hash值既与ip有关又与后端机器的数量有关。经过测试，上述算法可以连续产生1045个互异的value，这是该算法的硬限制。对此nginx使用了保护机制，当经过20次hash仍然找不到可用的机器时，算法退化成轮询。因此，从本质上说，ip hash算法是一种变相的轮询算法，如果两个ip的初始hash值恰好相同，那么来自这两个ip的请求将永远落在同一台服务器上，这为均衡性埋下了很深的隐患。</p></li>
<li><p>fair</p>

<p> fair策略是扩展策略，默认不被编译进nginx内核。其原理是根据后端服务器的响应时间判断负载情况，从中选出负载最轻的机器进行分流。这种策略具有很强的自适应性，但是实际的网络环境往往不是那么简单，因此要慎用。</p></li>
<li><p>通用hash、一致性hash</p>

<p> 这两种也是扩展策略，在具体的实现上有些差别，通用hash比较简单，可以以nginx内置的变量为key进行hash，一致性hash采用了nginx内置的一致性hash环，可以支持memcache。</p></li>
</ol>


<h3>2.2 配置示例</h3>

<ol>
<li><p>HTTP</p>

<pre><code> http {

     upstream  www.s135.com  {

       server   192.168.1.2:80;

       server   192.168.1.3:80;

     }



     server{

       listen  80;

       server_name  www.s135.com;



       location / {

                proxy_pass        http://www.s135.com;

                proxy_set_header   Host             $host;

                proxy_set_header   X-Real-IP        $remote_addr;

                proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;

       }



       location /nginx_status {

                stub_status on;

                access_log off;

                allow 192.168.1.1;#设置为可访问该状态信息的ip

                deny all;

       }

     }

 }
</code></pre></li>
<li><p>TCP - ngx_tcp_proxy_module</p>

<pre><code> tcp {

     upstream cluster {

         # simple round-robin

         server 192.168.0.1:80;

         server 192.168.0.2:80;



         check interval=3000 rise=2 fall=5 timeout=1000;



         #check interval=3000 rise=2 fall=5 timeout=1000 type=ssl_hello;



         #check interval=3000 rise=2 fall=5 timeout=1000 type=http;

         #check_http_send "GET / HTTP/1.0\r\n\r\n";

         #check_http_expect_alive http_2xx http_3xx;

     }



     server {

         listen 8888;

         proxy_pass cluster;

     }

 }
</code></pre></li>
</ol>


<h2>三、动态负载均衡</h2>

<h3>3.1 自身监控</h3>

<p>内置了对后端服务器的健康检查功能。如果Nginx proxy后端的某台服务器宕机了，会把返回错误的请求重新提交到另一个节点，不会影响前端访问。它没有独立的健康检查模块，而是使用业务请求作为健康检查，这省去了独立健康检查线程，这是好处。坏处是，当业务复杂时，可能出现误判，例如后端响应超时，这可能是后端宕机，也可能是某个业务请求自身出现问题，跟后端无关。</p>

<h3>3.2 可扩展性</h3>

<p>Nginx属于典型的微内核设计，其内核非常简洁和优雅，同时具有非常高的可扩展性。如下图所示：</p>

<p><img src="http://superhj1987.github.io/images/ngx_micro.jpg" alt="" /></p>

<p>Nginx是纯C语言的实现，其可扩展性在于其模块化的设计。目前，Nginx已经有很多的第三方模块，大大扩展了自身的功能。nginx_lua_module可以将Lua语言嵌入到Nginx配置中，从而利用Lua极大增强了Nginx本身的编程能力，甚至可以不用配合其它脚本语言（如PHP或Python等），只靠Nginx本身就可以实现复杂业务的处理。</p>

<h3>3.3 配置修改</h3>

<p>nginx的配置架构如下图所示：</p>

<p><img src="http://superhj1987.github.io/images/ngx_config.jpg" alt="" /></p>

<p>Nginx支持热部署，几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。能够在不间断服务的情况下，对软件版本进行进行升级。Nginx的配置文件非常简单，风格跟程序一样通俗易懂，能够支持perl语法。使用nginx –s reload可以在运行时加载配置文件，便于运行时扩容/减容。重新加载配置时，master进程发送命令给当前正在运行的worker进程worker进程接到命令后会在处理完当前任务后退出。同时，master进程会启动新的worker进程来接管工作。</p>

<h2>四、优势和劣势</h2>

<h3>4.1 优势</h3>

<ol>
<li><p>可以很好地进行http 的头处理</p></li>
<li><p>对http协议以及https的良好支持</p></li>
<li><p>有足够的第三方插件供使用</p></li>
<li><p>支持热部署，更改后端是平滑的</p></li>
</ol>


<h3>4.2 劣势</h3>

<ol>
<li><p>缺少对session的支持</p></li>
<li><p>对四层tcp的支持不够好</p></li>
<li><p>post请求写文件系统，造成500 error</p></li>
<li><p>缺乏主动的后端服务器健康监测</p></li>
<li><p>默认的监控界面统计信息不全</p></li>
</ol>


<h2>五、Tengine</h2>

<h3>5.1 特性</h3>

<ol>
<li><p>继承Nginx-1.2.9的所有特性，100%兼容Nginx的配置；</p></li>
<li><p>动态模块加载（DSO）支持。加入一个模块不再需要重新编译整个Tengine；</p></li>
<li><p>输入过滤器机制支持。通过使用这种机制Web应用防火墙的编写更为方便；</p></li>
<li><p>动态脚本语言Lua支持。扩展功能非常高效简单；</p></li>
<li><p>支持管道（pipe）和syslog（本地和远端）形式的日志以及日志抽样；</p></li>
<li><p>组合多个CSS、JavaScript文件的访问请求变成一个请求；</p></li>
<li><p>更加强大的负载均衡能力，包括一致性hash模块、会话保持模块，还可以对后端的服务器进行主动健康检查，根据服务器状态自动上线下线；</p></li>
<li><p>自动根据CPU数目设置进程个数和绑定CPU亲缘性；</p></li>
<li><p>监控系统的负载和资源占用从而对系统进行保护；</p></li>
<li><p>显示对运维人员更友好的出错信息，便于定位出错机器；</p></li>
<li><p>更强大的防攻击（访问速度限制）模块；</p></li>
<li><p>更方便的命令行参数，如列出编译的模块列表、支持的指令等；</p></li>
<li><p>可以根据访问文件类型设置过期时间；</p></li>
</ol>


<h3>5.2 负载均衡</h3>

<p>负载均衡方面，Tengine主要有以下几个特点，基本上弥补了 nginx在负载均衡方面的欠缺：</p>

<ol>
<li><p>支持一致性Hash模块</p></li>
<li><p>会话保持模块</p></li>
<li><p>对后端服务器的主动健康检查。</p></li>
<li><p>增加了请求体不缓存到磁盘的机制</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[async源码分析]]></title>
    <link href="http://superhj1987.github.io/blog/2014/08/22/node-async-analysis/"/>
    <updated>2014-08-22T16:08:28+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/08/22/node-async-analysis</id>
    <content type="html"><![CDATA[<p>最近在使用到node js的async库的时候，对其waterfall的实现感觉很奇妙，于是看了一下源码：</p>

<pre>
    async.waterfall = function (tasks, callback) {
        callback = callback || function () {};
        if (!_isArray(tasks)) {
          var err = new Error('First argument to waterfall must be an array of functions');
          return callback(err);
        }
        if (!tasks.length) {
            return callback();
        }
        var wrapIterator = function (iterator) {
            return function (err) {
                if (err) {
                    callback.apply(null, arguments);
                    callback = function () {};
                }
                else {
                    var args = Array.prototype.slice.call(arguments, 1);
                    var next = iterator.next();
                    if (next) {
                        args.push(wrapIterator(next));
                    }
                    else {
                        args.push(callback);
                    }
                    async.setImmediate(function () {
                        iterator.apply(null, args);
                    });
                }
            };
        };
        wrapIterator(async.iterator(tasks))();
    };
 </pre>


<p></p>

<!-- more -->


<p></p>

<p>开始先对参数进行了检查，判断tasks是否是一个function数组。然后使用了一个内部函数wrapIterator封装了实现。wrapIterator的参数带出了async.iterator函数：</p>

<pre> 
    async.iterator = function (tasks) {
        var makeCallback = function (index) {
            var fn = function () {
                if (tasks.length) {
                    tasks[index].apply(null, arguments);
                }
                return fn.next(); //这个地方有必要么？？？
            };
            fn.next = function () {
                return (index < tasks.length - 1) ? makeCallback(index + 1): null;
            };
            return fn;
        };
        return makeCallback(0);
    };
</pre>


<p> <br/>
这个函数，其主要实现是其内部函数makeCallback。其功能就是迭代tasks，封装其中的每一个function,让其执行后返回下一个function,以此实现迭代。</p>

<p>接下来，再回到wrapIterator，此function是对iterator的封装。执行后返回的是一个匿名function。其明确的参数只有一个err。当err不为空的时候，直接执行callback function。否则从index为1开始取出参数列表，并把iterator的下一个function包装之后push到args中（如果没有下一个function了则push回调函数）。接下来，则执行当前的iterator，执行的参数是下一个iterator function（作为这一步的回调函数）以及参数（如果当前的iterator被调用时传递了其他参数）。这样在当前iterator中回调下一个iterator，依次迭代执行，直至执行完所有function和callback。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[技术的成长]]></title>
    <link href="http://superhj1987.github.io/blog/2014/08/14/grow-up-in-tech/"/>
    <updated>2014-08-14T16:38:01+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/08/14/grow-up-in-tech</id>
    <content type="html"><![CDATA[<p>最近因为一件事情，让自己突然对自己产生了巨大的怀疑。工作一年多，仔细想想貌似真的只是在积累项目经验，而在技术深度上却一直停滞不前。这其中确也有因为之前做产品没有太多空闲时间的缘故，但更多的还是自己一直不得章法。对nginx源码的学习，一拖再拖，想成为这方面的专家却也不知道努力挤出时间或者说没有好的方法让自己合理安排出时间。</p>

<p>毕业的时候自己选择这里，就是想安心的做技术，以求在技术上得到长足的进步。现在却发现在做着一些没那么有技术含量的东西，像某人所说：上学的时候给我一定的时间也能够做出来。虽然我觉得上学的时候，大部分进公司做的东西也能做出来（除非是那种需要基于一定的环境像大数据、高并发才能做的）。但其实我明白，那句话的意思主要强调的是应该潜心去研究一门技术，比如hadoop、storm等，成为一个领域的专家。这也的确是自己的软肋，也的确该好好加强。</p>

<!--more-->


<p>这也牵扯到了技术的广度和深度的问题。这两个的优先级不能一味的说谁优谁劣，技术研究的人肯定倾向于去拓展技术的深度，而面向产品、架构的人应该关心广度多一些吧。当然如果不去精通一门技术，广度却也是无法拓展的。所谓技术上的成长，抛开技术的深度和广度来言，我觉得还是主要指技术思维的拓展和进步。技术领域的很多东西都是触类旁通的，只要你有好的逻辑思维和方法论，那么对于很多东西都是能很快上手直至掌握、运用、精通的。</p>

<p>还有一个上手能力和学习能力的问题，上手能力指的是你掌握然后使用，而学习能力应该是理解并能改进。这两个概念以前没去区分过，现在想想却也是有很大不同的。上手容易，精通难。所谓学习能力，是上手之后能够快速地吸收为自己的东西，能够从自己的角度看待问题，甚至提出自己的改进。很多人接触一个新的技术的确能够很快地上手去运用，但是却很少会深入地去学习这种技术的原理、运行机制之类的东西。这也是优秀开发人员和一般开发人员本质的区别。
学习技术，更是要学习其精髓而非皮毛，知其然更要知其所以然。</p>

<p>其实，总结来看，作为一个技术人，追求的技术上的长进，从多个维度来看，关键的还是项目经验和思维能力的同步提高。当然，如果对某一个领域能深入研究从而成为专家那也是锦上添花的事情。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx源码分析之基本数据结构]]></title>
    <link href="http://superhj1987.github.io/blog/2014/07/25/nginx-data-structure/"/>
    <updated>2014-07-25T17:08:02+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/07/25/nginx-data-structure</id>
    <content type="html"><![CDATA[<h3>引言</h3>

<p>nginx实现中有很多结构体，一般命名为ngx_xxx_t。这些结构体分散在许多头文件中。src/core/ngx_core.h中把几乎所有的头文件都集合起来。也因此造成了nginx各部分源代码的耦合。但实际上nginx各个部分逻辑划分还是很明确的，整体上是一种松散的结构。</p>

<p>作者之所以重复造了这些轮子，无非是为了追求高效。查看这些数据结构的源码，的确是设计的比较精巧，也保证了对内存足够小的占用以及各种操作的高效。</p>

<!--more-->


<h3>数据结构</h3>

<p>nginx实现中有很多结构体，一般命名为ngx_XXX_t。这些结构体分散在许多头文件中。src/core/ngx_core.h中把几乎所有的头文件都集合起来。也因此造成了nginx各部分源代码的耦合。但实际上nginx各个部分逻辑划分还是很明确的，整体上是一种松散的结构。</p>

<ul>
<li><p>ngx_str_t</p>

<pre><code>  typedef struct{
      size_t len;
      u_char *data;
  }ngx_str_t;
</code></pre></li>
</ul>


<p>这是nginx对字符串的实现，源码在ngx_string.h中。len指的是字符串的长度（不包括\0），data指向字符串。这种设计一方面，在计算字符创长度时只需要读取len字段即可，另一方面可以重复引用一段字符串内存。</p>

<p>常用api:</p>

<pre><code>    #define ngx_string(str) { sizof(str) - 1},(u_char *) str } //从一个普通字符串构造出一个nginx字符串，用sizeof计算长度，故参数必须是一个常量字符串。

    #define ngx_null_string {0,NULL}

    ngx_strncmp(s1,s2,n)

    ngx_strcm(s1,s2)
</code></pre>

<ul>
<li><p>ngx_pool_t</p>

<pre><code>  struct ngx_pool_s {
      ngx_pool_data_t       d;
      size_t                max;
      ngx_pool_t           *current;
      ngx_chain_t          *chain;
      ngx_pool_large_t     *large;
      ngx_pool_cleanup_t   *cleanup;
      ngx_log_t            *log;
  };
</code></pre></li>
</ul>


<p>这个数据结构在nginx中是一个非常重要的数据结构。用来管理一系列的资源（如内存、文件等
，使得对这些资源的使用和释放统一进行。这个是在c语言编程中值得借鉴的一个东西，代码中如果到处都是malloc和free的话，不仅会导致内存泄露，也会使代码难以阅读和维护。</p>

<ul>
<li><p>ngx_array_t</p>

<pre><code>  struct ngx_array_s {
      void        *elts; //指向实际的存储区域
      ngx_uint_t   nelts; //数组实际元素个数
      size_t       size; //数组单个元素的大小，单位是字节
      ngx_uint_t   nalloc; //数组的容量
      ngx_pool_t  *pool; //该数组用来分配内存的内存池
  };
</code></pre></li>
<li><p>ngx_hash_t</p>

<ul>
<li>ngx_hash_t不像其他的hash表的实现，可以插入删除元素，只能一次初始化。</li>
<li><p>解决冲突使用的是开链法，但实际上是开了一段连续的存储空间，和数组差不多。            <br/>
      ngx_int_t ngx_hash_init(ngx_hash_init_t <em>hinit, ngx_hash_key_t </em>names,ngx_uint_t nelts);//ngx_hash_t的初始化。</p>

<pre><code>  ngx_hash_init_t提供了初始化一个hash表所需要的一些基本信息
  typedef struct {
      ngx_hash_t       *hash; //指向hash表
      ngx_hash_key_pt   key; //指向从字符串生成hash值的hash函数。默认的实现为ngx_hash_key_lc
      ngx_uint_t        max_size; //hash表中的桶的个数
      ngx_uint_t        bucket_size; //每个桶的最大限制大小，单位是字节
      char             *name; //hash表的名字
      ngx_pool_t       *pool; //hash表分配内存使用的pool
      ngx_pool_t       *temp_pool; //使用的临时pool,初始化完成后，可以释放和销毁
  } ngx_hash_init_t;

  typedef struct {                ngx_str_t         key;              ngx_uint_t        key_hash;             void             *value;            } ngx_hash_key_t;
  void *ngx_hash_find(ngx_hash_t *hash, ngx_uint_t key, u_char *name, size_t len); //在hash里面查找key对应的value。          
</code></pre></li>
</ul>
</li>
<li><p>ngx_chain_t</p></li>
</ul>


<p>nginx的filter模块在处理从别的filter模块或者是handler模块传递过来的数据，数据一个链表的形式（ngx_chain_t）进行传递。</p>

<pre><code>        struct ngx_chain_s {
            ngx_buf_t    *buf;
            ngx_chain_t  *next;
        };
</code></pre>

<p>创建ngx_chain_t对象</p>

<pre><code>        ngx_chain_t *ngx_alloc_chain_link(ngx_pool_t *pool);
</code></pre>

<p>释放一个ngx_chain_t类型的对象。如果要释放整个chain，则迭代此链表，对每个节点使用此宏即可。</p>

<pre><code>        释放一个ngx_chain_t类型的对象。如果要释放整个chain，则迭代此链表，对每个节点使用此宏即可。
</code></pre>

<ul>
<li>ngx_buf_t</li>
</ul>


<p>ngx_buf_t是ngx_chain_t的数据结点</p>

<pre><code>    struct ngx_buf_s {
        u_char          *pos;
        u_char          *last;
        off_t            file_pos;
        off_t            file_last;

        u_char          *start;         /* start of buffer */
        u_char          *end;           /* end of buffer */
        ngx_buf_tag_t    tag;
        ngx_file_t      *file;
        ngx_buf_t       *shadow;


        /* the buf's content could be changed */
        unsigned         temporary:1;

        /*
        * the buf's content is in a memory cache or in a read only memory
        * and must not be changed
        */
        unsigned         memory:1;

        /* the buf's content is mmap()ed and must not be changed */
        unsigned         mmap:1;

        unsigned         recycled:1;
        unsigned         in_file:1;
        unsigned         flush:1;
        unsigned         sync:1;
        unsigned         last_buf:1;
        unsigned         last_in_chain:1;

        unsigned         last_shadow:1;
        unsigned         temp_file:1;

        /* STUB */ int   num;
    };
</code></pre>

<ul>
<li>ngx_list_t</li>
</ul>


<p>和普通的链表实现相比，它的节点是一个固定大小的数组。在初始化的时候，我们需要设定元素需要占用的空间大小，每个节点数组的容量大小。在添加元素到这个list里面的时候，会在最尾部的节点里的数组上添加元素，如果这个节点的数组存满了，就再增加一个新的节点到这个list里面去。</p>

<pre><code>    typedef struct {
        ngx_list_part_t  *last; //指向该链表的最后一个节点
        ngx_list_part_t   part; //指向该链表首个存放具体元素的节点
        size_t            size; //链表中存放的具体元素所需内存大小
        ngx_uint_t        nalloc; //每个节点所含的固定大小的数组的容量
        ngx_pool_t       *pool; //该list使用的分配内存的pool
    } ngx_list_t;

    struct ngx_list_part_s {
        void             *elts; //节点中存放具体元素的内存的开始地址   
        ngx_uint_t        nelts; //节点中已有元素个数，不能大于 nalloc
        ngx_list_part_t  *next; //指向下一个节点
    };

    ngx_list_t *ngx_list_create(ngx_pool_t *pool, ngx_uint_t n, size_t size); //创建一个ngx_list_t类型的对象,并对该list的第一个节点分配存放元素的内存空间。

    pool:   分配内存使用的pool。
    n:  每个节点固定长度的数组的长度。
    size:   存放的具体元素的个数。
</code></pre>

<ul>
<li><p>ngx_queue_t</p>

<pre><code>  struct ngx_queue_s {
      ngx_queue_t  *prev;
      ngx_queue_t  *next;
  };
</code></pre></li>
</ul>


<p>链表节点的数据成员并没有生命在链表节点的结构体中，只是声明了前向和后向指针。使用的时候需要定义一个哨兵节点。具体存放数据的节点称之为数据节点。对于数据节点，需要在数据结构体中加入一个类型为ngx_queue_s的域。使用下面的函数进行数据插入，其中x为数据节点的queue_t域。</p>

<pre><code>    #define ngx_queue_insert_head(h, x)                         \
        (x)-&gt;next = (h)-&gt;next;                                  \
        (x)-&gt;next-&gt;prev = x;                                    \
        (x)-&gt;prev = h;                                          \
        (h)-&gt;next = x

    #define ngx_queue_insert_after   ngx_queue_insert_head

    #define ngx_queue_insert_tail(h, x)                          \
        (x)-&gt;prev = (h)-&gt;prev;                                   \
        (x)-&gt;prev-&gt;next = x;                                     \
        (x)-&gt;next = h;                                           \
        (h)-&gt;prev = x
    获得数据时，使用ngx_queue_data()宏。
    #define ngx_queue_data(q, type, link)                        \
        (type *) ((u_char *) q - offsetof(type, link))
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《白帽子讲Web安全》读书笔记]]></title>
    <link href="http://superhj1987.github.io/blog/2014/07/24/web-security-notes/"/>
    <updated>2014-07-24T21:30:20+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/07/24/web-security-notes</id>
    <content type="html"><![CDATA[<p>最近一直在忙着易信公众平台的开发工作，一直没能抽出空来总结一下。周末终于有了一些空闲，就把这本书的笔记写了一下。</p>

<p>整本书四篇十八章，包括世界观安全、客户端脚本安全、服务端应用安全以及互联网公司安全运营四大部分。</p>

<h3>一、世界观安全</h3>

<ol>
<li>黑帽子和白帽子这两个概念，前者指的是利用安全技术进行破坏的哪一类黑客，后者则指的是工作在反黑客领域的安全技术专家。</li>
<li>安全问题的本质是信任的问题。并且安全是一个持续的过程，并不存在所谓的银弹。</li>
<li>安全三要素：机密性、完整性、可用性</li>
<li>一个安全评估的过程可以分为4个阶段：资产等级划分、威胁分析、风险分析、确认解决方案。其中威胁分析的一种建模方法是微软提出的STRIDE模型；风险分析则是DREAD模型，Risk = Probability * Damage Potenial。</li>
<li>白帽子并发有以下几个原则：Secure By Default原则；纵深防御原则（Defense in Depth）；数据与代码分离原则；不可预测性原则。</li>
</ol>


<!--more-->


<h3>二、客户端脚本安全</h3>

<ol>
<li><p>浏览器安全</p>

<p> 同源策略（Same Origin Policy）防止了跨域读写某些资源。
浏览器提供了浏览器沙箱，使进程在一个相对独立的空间运行，能在一定程度上保护浏览器安全。</p></li>
<li><p>跨站脚本攻击</p>

<p> 跨站脚本攻击主要是注入到网站内容中，授权用户访问内容时执行一段恶意代码，从而获取用户的私密信息或者进行破坏。通常叫做XSS攻击，是针对动态网站的攻击。</p></li>
<li><p>跨站点请求伪造</p>

<p> CSRF，指的是伪造出一个请求，诱使授权用户访问，以授权用户的身份去执行请求，从而达到对授权用户信息的读取、攻击等。</p></li>
<li><p>点击劫持</p>

<p> Click jacking，是指将恶意代码隐藏在看似无害的内容后者按钮之下，诱导用户访问的一种手段。</p></li>
<li><p>Html5安全</p>

<ul>
<li>HTML引入了很多新的标签，一些XSS Filter可能并没有覆盖这些新增的标签和功能。比如video、audio、iframe的sandbox。此外使用canvas可以在浏览器环境中实现对验证码的在线破解，大大降低了攻击的门槛。</li>
<li>跨域请求的Orgin Header和Access-Control-Allow-Origin的设置。postMessage的引入，使XSS PayLoad变得更加的灵活。</li>
</ul>
</li>
</ol>


<h3>三、服务端安全</h3>

<ol>
<li><p>注入攻击</p>

<p> 注入攻击是一种普遍的利用数据库SQL语句进行攻击的方式。使用用户提交的数据拼接数据库操作字符串，如果这些字符串中包含一些特殊字符就有可能查询到数据库关键信息。</p></li>
<li><p>文件上传漏洞</p>

<p> 通常的一个问题就是对上传文件的格式控制不严格，并且文件存放的路径可以通过Web路径直接进行访问；另一种方式，就是文件路径是通过表单的方式提交的，可以使用一个特殊字符“\0”截断文件路径，从而实现对脚本文件的上传。</p></li>
<li><p>认证与会话管理</p>

<p> 用户的登录状态一般是进过认证之后保存在服务端的，与服务器端的一系列交互即会话。一般对会话的管理。。。</p></li>
<li><p>访问控制</p>

<p> 对于系统中不同的用户具有不同的权限，对这些权限进行控制即访问控制。如果访问控制不严就容易形成漏洞被利用。</p></li>
<li><p>加密算法与随机数</p>

<p> 系统中对数据进行加密使用的加密算法和随机数生成算法的安全性和健壮性都直接关系到整个系统的安全性。对称加密、非对称加密的密钥的安全性，随机数算法的随机性都是要考虑的问题。</p></li>
<li><p>Web框架安全</p>

<p> 一些经典的使用率较高的Web框架如：Spring、Struts、Hibernate本身会在整个执行体系中有一些安全漏洞。比如前一阵的Struts2的命令执行漏洞，就是因为在OGNL中可以执行JAVA静态方法造成的。</p></li>
<li><p>应用层拒绝服务攻击</p>

<p> DOS，这种攻击是以耗尽服务器资源为目的攻击。DDOS分布式 拒绝服务攻击，是DOS的加强版。防范拒绝服务攻击要从访问入口处进行，限制来自统一IP的访问频率或者就是最大化提升系统的负载能力。</p></li>
<li><p>PHP安全和Web服务器配置安全</p>

<p> 针对与PHP本身的一些API的特点，可以在代码层面进行安全控制。比如，对数据库SQL相关的操作，要对用户输入的参数进行mysql_real_esape等。此外，对于Web Server如Apache http server，对其magic_quote,GLOBAL等配置要权衡关闭和开启是否会对系统的安全造成威胁。</p></li>
</ol>


<h3>四、互联网公司安全运营</h3>

<p>除了在技术层面对安全进行保证外，还可以在业务层面对安全进行最大化的保障。此外，微软提出的 SDL安全开发流程，运用在项目开发过程中能够很好地保障系统的安全。而运营方面的安全保障则能够进一步保证整个系统的安全性。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[杂感一篇]]></title>
    <link href="http://superhj1987.github.io/blog/2013/07/06/no-name/"/>
    <updated>2013-07-06T16:57:45+08:00</updated>
    <id>http://superhj1987.github.io/blog/2013/07/06/no-name</id>
    <content type="html"><![CDATA[<p>最近两部关于青春的片子《致青春》和《中国合伙人》，对于前者这种爱情的东西，从某个时间段开始，我早已不愿关注，也许是害怕触动心里某些痛处吧。后者讲述的奋斗、梦想，却是我特别想看一看的。虽然我知道成功学这东西，完全是一群成功了的人在吹嘘当年自己有多苦逼，后来变得多NB。但是他们的成功却的确能触动自己心里的那根神经，唤起自己当初的激情。</p>

<p>十几年前，自己无意之中说出的一句话，到现在也算一直坚持了下来。虽然没有功成名就，但到现在还是不至于令自己失望的。平淡的日子往往让自己忘了自己当初的梦想，也忘了走向它的这条路。今天看《中国合伙人》这部影片又像当初看《社交网络》一样让自己全身瞬间充满了能量，同时也让自己拷问着自己：还坚持当初的梦想吗？正在为梦想努力吗？努力有收获吗？其实，现实中大多数人在说自己梦想的时候都能侃侃而谈，而真正能付诸于努力的人却寥寥可数。为梦想而努力，结果不一定是成功，但没有为此而努力过，那也许会成为一辈子最大的憾事。</p>

<p>电影里三个人的友情是让我感触颇深的另一个地方。想想自己，活了快26年，真正能称得上朋友的人其实就那么几个人。和他们在一起，你会很确定不管你怎么样，他们都不会嫌弃你；不管你跟他们说了什么话，他们也不会介意。心情不好的时候，一个电话，他们不管有多忙也会立马赶到你的身旁。其实，以前的自己挺自私的，有点像孟晓峻，自从经历了那件事之后，我才体会到友情是多么的珍贵，也才弥足珍惜现在的他们。</p>

<p>不说什么下决心的话，能做的就是脚踏实地，朝着自己想去的那个方向努力。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[无题]]></title>
    <link href="http://superhj1987.github.io/blog/2013/05/13/no-name-1/"/>
    <updated>2013-05-13T23:02:50+08:00</updated>
    <id>http://superhj1987.github.io/blog/2013/05/13/no-name-1</id>
    <content type="html"><![CDATA[<p>5.11-5.12，176公里，千岛湖镇-汾口-千岛湖镇，环湖一周。相信这将会是我未来永远难忘的一段经历。</p>

<p>开始的计划是5.11中午从千岛湖镇出发，历经96公里前往汾口，18：00左右到达目的地。没想到走了大约20公里之后遇到了各种上坡路，尤其一段一公里的大上坡，让我们实在无法保持速度。全身各种疼，大腿完全是无知觉地在做机械运动，有无数次想放弃的冲动。如此艰难的挣扎，造成的后果就是从枫树岭开始的20公里山路只能摸黑前进，中间好几次撞到石头差点栽到地上。所幸的是有一辆自行车是有车灯的，不然还真不知道如何前行。最后到达汾口的时候已经是晚上快9点了。虽然远远晚于原定计划，但顺利到达目的地的喜悦还是让我们挺开心的。</p>

<p>5.12的路程相对来说是比较容易的，一路都是大缓坡，咬咬牙就都过了。中间在界首农庄吃了顿午饭。之后连续10个隧道，一路都还是挺舒服的。下午4点多，终于回到了出发点。算是完成了这次环千岛湖骑行。</p>

<p>这一段行程，真的感觉是对自己的一种历练+超越。在很多次想要放弃的时候，我都告诉自己，人只有超越自己、超越极限，才能成为一个无比强大的个体。和别人比较是没有任何意义的，能够战胜自己的人才是最优秀的。</p>

<p>PS：一路上各种哈雷机车，那叫一个帅气。。。据说是哈雷机车110周年纪念日，全国的机车爱好者都过来环湖庆祝。望而兴叹，啥时候自己也能成为一个哈雷机车车友呢？</p>

<!--more-->


<p><img src="http://superhj1987.github.io/images/blog_images/1.jpg" alt="" /></p>

<p><img src="http://superhj1987.github.io/images/blog_images/2.jpg" alt="" /></p>

<p><img src="http://superhj1987.github.io/images/blog_images/3.jpg" alt="" /></p>

<p><img src="http://superhj1987.github.io/images/blog_images/4.jpg" alt="" /></p>

<p><img src="http://superhj1987.github.io/images/blog_images/5.jpg" alt="" /></p>

<p><img src="http://superhj1987.github.io/images/blog_images/6.jpg" alt="" /></p>
]]></content>
  </entry>
  
</feed>
