<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Blog - srHang | 飒然]]></title>
  <link href="http://superhj1987.github.io/atom.xml" rel="self"/>
  <link href="http://superhj1987.github.io/"/>
  <updated>2015-02-06T17:13:23+08:00</updated>
  <id>http://superhj1987.github.io/</id>
  <author>
    <name><![CDATA[飒然Hang]]></name>
    <email><![CDATA[superhj1987@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[关于Spring mvc中modelattribute无法制定别名的解决方案]]></title>
    <link href="http://superhj1987.github.io/blog/2015/01/21/springm-mvc-model-attribute-alias/"/>
    <updated>2015-01-21T12:00:00+08:00</updated>
    <id>http://superhj1987.github.io/blog/2015/01/21/springm-mvc-model-attribute-alias</id>
    <content type="html"><![CDATA[<p>最近由于项目需要，发现spring mvc在绑定参数时有这么一个缺陷。</p>

<p><strong>Url</strong>: <a href="http://localhost:8080/api/test?user_name=testUser">http://localhost:8080/api/test?user_name=testUser</a></p>

<p><strong>Controller</strong>:</p>

<pre>
@Controller
@RequestMapping("/api")
public class ApiController extends BaseController {

    @RequestMapping(value = "/test", headers = "Accept=application/json")
    public void authUser(ModelMap modelMap, Account acc) {
        ResultPack.packOk(modelMap);
    }
}

public class Account{
    private static final long serialVersionUID = 750752375611621980L;

    private long id;
    private String userName;
    private String password;
    private AccountType type = AccountType.ADMIN;
    private long timeTag;
    private int status = 1;
    ...
    ...
}
</pre>


<p>user_name无法映射到acc的userName上。如果使用json的方式，可以使用JsonProperty注解来解决。否则，spring貌似没提供解决方案。</p>

<p>于是追踪了一下spring mvc的源代码，发现可以通过重写ServletModelAttributeMethodProcessor来支持这个功能。</p>

<p><strong>Github</strong>:  <a href="https://github.com/superhj1987/spring-mvc-model-attribute-alias">https://github.com/superhj1987/spring-mvc-model-attribute-alias</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2014这一年]]></title>
    <link href="http://superhj1987.github.io/blog/2015/01/15/2014-final-note/"/>
    <updated>2015-01-15T16:08:48+08:00</updated>
    <id>http://superhj1987.github.io/blog/2015/01/15/2014-final-note</id>
    <content type="html"><![CDATA[<p>突然发觉已经是2015年的1月15号了，即兴补上一篇2014年的总结吧。</p>

<p>2014年全国、全世界发生了很多事情。政府大规模的反腐揪出了一个个贪得无厌的官僚，让人们不禁拍手称快，觉得看到了国家的希望。但是腐败的根本在于体制，体制不进行变革，那么倒下一个贪官，还有另一批贪官起来，顶多是在这段时间收敛一下。其实，从某种意义来说，贪腐还不是危害最大的，如果你给人民做了贡献，带来了好处，至少我们受益了；但要只是贪污而无作为，那么真的是让人不齿了。不知道从什么时候起，自己对体制内的东西都有点反感，提到体制内，首先想到的就是背景、亲戚、老爹、关系，而不是能力。尤其是自己亲身体会或者道听途说到体制内很多万恶的潜规则之后，更是加深了这种感觉。真心希望在习大大的努力之下，能彻底破除体制内多少年形成的各种弊病，让“中国梦”真的可以成为所有人的“中国梦”。除了反腐，14年最大的事情莫过于世界杯了，对于我这种对足球仅存在巴西、罗纳尔多、亨利这些字眼的人来说，也就趁机给自己一个放纵的理由，晚上看世界杯、喝啤酒、吃烧烤，顺便买个足彩，也算充实了一下每天三点一线的生活。至于谁最好拿了冠军，说实话还真的没那么关心。</p>

<!--more-->


<p>举国、举世界的那些大事，对于我这种小屁民来说，也就只能调侃一下，过过嘴瘾。对于自己，2014也发生了不少事情。年初在家人的支持下，买了人生第一辆汽车，让我这个已经四年驾龄的“老司机”终于有了私家车。说来也巧，我压根不知道杭州会启动摇号买车政策的，没想到，刚买完没过多久，竟然宣布限号了，而且是在之前无数次声明“不限号”的情况下，这又显示出政府的老辣了。。。拿到新车，经历了开始的几次“摩擦”之后，自己也算慢慢上手了，到后来从杭州一路开到北京，也算能彻底摆脱“新手”的头衔了。买完车，一般的大事就是要买房子了，其实自己并没打算很快就买房的，但是2014年中开始，房子的价格貌似一降再降，让我总有一种再不买价格就回升的感觉。在纠结了无数次的情况下，终于狠下心付了首付（父母也倾囊相助），也算拥有了自己的小房子。买车买房两件大事都解决的同时，我却没想到最大的事情也来了。在自己已经打算彻底定居在杭州的情况下，老同学极力邀请自己加入他们公司打拼一下。当时虽然对自身的状况已经稍有微词，但还不至于想离职的地步。说起这个机会，自己在2011年的时候就险些加入他们，后来又折腾了两次。所以，早就认为和这次机会擦肩而过了，也就没再做指望。这一次机会又来到自己面前，而且是一个极其微妙的时间点。丰厚的年终奖、升职、股票摆在自己的面前，车子、房子也限制着自己。很多因素都告诉我不要去。纠结了n久，和父母、女友商议了无数次。我最后意识到在这种局面之下，还是要听从一下自己的内心的。大公司的生活固然待遇优厚、生活舒适，但是还未到30就已经学会享受也不是一件好事情，去一个未知的公司博一次，也许自己能收获意想不到的东西。衡量许久，也算做出了人生又一次极其重要的选择，决意北上博一下了。很多人可能会认为是给的待遇足够好。但说实话，虽然工资不错，但是由于年终奖的损失，如果和我不离职拿到的相比，2014年最后到手的是只可能少不可能多的。不过，加入创业公司，看重的是未来，对于眼前这些东西，并没有那么重要。</p>

<p>11月中旬，一路北上，来到了我一直持排斥态度的帝都。自己第一次长途开车，竟然顺利地到达了北京，也算是一种成功吧。</p>

<p>进入新的公司，一个未知前途的创业公司，截然不同的运作方式让我一开始有点措手不及。相比之前在大公司，小公司更需要一个人的快速成长以及自我约束，以及那种随叫随到、不怕脏累的奋斗精神。而技术层面，要尽最大化压榨硬件资源，用有限的硬件资源达到最大的性能。这些都让自己的架构方式和代码编写不得不去改变、去适应，这也算是一种成长吧。公司的基础架构、公共组件、项目管理、技术体系、项目架构都是一个初级的水平，改变这些是一个很难很长的路，但又不得不做。到现在，在做这些改变的过程中，自己的基础知识得到了巩固、架构能力也有了一定的提升，技术视野也开阔了一些。熟悉了公司的流程和整体的氛围，也算融入了这个团队，要做的还有很多，阻力也有很多。一切都在逼迫自己去学习、去思考、去提高。这也是与以前相比，给自己最大动力的事情。</p>

<p>2015年，工作上希望自己能做到这些</p>

<ul>
<li>合理设计并实现整个公司的基础架构</li>
<li>构建合理的项目管理流程、监督机制</li>
<li>提升团队的整体水平</li>
<li>保证产品的研发进度以及线上稳定性</li>
<li>招一些优秀的人加入</li>
</ul>


<p>自身方面，希望能做到这些：</p>

<ul>
<li>提升自身的技术水平和视野</li>
<li>深入学习一门技术：docker netty kafka rabbitmq elasticsearch solr</li>
<li>阅读至少五本非技术书籍</li>
</ul>


<p>Stay hungry,stay foolish!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spring mvc的controller传递HttpServletResponse参数的一点事]]></title>
    <link href="http://superhj1987.github.io/blog/2014/12/09/spring-mvc-httpservletresponse/"/>
    <updated>2014-12-09T10:05:41+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/12/09/spring-mvc-httpservletresponse</id>
    <content type="html"><![CDATA[<pre>
    @RequestMapping(value = "cardDown", method = RequestMethod.GET, headers = "Accept=text/html")
    public void cardDown(ModelMap modelMap, HttpServletRequest request, HttpServletResponse response, String id, int status){
    ......
    }
</pre>


<p>之前在使用Spring mvc的时候发现这么一回事：在spring mvc的controller的参数里如果有HttpServletResponse(类似上面的代码),那么必须有返回值框架才会去在执行完handler后去搜索相应的viewResolver和view从而展现数据。如果没有返回值，那么默认就是返回null的。我初步推测框架的处理过程大致如此：如果controller参数里传递HttpServletResposne的话，框架就认为视图由handler自己生成可以不参于这个过程,但是如果handler有返回值的话，那么仍然认为还需要参与到视图生成的过程中。</p>

<!--more-->


<p>翻了一下spring mvc的代码，验证了自己的想法。在DispatchServlet的921行</p>

<pre>
// Actually invoke the handler.
mv = ha.handle(processedRequest, response, mappedHandler.getHandler());
</pre>


<p>这里的mv就是视图生成的结果。接着经历下面的过程：</p>

<ol>
<li>AbstractHandlerMethodAdapter.handle</li>
<li>RequestMappingHandlerAdapter.handleInternal</li>
<li><p>RequestMappingHandlerAdapter.invokeHandleMethod</p>

<p> 这地方有一个关键的变量mavContainer
 <pre>
 ModelAndViewContainer mavContainer = new ModelAndViewContainer();
 </pre>
 mavContainer有一个属性requestHandled，其标志着此次请求是否是由handler自己控制的。默认为false。</p></li>
<li><p>ServletInvocableHandlerMethod.invokeAndHandle</p></li>
<li>InvocableHandlerMethod.invokeForRequest</li>
<li><p>InvocableHandlerMethod.getMethodArgumentValues</p>

<p> 这个方法的功能在名字上大体就能看出来：获取controller中每一个参数的值。关键的地方在于
 <pre>
 args[i] = argumentResolvers.resolveArgument(parameter, mavContainer, request, dataBinderFactory);
 </pre>
 这一行代码关联的是对每一中paramerter的处理类。接下来的调用见7</p></li>
<li><p>HandlerMethodArgumentResolverComposite.resolveArgument</p>

<p> <pre>
 HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter);
 Assert.notNull(resolver, &ldquo;Unknown parameter type [&rdquo; + parameter.getParameterType().getName() + &ldquo;]&rdquo;);
 return resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);
 </pre></p>

<p> 这里的代码就三行，第一步是根据参数不同，获取不同的argumentResolver。当参数为HttpServletResponse的时候，就会调用ServletResponseMethodArgumentResolver.resolveArgument</p></li>
<li><p>ServletResponseMethodArgumentResolver.resolveArgument</p>

<p> 最核心的一段代码来了</p>

<p> <pre>
 if (mavContainer != null) {
     mavContainer.setRequestHandled(true);
 }
 </pre></p>

<p> 这里就把mavContainer的requestHandled设置为了true.</p></li>
<li><p>回到4，调用完InvocableHandlerMethod.invokeForRequest</p>

<p> <pre>
 if (returnValue == null) {
     if (isRequestNotModified(webRequest) || hasResponseStatus() || mavContainer.isRequestHandled()) {
         mavContainer.setRequestHandled(true);
         return;
     }
 }else if (StringUtils.hasText(this.responseReason)) {
     mavContainer.setRequestHandled(true);
     return;
 }</p>

<p> mavContainer.setRequestHandled(false);
 </pre></p>

<p> 当handler的返回值为null的时候，直接返回。否则将mavContainer的requestHandled设置为false。</p></li>
<li><p>接着回到3，调用完ServletInvocableHandlerMethod.invokeAndHandle后，接着调用getModelAndView(mavContainer, modelFactory, webRequest)</p></li>
<li><p>ServletInvocableHandlerMethod.getModelAndView</p>

<p><pre>
modelFactory.updateModel(webRequest, mavContainer);</p>

<p>if (mavContainer.isRequestHandled()) {
    return null;
}
</pre></p>

<p>这里当mavContainer的requestHandled被设置为true时,视图返回null。</p></li>
</ol>


<p>整个大体的流程就是这样的，如果需要使用HttpServletResponse同时还需要框架控制视图生成的话，可以给controller method一个返回值（随便什么都行）。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于工作]]></title>
    <link href="http://superhj1987.github.io/blog/2014/11/26/work-note-new/"/>
    <updated>2014-11-26T17:57:05+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/11/26/work-note-new</id>
    <content type="html"><![CDATA[<p>离开上一个公司快半个月了。想想，自己坚持从杭州离开，从一个大公司离开，来到这个自己一直很排斥的城市，加入一个尚不知前景的创业公司。是对还是错?</p>

<p>在前东家的时候，周围优秀的人太多，不管怎么样自己都能学到很多知识，遇到疑问的时候也能有人解答。所以在前东家的几年自己成长了很多。有怨言的仅仅是那一直落后于业界的工资待遇以及刚入职时候坑人的80%，其他的都是自己很满意的，也是自己会感恩的一家公司。自己起初也是打算在那里沉淀几年技术再去创业的。至于选择离开，问问自己，是为了钱吗？其实在杭州能给我开出这种待遇的公司很多；为了职位吗？其实现在的自己水平还处于很低的一个水准，学习才是主旋律。也许仅仅是那种不甘心和挑战带来的机会吧。要知道，选择这条路意味着从此以后需要依靠自己的学习能力，自我提高，自我成长；选择这条路意味着压力、责任和冒险。自己到这里的期望是什么呢？成为技术领头人，带着一个技术团队从一个没有什么业界水准的初级团队成长为一个业界有地位的杰出团队，这也是现在能追求的最大化吧。人生总是面临很多选择，选择一个就意味着不能回头。自己能把握的只有成为更好的自己，不能把握的只能顺其自然。</p>

<p>在一个极具挑战的环境下，汲取各种知识，培养自己的架构思维，尽快的成长为合格甚至顶尖的架构师，这也许是现在能带给自己最大的机会。这也是自己当初这么坚决来这里的原因吧。Stay hungry,stay foolish,把握现在，充实自己，一切顺其自然。^_^</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ShellShock这点事]]></title>
    <link href="http://superhj1987.github.io/blog/2014/09/29/shell-shock/"/>
    <updated>2014-09-29T21:49:46+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/09/29/shell-shock</id>
    <content type="html"><![CDATA[<h2>前言</h2>

<p>在微博上看到最近安全界爆出了一个危害比之前的“心脏流血”（Heartbleed Bug）还要大很多的Bash代码注入漏洞：CVE-2014-6271 “shellshock”漏洞，然后随之而来一系列相关漏洞。详情可以看这些链接：<a href="http://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2014-6271">CVE-2014-6271</a> 、<a href="http://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2014-7169">CVE-2014-7169</a>、<a href="https://access.redhat.com/security/cve/CVE-2014-7186">CVE-2014-7186</a>、<a href="https://access.redhat.com/security/cve/CVE-2014-7187">CVE-2014-7187</a>、<a href="https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2014-6277">CVE-2014-6277</a>。世界上Linux服务器的占有份额是很大的，而bash又是Linux不可或缺的一个部分。可想而知，这个漏洞的破坏力有多大。这个从名字上就可以看出来，ShellShock是医学上的一种严重的疾病，中文叫做“弹震症”，指的是受到爆炸冲击后导致浑身颤抖、思维混乱等症状。这个命名很形象地反映了问题的严重性。</p>

<!--more-->


<h2>漏洞的原理是什么</h2>

<p>参照shellshock官网<a href="https://shellshocker.net/">https://shellshocker.net/</a>，测试本机是否受这个漏洞的影响，先要执行一段shell代码：</p>

<pre>
env x='() { :;}; echo vulnerable' bash -c ""
</pre>


<p>如果发现有以下输出说明你系统受到这个漏洞的影响。</p>

<pre>
vulnerable
</pre>


<p>为什么会这样呢？看一下代码，首先设置一个环境变量x，x指向的是一个函数，这个函数仅仅有一句:;的代码，就是返回true。后面跟着的echo vulnerable，按说是不应该为执行的。后面的bash -c &hellip;，这里使用bash命令开启了子shell，子shell会在启动的时候继承父shell的环境变量，于是在继承x这个变量的时候，就把echo vulnerable这行执行了。结果就是打印出了vulnerable。</p>

<p>官网上提到如果这一步就发现自己收到了影响，那么先update bash吧。</p>

<p>在升级完bash后，并非就高枕无忧了，又有人发现了更NB的利用这个漏洞的办法。执行下面的shell代码：</p>

<pre>
env X='() { (shellshocker.net)=>\' bash -c "echo date"; cat echo ; rm -f echo
</pre>


<p>如果这行代码，打印出了日期（可能会伴有一些错误），那么说明你仍然没有逃脱这个漏洞的影响。</p>

<pre>
bash: X: line 1: syntax error near unexpected token `='
bash: X: line 1: `'
bash: error importing function definition for `X'
2014年 9月29日 星期一 21时04分30秒 CST
</pre>


<p>update bash之后，只是让子shell继承父shell的时候不去执行后面的语句。但是这个代码变态之处在于它故意使用（shellshocker.net）=让shell报错，后面的>\则留在了缓冲区中，子shell继承到了>\,然后执行echo date，此时相当于下面的代码：</p>

<pre>
>\
echo date
</pre>


<p>\是命令换行的，于是就相当于>echo date，>是重定向符号，最后其实等价于date  > echo，这样最终把命令给执行了。</p>

<p>此外，官网还列出了其他的exploit，都是利用了子进程对环境变量的继承：</p>

<ol>
<li><p>Exploit 3 (???)</p>

<p> Here is another variation of the exploit. Please leave a comment below if you know the CVE of this exploit.
 <pre>
env -i X=&lsquo; () { }; echo hello&rsquo; bash -c &lsquo;date&rsquo;
</pre></p>

<p>  If the above command outputs &ldquo;hello&rdquo;, you are vulnerable.</p></li>
<li><p>Exploit 4 (CVE-2014-7186)</p></li>
<li><p>Exploit 5 (CVE-2014-7187)</p></li>
</ol>


<h2>怎样利用这个漏洞</h2>

<p>看了上面说的bash漏洞，那我们怎样来利用呢？举一个典型的列子，现在有很多网站是使用的apache运行在Linux系统上的，也是以子进程的方式来运行web程序的，其中用户端传来的HTTP_USER_AGENT、HTTP_HEADER等是会传递到子进程中的，而且这些变量是用户端任意可以指定的，如果按照开始讲的那样传递一个x过来，但是并不仅仅是echo一个字符串，那危害。。。可想而知。如下面的一个http请求（如果不是仅仅ping一个ip地址）：</p>

<pre>
http-user-agent = shellshock-scan () http-header = Cookie:() { :; }; ping -c 163.com
http-header = Host:() { :; }; ping -c 163.com
http-header = Referer:() { :; }; ping -c 163.com
</pre>


<p>除此之外，现在已经有利用这个漏洞攻击DHCP客户端、VoIP设备、Git版本控制系统、qmail等的成功例子了，可以说有Linux的地方就有shellshock的“用武之地”，包括Mac os。这篇文章总结了现在发现的各种各样的攻击方式：<a href="http://www.fireeye.com/blog/uncategorized/2014/09/shellshock-in-the-wild.html">http://www.fireeye.com/blog/uncategorized/2014/09/shellshock-in-the-wild.html</a></p>

<p>看到这里，可能有人会说：”让你们天天说Linux有多安全”。其实Windows也逃不开这个漏洞的危害，很多windows系统里都有bash环境，即使没有bash环境，只要你的系统使用了含有bash的组件（如负载均衡、CDN）也难逃shellshock的魔掌。</p>

<h2>总结</h2>

<p>修复Shellshock漏洞就像打地鼠，堵了一头另一头又冒出，修复一部分，很快就有其他的攻击方式出现，层出不穷，问题的关键其实还是在于bash在设计的时候对于环境变量的依赖。只要存在对环境变量的导出，那么攻击者就可以使用各种方式诱骗bash视其为命令，进行执行。</p>

<h3>参考文章</h3>

<ul>
<li><a href="http://www.oschina.net/news/55694/shellshock-flaw">http://www.oschina.net/news/55694/shellshock-flaw</a></li>
<li><a href="http://news.cnblogs.com/n/504675/">http://news.cnblogs.com/n/504675/</a></li>
<li><a href="http://weibo.com/p/1005051401527553/weibo">http://weibo.com/p/1005051401527553/weibo</a></li>
<li><a href="https://shellshocker.net/">https://shellshocker.net/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM内存的GC的骗局（转载）]]></title>
    <link href="http://superhj1987.github.io/blog/2014/09/25/jvm-cheat/"/>
    <updated>2014-09-25T21:29:52+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/09/25/jvm-cheat</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<p>在日常程序开发中，很多JAVA程度员不太关心内存的使用情况。当然，如果程序员运气较好或者系统没有大规模的被测试或者被用户使用时，这个问题或许永远不出现，使得程序员一直认为内存反正是无限的，可以一直使用。确实，JVM的垃圾回收器会帮我们处理好所有的事情，可如果运气不是那么好，不幸就有可能发生在我们的身上，比如：进程会抛出OOM异常，不再接收新的请求；响应时间在固定时间段内变长，超时或者不响应，CPU使用率时常像过山车一样等。内存使用在大部分的工作时间可以正常工作，这样会导致很多的人对JAVA应用的内存使用情况不明了或者得不到充分的性能测试，而导致程序无法正常工作。出现上面的情况程序员一般会比较好的较快的发现问题或能总结一定的规律。</p>

<!--more-->


<h2>问题</h2>

<p>有时候JVM还会发生欺骗你的场景， JVM不停的在垃圾回收，可是每次回收完后堆却还是满的，很明显程序内存被使用完了，已经无法正常工作了，但JVM就是不抛出OutOfMemoryError(OOM)这个异常来告诉程序员内部发出了什么，只是不停的做老好人尝试帮我们做垃圾回收，把服务器的资源耗光了，但是此时服务器已经无法响应用户的正常请求了，让我们一起来看看这些情况发生时候的现象，体会一下被欺骗的感觉。</p>

<h2>现状：</h2>

<p>同事在模拟用户不停的发送请求给某系统，在运行一段时间后，突然，系统上邮件报告测试用例请求失败，登录测试系统的服务器，首先看下JVM的参数设置，如下：</p>

<p>-server –Xms4g –Xmx4g -XX:MaxPermSize=256m  -verbose:gc -XX:+PrintGCDetails -Xloggc:$CATALINA_BASE/logs/gc.log -XX:+PrintGCTimeStamp，再使用TOP命令看看服务器发生了什么。</p>

<p>观察一段时间后，CPU一直运行在100%，于是想当然的认为可能是那段程序里面触发了BUG,有可能是正则表达式或者某段代码里面有个死循环的坑跳进去，没有出来。这不是很简单的事吗？直接使用jstack + pid 把堆栈打出来即可，直接操作吧，界面上马上输出操作日志，从堆栈日志可以看出，所有的线程都被BLOCKED住了，然后堆栈里面也找不到任何业务的相关代码，难道直觉出错了，感觉一下子不太好了，但是至少可以排查到不是上面的二种原因了，好吧，那再看看应用的GC的情况，部分日志如下。</p>

<p>1403682.561: [GC [PSYoungGen: 1375104K->11376K(1386176K)] 4145665K->2782002K(4182400K), 0.0174410 secs] [Times: user=0.27 sys=0.00, real=0.02 secs]</p>

<p>1407799.743: [GC [PSYoungGen: 1386160K->11632K(1386432K)] 4156786K->2793538K(4182656K), 0.0285330 secs] [Times: user=0.48 sys=0.00, real=0.03 secs]</p>

<p>1409230.024: [GC [PSYoungGen: 1386416K->10688K(1377984K)] 4168322K->2803822K(4174208K), 0.0265000 secs] [Times: user=0.43 sys=0.00, real=0.02 secs]</p>

<p>1409230.051: [Full GC [PSYoungGen: 10688K->7014K(1377984K)] [PSOldGen: 2793134K->2796224K(2796224K)] 2803822K->2803238K(4174208K) [PSPermGen: 48439K->48439K(262144K)], 7.8892780 secs] [Times: user=7.92 sys=0.00, real=7.89 secs]</p>

<p>1410502.582: [Full GC [PSYoungGen: 1366336K->85344K(1377984K)] [PSOldGen: 2796224K->2796224K(2796224K)] 4162560K->2881568K(4174208K) [PSPermGen: 48577K->48577K(262144K)], 8.2720110 secs] [Times: user=8.29 sys=0.00, real=8.27 secs]</p>

<p>PS：这里使用-XX:+PrintGCDateStamps替代-XX:+PrintGCTimeStamp,可以打印出真实时间戳。</p>

<h2>解释一下：</h2>

<p>第一行：
1403682.561: [GC [PSYoungGen: 1375104K->11376K(1386176K)] 4145665K->2782002K(4182400K), 0.0174410 secs] [Times: user=0.27 sys=0.00, real=0.02 secs]</p>

<p>发生的时间点，：JVM运行的时间长度，以度为单位，也可以格式化成固定的时间格式</p>

<p>PSYoungGen：发生了何种类型的GC，此处代表发生了年轻代的GC</p>

<p>1375104K：回收前的大小</p>

<p>11376K：回收后的大小</p>

<p>1386176K：YOUNG代的大小</p>

<p>4145665 K：回收前总的占用大小</p>

<p>2782002K：回收后的占用大小</p>

<p>4182400K：总占用大小</p>

<p>0.27和0.00：代表在用户态(user)和系统状(sys)的CPU运行时间</p>

<p>0.02 secs：代表实际的GC的运行时间</p>

<p>注：上面总的运行时间小于用户态和系统态的时间总和，是由于后者仅指CPU的运行时间，包括等待或IO阻塞的时间，而且现在的GC是采用多线程收集的，同时机器也是多个CPU，因此，大部分是二者之和要比前面的值大，如果是采用串形化收集器( serial collector)的话，二者时间几乎相差不多。关于各种收集器的差别，后续有时间再安排详细总结。</p>

<p>接下来的二行，不再重复说明，第四行有Full字样，代表JVM发生了Full GC，不过多了二个分区的收集，PSOldGen：老生代的回收前后空间大小及总空间；PSPermGen：持久代的回收前后空间大小和总空间。从第三行，可以看出老空间的使用率达到饱和，从而触发了FULL GC，但是很遗憾的是第五行后又接着发生了FULL GC，后面的都是一直在持续进行，但是系统一直不抛出OOM异常或者进程退出，导致这台机器服务进程一直存在，但是基本无法正常工作。</p>

<p>GC，无论Young GC还是Full GC，每次都会导致JVM STW(STOP WORLD)暂停用户的业务工作，来处理垃圾回收任务，短时间内无法响应用户请求，特别是大量的Full GC会导致系统响应速度降低，另外还有OOM的巨大风险。Young GC频繁，就算GC采用多线程回收方式，尽管回收的时候非常短，但是如果GC次数和频率很高，因此对应用的影响是不可忽视的。 Full GC 包括整个分区的垃圾回收，包括新生代、旧生代、持久代等。因此其回收成本高，应用也会暂停更长时间，无法及时响应用户的请求，所以需要特别注意这个种情况，一般来讲，排除主动的调用GC操作外，JVM会在以下几种情况发生Full GC。</p>

<ol>
<li><p>旧生代内存不足</p></li>
<li><p>持久代内存不足</p></li>
<li><p>统计新生代 GC晋升到旧生代的平均大小大于旧生代的剩余空间</p></li>
</ol>


<h2>解决</h2>

<p>知道发生的原因后，就可以使用JMAP -heap直接看一下JVM内存的对像值，或者使用JMAP -dump直接JVM的堆栈DUMP出来，使用MAT打开分析就行。如果这种现像发生之后，DUMP出来的文件会较大，有些会达到十多个G，因为一般不直接在工作机器上进行，需要把文件转发到其他的非线上服务并且内存足够的机器上分析，最后可以用MAT把分析后的文件打开即可，打开后，首页会给出可疑的建议对象实例，直接跳转到列表中，打开折叠细节即可看到真面目，里面包括了三十多万个对象，找相关的人员对根据业务需要，直接把不需要的实例在使用完后移除，其他几行的问题类似处理就即可。</p>

<h2>总结</h2>

<p>从上面GC的发生的情况来看，JVM一次次不停的努力的帮我们进行GC操作，直到把CPU全部占光，但是就是不直接抛出异常直接告诉我们内存不够了，感觉把我们带了到一个巨大的庞氏骗局，也许我们把JVM的内存加大，这个坑还将帮我们隐藏下去，如果程序设置了定时重启之类的操作，这个坑就永远发现不了。一般产品开发人员非常希望应用程序能在用户发觉之前发现这个问题，JVM无法判断出这个问题，因为也就不能帮我们抛出几乎OOM的异常，不过可以通过调整GCTimeLimit和GCHeapFreeLimit参数来重新定义何时抛出OutOfMemoryError错误。GCTimeLimit 的默认值是98%，也就是说如果98%时间都用花在GC上，则会抛出OutOfMemoryError。GCHeapFreeLimit 是回收后可用堆的大小。默认值是2%。当然最好的办法就是开发工程师开始就很清楚如何使用相关的容器类的正确用法，并且在上线前能经过充分的测试或运行。本文只是引用GC方面的一个具体的安全来说明GC是怎么骗人的，关于GC和JVM内存相关的细节如何及时的发现此类的问题，有机会再通过示例和大家探讨学习。</p>

<p>注：以上资料仅以HOTSPOT VM 1.7.65 版本参考。</p>

<p>参考资料：</p>

<p>JVM <a href="http://docs.oracle.com/javase/8/docs/technotes/guides/vm/gc-ergonomics.html">http://docs.oracle.com/javase/8/docs/technotes/guides/vm/gc-ergonomics.html</a></p>

<p>HotSpot JVM就是个庞氏骗局 <a href="http://it.deepinmind.com/gc/2014/04/01/hotspot-jvm-ponzi-scheme.html">http://it.deepinmind.com/gc/2014/04/01/hotspot-jvm-ponzi-scheme.html</a></p>

<p>Java内存泄露分析 <a href="http://doc.hz.netease.com/pages/viewpage.action?pageId=36468038">http://doc.hz.netease.com/pages/viewpage.action?pageId=36468038</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx源码分析之启动过程]]></title>
    <link href="http://superhj1987.github.io/blog/2014/09/24/nginx-bootstrap/"/>
    <updated>2014-09-24T17:38:57+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/09/24/nginx-bootstrap</id>
    <content type="html"><![CDATA[<p>nginx的启动过程代码主要分布在src/core以及src/os/unix目录下。启动流程的函数调用序列：main(src/core/nginx.c)→ngx_init_cycle(src/core/ngx_cycle.c)→ngx_master_process_cycle(src/os/)。nginx的启动过程就是围绕着这三个函数进行的。</p>

<p>main函数的处理过程总体上可以概括如下：</p>

<!--more-->


<ol>
<li>简单初始化一些数据接结构和模块：ngx_debug_init、ngx_strerror_init、ngx_time_init、ngx_regex_init、ngx_log_init、ngx_ssl_init等</li>
<li>获取并处理命令参数：ngx_get_options。</li>
<li><p>初始化ngx_cycle_t结构体变量init_cycle，设置其log、pool字段等。
 <pre>
 ngx_memzero(&amp;init_cycle, sizeof(ngx_cycle_t));
 init_cycle.log = log;
 ngx_cycle = &amp;init_cycle;</p>

<p> init_cycle.pool = ngx_create_pool(1024, log);
 if (init_cycle.pool == NULL) {
     return 1;
 }
</pre></p></li>
<li>保存参数，设置全局变量：ngx_argc ngx_os_argv ngx_argv ngx_environ</li>
<li>处理控制台命令行参数，设置init_cycle的字段。这些字段包括：conf_prefix、prefix（-p prefix）、conf_file(-c filename)、conf_param(-g directives)。此外，还设置init_cyle.log.log_level=NGX_LOG_INFO。</li>
<li>调用ngx_os_init来设置一些和操作系统相关的全局变量：ngx_page_size、ngx_cacheline_size、ngx_ncpu、ngx_max_sockets、ngx_inherited_nonblocking。</li>
<li>调用ngx_crc32_table_init初始化ngx_crc32_table_short。用于后续做crc校验。</li>
<li>调用ngx_add_inherited_sockets(&amp;init_cycle)→ngx_set_inherited_sockets，初始化init_cycle的listening字段（一个ngx_listening_t的数组）。</li>
<li>对所有模块进行计数
 <pre>
 ngx_max_module = 0;
 for (i = 0; ngx_modules[i]; i++) {
     ngx_modules[i]&ndash;>index = ngx_max_module++;
 }
</pre></li>
<li>调用ngx_init_cycle进行模块的初始化，当解析配置文件错误时，退出程序。这个函数传入init_cycle然后返回一个新的ngx_cycle_t。</li>
<li>调用ngx_signal_process、ngx_init_signals处理信号。</li>
<li>在daemon模式下，调用ngx_daemon以守护进程的方式运行。这里可以在./configure的时候加入参数&mdash;with-debug，并在nginx.conf中配置:
<pre>
master_process  off; # 简化调试 此指令不得用于生产环境
daemon          off; # 简化调试 此指令可以用到生产环境
</pre>
可以取消守护进程模式以及master线程模型。</li>
<li>调用ngx_create_pidfile创建pid文件，把master进程的pid保存在里面。</li>
<li><p>根据进程模式来分别调用相应的函数
<pre>
if (ngx_process == NGX_PROCESS_SINGLE) {
    ngx_single_process_cycle(cycle);</p>

<p>} else {
    ngx_master_process_cycle(cycle);
}
</pre>
多进程的情况下，调用ngx_master_process_cycle。单进程的情况下调用ngx_single_process_cycle完成最后的启动工作。</p></li>
</ol>


<p>整个启动过程中一个关键的变量init_cycle，其数据结构ngx_cycle_t如下所示：</p>

<pre>
struct ngx_cycle_s {
    void                  ****conf_ctx;
    ngx_pool_t               *pool;

    ngx_log_t                *log;
    ngx_log_t                 new_log;

    ngx_connection_t        **files;
    ngx_connection_t         *free_connections;
    ngx_uint_t                free_connection_n;

    ngx_queue_t               reusable_connections_queue;

    ngx_array_t               listening;
    ngx_array_t               paths;
    ngx_list_t                open_files;
    ngx_list_t                shared_memory;

    ngx_uint_t                connection_n;
    ngx_uint_t                files_n;

    ngx_connection_t         *connections;
    ngx_event_t              *read_events;
    ngx_event_t              *write_events;

    ngx_cycle_t              *old_cycle;

    ngx_str_t                 conf_file;
    ngx_str_t                 conf_param;
    ngx_str_t                 conf_prefix;
    ngx_str_t                 prefix;
    ngx_str_t                 lock_file;
    ngx_str_t                 hostname;
};
</pre>


<p>它保存了一次启动过程需要的一些资源。</p>

<p>ngx_init_cycle函数的处理过程如下：</p>

<ol>
<li>调用ngx_timezone_update()、ngx_timeofday、ngx_time_update()来更新时区、时间等，做时间校准，用来创建定时器等。</li>
<li><p>创建pool,赋给一个新的cycle（ngx_cycle_t）。这个新的cycle的一些字段从旧的cycle传递过来，比如：log,conf_prefix,prefix,conf_file,conf_param。
 <pre>
 cycle->conf_prefix.len = old_cycle->conf_prefix.len;
 cycle->conf_prefix.data = ngx_pstrdup(pool, &amp;old_cycle->conf_prefix);
 if (cycle->conf_prefix.data == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }</p>

<p> cycle->prefix.len = old_cycle->prefix.len;
 cycle->prefix.data = ngx_pstrdup(pool, &amp;old_cycle->prefix);
 if (cycle->prefix.data == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }</p>

<p> cycle->conf_file.len = old_cycle->conf_file.len;
 cycle->conf_file.data = ngx_pnalloc(pool, old_cycle->conf_file.len + 1);
 if (cycle->conf_file.data == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }
 ngx_cpystrn(cycle->conf_file.data, old_cycle->conf_file.data,
             old_cycle->conf_file.len + 1);</p>

<p> cycle->conf_param.len = old_cycle->conf_param.len;
 cycle->conf_param.data = ngx_pstrdup(pool, &amp;old_cycle->conf_param);
 if (cycle->conf_param.data == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }
 </pre>
还有一些字段会首先判断old_cycle中是否存在，如果存在，则申请同样大小的空间，并初始化。这些字段如下：
 <pre>
 n = old_cycle->paths.nelts ? old_cycle->paths.nelts : 10;</p>

<p> //paths
 cycle->paths.elts = ngx_pcalloc(pool, n * sizeof(ngx_path_t *));
 if (cycle->paths.elts == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }</p>

<p> cycle->paths.nelts = 0;
 cycle->paths.size = sizeof(ngx_path_t *);
 cycle->paths.nalloc = n;
 cycle->paths.pool = pool;</p>

<p> //open_files
 if (old_cycle->open_files.part.nelts) {
     n = old_cycle->open_files.part.nelts;
     for (part = old_cycle->open_files.part.next; part; part = part->next) {
         n += part->nelts;
     }</p>

<p> } else {
     n = 20;
 }</p>

<p> //shared_memory
 if (old_cycle->shared_memory.part.nelts) {
     n = old_cycle->shared_memory.part.nelts;
     for (part = old_cycle->shared_memory.part.next; part; part = part->next)
     {
         n += part->nelts;
     }</p>

<p> } else {
     n = 1;
 }</p>

<p> //listening
 n = old_cycle->listening.nelts ? old_cycle->listening.nelts : 10;</p>

<p> cycle->listening.elts = ngx_pcalloc(pool, n * sizeof(ngx_listening_t));
 if (cycle->listening.elts == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }</p>

<p> cycle->listening.nelts = 0;
 cycle->listening.size = sizeof(ngx_listening_t);
 cycle->listening.nalloc = n;
 cycle->listening.pool = pool;
</pre></p>

<p>  此外，new_log.log_level重新赋值的为NGX_LOG_ERR；old_cycle为传递进来的cycle；hostname为gethostname;初始化resuable_connection_queue。</p>

<p>  这里有一个关键变量的初始化：conf_ctx。初始化为ngx_max_module个void *指针。说明其实所有模块的配置结构的指针。</p></li>
<li><p>调用所有模块的create_conf，返回的配置结构指针放到conf_ctx数组中，索引为ngx_modules[i]&ndash;>index。</p></li>
<li>从命令行和配置文件读取配置更新到conf_ctx中。ngx_conf_param是读取命令行中的指令，ngx_conf_parse是把读取配置文件。ngx_conf_param最后也是通过调用ngx_cong_parse来读取配置的。ngx_conf_parse函数中有一个for循环，每次都调用ngx_conf_read_token取得一个配置指令，然后调用ngx_conf_handler来处理这条指令。ngx_conf_handler每次会遍历所有模块的指令集，查找这条配置指令并分析其合法性，如果正确则创建配置结构并把指针加入到cycle.conf_ctx中。
 遍历指令集的过程首先是遍历所有的核心类模块，若是 event类的指令，则会遍历到ngx_events_module，这个模块是属于核心类的，其钩子set又会嵌套调用ngx_conf_parse去遍历所有的event类模块，同样的，若是http类指令，则会遍历到ngx_http_module，该模块的钩子set进一步遍历所有的http类模块，mail类指令会遍历到ngx_mail_module，该模块的钩子进一步遍历到所有的mail类模块。要特别注意的是：这三个遍历过程中会在适当的时机调用event类模块、http类模块和mail类模块的创建配置和初始化配置的钩子。从这里可以看出，event、http、mail三类模块的钩子是配置中的指令驱动的。</li>
<li>调用core module的init_conf。</li>
<li><p>读取核心模块ngx_core_module的配置结构，调用ngx_create_pidfile创建pid文件。
 <pre>
 ccf = (ngx_core_conf_t *) ngx_get_conf(cycle->conf_ctx, ngx_core_module);
</pre></p>

<p>  这里代码中有一句注释：
  <pre>
   we do not create the pid file in the first ngx_init_cycle() call
   because we need to write the demonized process pid
</pre>
  当不是第一次初始化cycles时才会调用ngx_create_pidfile写入pid。</p></li>
<li>调用ngx_test_lockfile,ngx_create_paths并打开error_log文件复制给cycle->new_log.file。</li>
<li>遍历cycle的open_files.part.elts，打开每一个文件。open_files填充的文件数据是读取配置文件时写入的。</li>
<li>创建共享内存。这里和对open_files类似。先预分配空间，再填充数据。</li>
<li>处理listening sockets，遍历cycle->listening数组与old_cycle->listenning进行比较，设置cycle->listening的一些状态信息，调用ngx_open_listening_sockets启动所有监听socket，循环调用socket、bind、listen完成服务端监听监听socket的启动。并调用ngx_configure_listening_sockets配置监听socket,根据ngx_listening_t中的状态信息设置socket的读写缓存和TCP_DEFER_ACCEPT。</li>
<li>调用每个module的init_module。</li>
<li>关闭或者删除一些残留在old_cycle中的资源，首先释放不用的共性内存，关闭不使用的监听socket，再关闭不适用的打开文件。最后把old_cycle放入ngx_old_cycles。最后再设定一个定时器，定期回调ngx_cleaner_event清理ngx_old_cycles。周期设置为30000ms。</li>
</ol>


<p>接下来是进程的启动，包括master和worker进程。main函数最后调用ngx_master_process_cycle来启动master进程模式(这里对单进程模式不做讲述)。</p>

<ol>
<li>设置一些信号，如下：
 <pre>
 sigaddset(&amp;set, SIGCHLD);
 sigaddset(&amp;set, SIGALRM);
 sigaddset(&amp;set, SIGIO);
 sigaddset(&amp;set, SIGINT);
 sigaddset(&amp;set, ngx_signal_value(NGX_RECONFIGURE_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_REOPEN_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_NOACCEPT_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_TERMINATE_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_SHUTDOWN_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_CHANGEBIN_SIGNAL));
</pre></li>
<li>调用ngx_setproctitle设置进程标题：&#8221;master process&#8221; + ngx_argv[0&hellip;]</li>
<li>启动worker进程,数量为ccf->worker_processes。
 <pre>
 ngx_start_worker_processes(cycle, ccf->worker_processes,
                            NGX_PROCESS_RESPAWN);
</pre></li>
<li>启动文件cache管理进程。
 <pre>
 ngx_start_cache_manager_processes(cycle, 0);
</pre>
 这里的cahche在一些模块中是需要的，如fastcgi模块等,这些模块会把文件cache路径添加到cycle->paths中，文件cache管理进程会定期调用这些模块的文件cache处理钩子处理一下文件cache。</li>
<li>master主循环，主要是循环处理信号量。在循环过程中，判断相应的条件然后进入相应的处理。这里的相关标志位基本都是在信号处理函数中赋值的。
 <pre>
 for ( ;; ) {
  // delay用来设置等待worker退出的时间，master接收了退出信号后首先发送退出信号给worker，
  // 而worker退出需要一些时间
  if (delay) {
      delay = 2;
          &hellip;
      itv.it_interval.tv_sec = 0;
      itv.it_interval.tv_usec = 0;
      itv.it_value.tv_sec = delay / 1000;
      itv.it_value.tv_usec = (delay % 1000 ) * 1000;
      // 设置定时器
      if (setitimer(ITIMER_REAL, &amp;itv, NULL) == -1) {
          ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
          “setitimer() failed”);
      }
  }
  ngx_log_debug0(NGX_LOG_DEBUG_EVENT, cycle->log, 0, “sigsuspend”);
  // 挂起信号量，等待定时器
  sigsuspend(&amp;set);
  ngx_time_update(0, 0);
  ngx_log_debug0(NGX_LOG_DEBUG_EVENT, cycle->log, 0, “wake up”);
  // 收到了SIGCHLD信号，有worker退出（ngx_reap==1）
  if (ngx_reap) {
      ngx_reap = 0;
      ngx_log_debug0(NGX_LOG_DEBUG_EVENT, cycle->log, 0, “reap children”);
      // 处理所有worker，如果有worker异常退出则重启这个worker，如果所有worker都退出
      // 返回0赋值给live
      live = ngx_reap_children(cycle);
  }
  // 如果worker都已经退出，
  // 并且收到了NGX_CMD_TERMINATE命令或者SIGTERM信号或者SIGINT信号(ngx_terminate=1)
  // 或者NGX_CMD_QUIT命令或者SIGQUIT信号(ngx_quit=1)，则master退出
  if (!live &amp;&amp; (ngx_terminate || ngx_quit)) {
      ngx_master_process_exit(cycle);
  }
  // 收到了NGX_CMD_TERMINATE命令或者SIGTERM信号或者SIGINT信号，
  // 通知所有worker退出，并且等待worker退出
  if (ngx_terminate) {
      // 设置延时
      if (delay == 0) {
          delay = 50;
      }
      if (delay > 1000) {
          // 延时已到，给所有worker发送SIGKILL信号，强制杀死worker
          ngx_signal_worker_processes(cycle, SIGKILL);
      } else {
          // 给所有worker发送SIGTERM信号，通知worker退出
          ngx_signal_worker_processes(cycle,
          ngx_signal_value(NGX_TERMINATE_SIGNAL));
      }
      continue;
  }
  // 收到了NGX_CMD_QUIT命令或者SIGQUIT信号
  if (ngx_quit) {
      // 给所有worker发送SIGQUIT信号
      ngx_signal_worker_processes(cycle,
      ngx_signal_value(NGX_SHUTDOWN_SIGNAL));
      // 关闭所有监听的socket
      ls = cycle->listening.elts;
      for (n = 0; n &lt; cycle->listening.nelts; n++) {
          if (ngx_close_socket(ls[n].fd) == -1) {
              ngx_log_error(NGX_LOG_EMERG, cycle->log, ngx_socket_errno,
                  ngx_close_socket_n ” %V failed”,&amp;ls[n].addr_text);
          }
      }
      cycle->listening.nelts = 0;
  continue;
  }
  // 收到了SIGHUP信号
  if (ngx_reconfigure) {
      ngx_reconfigure = 0;
      // 代码已经被替换，重启worker，不需要重新初始化配置
      if (ngx_new_binary) {
          ngx_start_worker_processes(cycle, ccf->worker_processes,
              NGX_PROCESS_RESPAWN);
          ngx_start_cache_manager_processes(cycle, 0);
          ngx_noaccepting = 0;
          continue;
      }
      ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, “reconfiguring”);
      // 重新初始化配置
      cycle = ngx_init_cycle(cycle);
      if (cycle == NULL) {
          cycle = (ngx_cycle_t ) ngx_cycle;
          continue;
      }
      // 重启worker
      ngx_cycle = cycle;
      ccf = (ngx_core_conf_t *) ngx_get_conf(cycle->conf_ctx,
      ngx_core_module);
      ngx_start_worker_processes(cycle, ccf->worker_processes,
          NGX_PROCESS_JUST_RESPAWN);
      ngx_start_cache_manager_processes(cycle, 1);
      live = 1;
      ngx_signal_worker_processes(cycle,
          ngx_signal_value(NGX_SHUTDOWN_SIGNAL));
  }
  // 当ngx_noaccepting=1的时候会把ngx_restart设为1，重启worker
  if (ngx_restart) {
      ngx_restart = 0;
      ngx_start_worker_processes(cycle, ccf->worker_processes,
          NGX_PROCESS_RESPAWN);
      ngx_start_cache_manager_processes(cycle, 0);
      live = 1;
  }
  // 收到SIGUSR1信号，重新打开log文件
  if (ngx_reopen) {
      ngx_reopen = 0;
      ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, “reopening logs”);
      ngx_reopen_files(cycle, ccf->user);
      ngx_signal_worker_processes(cycle,
      ngx_signal_value(NGX_REOPEN_SIGNAL));
  }
  // 收到SIGUSR2信号，热代码替换
  if (ngx_change_binary) {
      ngx_change_binary = 0;
      ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, “changing binary”);
      // 调用execve执行新的代码
      ngx_new_binary = ngx_exec_new_binary(cycle, ngx_argv);
  }
  // 收到SIGWINCH信号，不再接收请求，worker退出，master不退出
  if (ngx_noaccept) {
      ngx_noaccept = 0;
      ngx_noaccepting = 1;
      ngx_signal_worker_processes(cycle,
      ngx_signal_value(NGX_SHUTDOWN_SIGNAL));
  }
}
</pre>
信号处理函数是在main函数中进行的初始化：ngx_init_signals(cycle->log)。其中的signal handler代码如下所示：</li>
</ol>


<pre>
void
ngx_signal_handler(int signo)
{
    char            *action;
    ngx_int_t        ignore;
    ngx_err_t        err;
    ngx_signal_t    *sig;

    ignore = 0;

    err = ngx_errno;

    for (sig = signals; sig->signo != 0; sig++) {
        if (sig->signo == signo) {
            break;
        }
    }

    ngx_time_sigsafe_update();

    action = "";

    switch (ngx_process) {

    case NGX_PROCESS_MASTER:
    case NGX_PROCESS_SINGLE:
        switch (signo) {

        case ngx_signal_value(NGX_SHUTDOWN_SIGNAL):
            ngx_quit = 1;
            action = ", shutting down";
            break;

        case ngx_signal_value(NGX_TERMINATE_SIGNAL):
        case SIGINT:
            ngx_terminate = 1;
            action = ", exiting";
            break;

        case ngx_signal_value(NGX_NOACCEPT_SIGNAL):
            if (ngx_daemonized) {
                ngx_noaccept = 1;
                action = ", stop accepting connections";
            }
            break;

        case ngx_signal_value(NGX_RECONFIGURE_SIGNAL):
            ngx_reconfigure = 1;
            action = ", reconfiguring";
            break;

        case ngx_signal_value(NGX_REOPEN_SIGNAL):
            ngx_reopen = 1;
            action = ", reopening logs";
            break;

        case ngx_signal_value(NGX_CHANGEBIN_SIGNAL):
            if (getppid() > 1 || ngx_new_binary > 0) {

                /*
                 * Ignore the signal in the new binary if its parent is
                 * not the init process, i.e. the old binary's process
                 * is still running.  Or ignore the signal in the old binary's
                 * process if the new binary's process is already running.
                 */

                action = ", ignoring";
                ignore = 1;
                break;
            }

            ngx_change_binary = 1;
            action = ", changing binary";
            break;

        case SIGALRM:
            ngx_sigalrm = 1;
            break;

        case SIGIO:
            ngx_sigio = 1;
            break;

        case SIGCHLD:
            ngx_reap = 1;
            break;
        }

        break;

    case NGX_PROCESS_WORKER:
    case NGX_PROCESS_HELPER:
        switch (signo) {

        case ngx_signal_value(NGX_NOACCEPT_SIGNAL):
            if (!ngx_daemonized) {
                break;
            }
            ngx_debug_quit = 1;
        case ngx_signal_value(NGX_SHUTDOWN_SIGNAL):
            ngx_quit = 1;
            action = ", shutting down";
            break;

        case ngx_signal_value(NGX_TERMINATE_SIGNAL):
        case SIGINT:
            ngx_terminate = 1;
            action = ", exiting";
            break;

        case ngx_signal_value(NGX_REOPEN_SIGNAL):
            ngx_reopen = 1;
            action = ", reopening logs";
            break;

        case ngx_signal_value(NGX_RECONFIGURE_SIGNAL):
        case ngx_signal_value(NGX_CHANGEBIN_SIGNAL):
        case SIGIO:
            action = ", ignoring";
            break;
        }

        break;
    }

    ngx_log_error(NGX_LOG_NOTICE, ngx_cycle->log, 0,
                  "signal %d (%s) received%s", signo, sig->signame, action);

    if (ignore) {
        ngx_log_error(NGX_LOG_CRIT, ngx_cycle->log, 0,
                      "the changing binary signal is ignored: "
                      "you should shutdown or terminate "
                      "before either old or new binary's process");
    }

    if (signo == SIGCHLD) {
        ngx_process_get_status();
    }

    ngx_set_errno(err);
}
</pre>


<p>创建worker子进程的函数是ngx_start_worker_processes。</p>

<pre>
static void
ngx_start_worker_processes(ngx_cycle_t *cycle, ngx_int_t n, ngx_int_t type)
{
    ngx_int_t      i;
    ngx_channel_t  ch;

    ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "start worker processes");

    ch.command = NGX_CMD_OPEN_CHANNEL; //传递给其他worker子进程的命令：打开通信管道

    //创建n个worker进程
    for (i = 0; i < n; i++) {

        //创建worker子进程并初始化相关资源和属性
        ngx_spawn_process(cycle, ngx_worker_process_cycle,
                          (void *) (intptr_t) i, "worker process", type);

        /*master父进程向所有已经创建的worker子进程（不包括本子进程）广播消息
        包括当前worker子进程的进程id、在进程表中的位置和管道句柄，这些worker子进程收到消息后，会更新这些消息到自己进程空间的进程表，以此实现两个worke子进程之间的通信。
        */
        ch.pid = ngx_processes[ngx_process_slot].pid;
        ch.slot = ngx_process_slot;
        ch.fd = ngx_processes[ngx_process_slot].channel[0];

        ngx_pass_open_channel(cycle, &ch);
    }
}
</pre>


<p>这里ngx_pass_open_channel，即遍历所有worker进程，跳过自己和异常的worker，把消息发送给各个worker进程。worker进程的管道可读事件捕捉函数是ngx_channel_handler(ngx_event_t *ev)，在这个函数中，会读取message，然后解析，并根据不同给的命令做不同的处理。</p>

<p>这里有一个关键的函数是ngx_pid_t ngx_spawn_process(ngx_cycle_t <em>cycle, ngx_spawn_proc_pt proc, void </em>data,char *name, ngx_int_t respawn)。proc是子进程的执行函数，data是其参数，name是进程名。</p>

<p>这个函数的任务：</p>

<ol>
<li>有一个ngx_processes全局数组，包含了所有的子进程，这里会fork出子进程并放入相应的位置，并设置这个进程的相关属性。</li>
<li>创建socketpair，并设置相关属性</li>
<li>子啊子进程中执行传递进来的函数。</li>
</ol>


<pre>
u_long     on;
ngx_pid_t  pid;
ngx_int_t  s; //fork的子进程在ngx_processes中的位置

//如果传递进来的respawn>0，说明是要替换进程ngx_processes[respawn]，可安全重用该进程表项。
if (respawn >= 0) {
   s = respawn;
} else {
   遍历进程表，找到空闲的slot
   for (s = 0; s < ngx_last_process; s++) {
        if (ngx_processes[s].pid == -1) {
                break;
            }
        }

        //达到最大进程限制报错
        if (s == NGX_MAX_PROCESSES) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, 0,
                          "no more than %d processes can be spawned",
                          NGX_MAX_PROCESSES);
            return NGX_INVALID_PID;
        }
    }
</pre>


<p></p>

<p>接下来创建一对socketpair句柄，然后初始化相关属性。</p>

<pre>
    if (respawn != NGX_PROCESS_DETACHED) { //NGX_PROCESS_DETACHED是热代码替换

        /* Solaris 9 still has no AF_LOCAL */

        //建立socketpair
        if (socketpair(AF_UNIX, SOCK_STREAM, 0, ngx_processes[s].channel) == -1)
        {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "socketpair() failed while spawning \"%s\"", name);
            return NGX_INVALID_PID;
        }

        。。。

        //设置非阻塞模式
        if (ngx_nonblocking(ngx_processes[s].channel[0]) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          ngx_nonblocking_n " failed while spawning \"%s\"",
                          name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        if (ngx_nonblocking(ngx_processes[s].channel[1]) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          ngx_nonblocking_n " failed while spawning \"%s\"",
                          name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        //打开异步模式
        on = 1;
        if (ioctl(ngx_processes[s].channel[0], FIOASYNC, &on) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "ioctl(FIOASYNC) failed while spawning \"%s\"", name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        //设置异步io所有者
        if (fcntl(ngx_processes[s].channel[0], F_SETOWN, ngx_pid) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "fcntl(F_SETOWN) failed while spawning \"%s\"", name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        //当exec后关闭句柄
        if (fcntl(ngx_processes[s].channel[0], F_SETFD, FD_CLOEXEC) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "fcntl(FD_CLOEXEC) failed while spawning \"%s\"",
                           name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        if (fcntl(ngx_processes[s].channel[1], F_SETFD, FD_CLOEXEC) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "fcntl(FD_CLOEXEC) failed while spawning \"%s\"",
                           name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        //设置当前子进程的句柄
        ngx_channel = ngx_processes[s].channel[1];

    } else {
        ngx_processes[s].channel[0] = -1;
        ngx_processes[s].channel[1] = -1;
    }
</pre>


<p>接下来就是fork子进程，并设置进程相关参数。</p>

<pre>
    //设置进程在进程表中的slot
    ngx_process_slot = s;

    pid = fork();

    switch (pid) {

    case -1:
        ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                      "fork() failed while spawning \"%s\"", name);
        ngx_close_channel(ngx_processes[s].channel, cycle->log);
        return NGX_INVALID_PID;

    case 0:
        //子进程，执行传递进来的子进程函数
        ngx_pid = ngx_getpid();
        proc(cycle, data);
        break;

    default:
        break;
    }

    ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "start %s %P", name, pid);

    ngx_processes[s].pid = pid;
    ngx_processes[s].exited = 0;

    if (respawn >= 0) { //使用原来的子进程即可
        return pid;
    }

    //初始化进程结构
    ngx_processes[s].proc = proc;
    ngx_processes[s].data = data;
    ngx_processes[s].name = name;
    ngx_processes[s].exiting = 0;

    switch (respawn) {

    case NGX_PROCESS_NORESPAWN:
        ngx_processes[s].respawn = 0;
        ngx_processes[s].just_spawn = 0;
        ngx_processes[s].detached = 0;
        break;

    case NGX_PROCESS_JUST_SPAWN:
        ngx_processes[s].respawn = 0;
        ngx_processes[s].just_spawn = 1;
        ngx_processes[s].detached = 0;
        break;

    case NGX_PROCESS_RESPAWN:
        ngx_processes[s].respawn = 1;
        ngx_processes[s].just_spawn = 0;
        ngx_processes[s].detached = 0;
        break;

    case NGX_PROCESS_JUST_RESPAWN:
        ngx_processes[s].respawn = 1;
        ngx_processes[s].just_spawn = 1;
        ngx_processes[s].detached = 0;
        break;

    case NGX_PROCESS_DETACHED:
        ngx_processes[s].respawn = 0;
        ngx_processes[s].just_spawn = 0;
        ngx_processes[s].detached = 1;
        break;
    }

    if (s == ngx_last_process) {
        ngx_last_process++;
    }   
</pre>


<p>最后看一下，worker进程执行的函数static void
ngx_worker_process_cycle(ngx_cycle_t <em>cycle, void </em>data)。</p>

<ol>
<li><p>调用ngx_worker_process_init初始化；</p>

<ul>
<li>设置ngx_process=NGX_PROCESS_WORKER</li>
<li>全局性的设置，包括执行环境、优先级、限制、setgid、setuid、信号初始化</li>
<li>调用所有模块的init_process钩子</li>
<li>关闭不使用的管道句柄，关闭当前的worker子进程的channel[0]句柄和继承来的其他进程的channel[1]句柄。使用其他进程的channel[0]句柄发送消息，使用本进程的channel[1]句柄监听事件。</li>
</ul>
</li>
<li><p>进行线程相关的操作。（如果有线程模式）</p></li>
<li>主循环处理各种状态，类似master进程的主循环。</li>
</ol>


<pre>   
for ( ;; ) {

        if (ngx_exiting) { //退出状态，关闭所有连接

            c = cycle->connections;

            for (i = 0; i < cycle->connection_n; i++) {

                /* THREAD: lock */

                if (c[i].fd != -1 && c[i].idle) {
                    c[i].close = 1;
                    c[i].read->handler(c[i].read);
                }
            }

            if (ngx_event_timer_rbtree.root == ngx_event_timer_rbtree.sentinel)
            {
                ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "exiting");

                ngx_worker_process_exit(cycle);
            }
        }

        ngx_log_debug0(NGX_LOG_DEBUG_EVENT, cycle->log, 0, "worker cycle");

        ngx_process_events_and_timers(cycle); //处理事件和计时

        if (ngx_terminate) { //收到NGX_CMD_TERMINATE命令，清理进城后退出，并调用所有模块的exit_process钩子。
            ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "exiting");

            ngx_worker_process_exit(cycle);
        }

        if (ngx_quit) {
            ngx_quit = 0;
            ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0,
                          "gracefully shutting down");
            ngx_setproctitle("worker process is shutting down");

            if (!ngx_exiting) {
                //关闭监听socket，并设置退出状态
                ngx_close_listening_sockets(cycle);
                ngx_exiting = 1;
            }
        }

        if (ngx_reopen) { //重新打开log
            ngx_reopen = 0;
            ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "reopening logs");
            ngx_reopen_files(cycle, -1);
        }
    }
</pre>


<p>总结一下，nginx的启动过程可以划分为两个部分，</p>

<ol>
<li>读取配置文件并设置全局的配置结构信息以及每个模块的配置结构信息，调用模块的 create_conf钩子和init_conf钩子。</li>
<li>创建进程和进程间通信机制，master进程负责管理各个worker子进程，通过 socketpair向子进程发送消息，各个worker子进程服务利用事件机制处理请求，通过socketpair与其他子进程通信（发送消息或者接收消息），进程启动的各个适当时机会调用模块的init_module钩子、init_process钩子、exit_process钩子和 exit_master钩子，init_master钩子没有被调用过。nginx的worker子进程继承了父进程的全局变量之后，子进程和父进程就会独立处理这些全局变量，有些全局量需要在父子进程之间同步就要通过通信方式了，比如 ngx_processes（进程表）的同步。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx负载均衡]]></title>
    <link href="http://superhj1987.github.io/blog/2014/08/27/nginx-loabbalance/"/>
    <updated>2014-08-27T14:32:50+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/08/27/nginx-loabbalance</id>
    <content type="html"><![CDATA[<h2>一、特点</h2>

<h3>1.1 应用情况</h3>

<p>Nginx做为一个强大的Web服务器软件，具有高性能、高并发性和低内存占用的特点。此外，其也能够提供强大的反向代理功能。俄罗斯大约有超过20%的虚拟主机采用Nginx作为反向代理服务器,在国内也有腾讯、新浪、网易等多家网站在使用Nginx作为反向代理服务器。据Netcraft统计，世界上最繁忙的网站中有11.48%使用Nginx作为其服务器或者代理服务器。基于反向代理的功能，Nginx作为负载均衡主要有以下几点理由：</p>

<ol>
<li><p>高并发连接</p></li>
<li><p>内存消耗少</p></li>
<li><p>配置文件非常简单</p></li>
<li><p>成本低廉</p></li>
<li><p>支持Rewrite重写规则</p></li>
<li><p>内置的健康检查功能</p></li>
<li><p>节省带宽</p></li>
<li><p>稳定性高</p></li>
</ol>


<!--more-->


<h3>1.2 架构</h3>

<p><img src="http://superhj1987.github.io/images/ngx_arch.jpg" alt="" /></p>

<p>nginx在启动后，会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程。工作进程以非特权用户运行。</p>

<p>master进程主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程。</p>

<p>worker进程则是处理基本的网络事件。多个worker进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。</p>

<p>开发模型：epoll和kqueue。</p>

<p>支持的事件机制：kqueue、epoll、rt signals、/dev/poll 、event ports、select以及poll。</p>

<p>支持的kqueue特性包括EV_CLEAR、EV_DISABLE、NOTE_LOWAT、EV_EOF，可用数据的数量，错误代码.</p>

<p>支持sendfile、sendfile64和sendfilev;文件AIO；DIRECTIO;支持Accept-filters和TCP_DEFER_ACCEP.</p>

<h3>1.3 性能</h3>

<p>Nginx的高并发，官方测试支持5万并发连接。实际生产环境能到2-3万并发连接数。10000个非活跃的HTTP keep-alive 连接仅占用约2.5MB内存。三万并发连接下，10个Nginx进程，消耗内存150M。淘宝tengine团队说测试结果是“24G内存机器上，处理并发请求可达200万”。</p>

<h2>二、负载均衡</h2>

<h3>2.1 协议支持</h3>

<p>Nginx工作在网络的7层，可以针对http应用本身来做分流策略。支持七层HTTP、HTTPS协议的负载均衡。对四层协议的支持需要第三方插件-yaoweibin的ngx_tcp_proxy_module实现了tcp upstream。</p>

<p><a href="https://github.com/yaoweibin/nginx_tcp_proxy_module">https://github.com/yaoweibin/nginx_tcp_proxy_module</a></p>

<p>此外，nginx本身也逐渐在完善对其他协议的支持：</p>

<ul>
<li><p>Nginx 1.3.13 开发版支持WebSocket代理。</p></li>
<li><p>Nginx 1.3.15开发版支持SPDY。</p></li>
</ul>


<h3>2.2 均衡策略</h3>

<p>nginx的负载均衡策略可以划分为两大类：内置策略和扩展策略。内置策略包含加权轮询和ip hash，在默认情况下这两种策略会编译进nginx内核，只需在nginx配置中指明参数即可。扩展策略有很多，如fair、通用hash、consistent hash等，默认不编译进nginx内核。</p>

<ol>
<li><p>加权轮询（weighted round robin）</p>

<p> 轮询的原理很简单，首先我们介绍一下轮询的基本流程。如下是处理一次请求的流程图：</p>

<p> <img src="http://superhj1987.github.io/images/ngx_wr_process.jpg" alt="" /></p>

<p> 图中有两点需要注意，第一，如果可以把加权轮询算法分为先深搜索和先广搜索，那么nginx采用的是先深搜索算法，即将首先将请求都分给高权重的机器，直到该机器的权值降到了比其他机器低，才开始将请求分给下一个高权重的机器；第二，当所有后端机器都down掉时，nginx会立即将所有机器的标志位清成初始状态，以避免造成所有的机器都处在timeout的状态，从而导致整个前端被夯住。</p></li>
<li><p>ip hash</p>

<p> ip hash是nginx内置的另一个负载均衡的策略，流程和轮询很类似，只是其中的算法和具体的策略有些变化，如下图所示：</p>

<p> <img src="http://superhj1987.github.io/images/ngx_iphash_process.jpg" alt="" /></p>

<p> ip hash算法的核心实现如下：</p>

<p> <pre>
 for(i = 0;i &lt; 3;i++){
     hash = (hash * 113 + iphp->addr[i]) % 6271;
 }</p>

<p> p = hash % iphp->rrp.peers->number;
 </pre></p>

<p> 从代码中可以看出，hash值既与ip有关又与后端机器的数量有关。经过测试，上述算法可以连续产生1045个互异的value，这是该算法的硬限制。对此nginx使用了保护机制，当经过20次hash仍然找不到可用的机器时，算法退化成轮询。因此，从本质上说，ip hash算法是一种变相的轮询算法，如果两个ip的初始hash值恰好相同，那么来自这两个ip的请求将永远落在同一台服务器上，这为均衡性埋下了很深的隐患。</p></li>
<li><p>fair</p>

<p> fair策略是扩展策略，默认不被编译进nginx内核。其原理是根据后端服务器的响应时间判断负载情况，从中选出负载最轻的机器进行分流。这种策略具有很强的自适应性，但是实际的网络环境往往不是那么简单，因此要慎用。</p></li>
<li><p>通用hash、一致性hash</p>

<p> 这两种也是扩展策略，在具体的实现上有些差别，通用hash比较简单，可以以nginx内置的变量为key进行hash，一致性hash采用了nginx内置的一致性hash环，可以支持memcache。</p></li>
</ol>


<h3>2.2 配置示例</h3>

<ol>
<li><p>HTTP</p>

<pre><code> http {

     upstream  www.s135.com  {

       server   192.168.1.2:80;

       server   192.168.1.3:80;

     }



     server{

       listen  80;

       server_name  www.s135.com;



       location / {

                proxy_pass        http://www.s135.com;

                proxy_set_header   Host             $host;

                proxy_set_header   X-Real-IP        $remote_addr;

                proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;

       }



       location /nginx_status {

                stub_status on;

                access_log off;

                allow 192.168.1.1;#设置为可访问该状态信息的ip

                deny all;

       }

     }

 }
</code></pre></li>
<li><p>TCP &ndash; ngx_tcp_proxy_module</p>

<pre><code> tcp {

     upstream cluster {

         # simple round-robin

         server 192.168.0.1:80;

         server 192.168.0.2:80;



         check interval=3000 rise=2 fall=5 timeout=1000;



         #check interval=3000 rise=2 fall=5 timeout=1000 type=ssl_hello;



         #check interval=3000 rise=2 fall=5 timeout=1000 type=http;

         #check_http_send "GET / HTTP/1.0\r\n\r\n";

         #check_http_expect_alive http_2xx http_3xx;

     }



     server {

         listen 8888;

         proxy_pass cluster;

     }

 }
</code></pre></li>
</ol>


<h2>三、动态负载均衡</h2>

<h3>3.1 自身监控</h3>

<p>内置了对后端服务器的健康检查功能。如果Nginx proxy后端的某台服务器宕机了，会把返回错误的请求重新提交到另一个节点，不会影响前端访问。它没有独立的健康检查模块，而是使用业务请求作为健康检查，这省去了独立健康检查线程，这是好处。坏处是，当业务复杂时，可能出现误判，例如后端响应超时，这可能是后端宕机，也可能是某个业务请求自身出现问题，跟后端无关。</p>

<h3>3.2 可扩展性</h3>

<p>Nginx属于典型的微内核设计，其内核非常简洁和优雅，同时具有非常高的可扩展性。如下图所示：</p>

<p><img src="http://superhj1987.github.io/images/ngx_micro.jpg" alt="" /></p>

<p>Nginx是纯C语言的实现，其可扩展性在于其模块化的设计。目前，Nginx已经有很多的第三方模块，大大扩展了自身的功能。nginx_lua_module可以将Lua语言嵌入到Nginx配置中，从而利用Lua极大增强了Nginx本身的编程能力，甚至可以不用配合其它脚本语言（如PHP或Python等），只靠Nginx本身就可以实现复杂业务的处理。</p>

<h3>3.3 配置修改</h3>

<p>nginx的配置架构如下图所示：</p>

<p><img src="http://superhj1987.github.io/images/ngx_config.jpg" alt="" /></p>

<p>Nginx支持热部署，几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。能够在不间断服务的情况下，对软件版本进行进行升级。Nginx的配置文件非常简单，风格跟程序一样通俗易懂，能够支持perl语法。使用nginx –s reload可以在运行时加载配置文件，便于运行时扩容/减容。重新加载配置时，master进程发送命令给当前正在运行的worker进程worker进程接到命令后会在处理完当前任务后退出。同时，master进程会启动新的worker进程来接管工作。</p>

<h2>四、优势和劣势</h2>

<h3>4.1 优势</h3>

<ol>
<li><p>可以很好地进行http 的头处理</p></li>
<li><p>对http协议以及https的良好支持</p></li>
<li><p>有足够的第三方插件供使用</p></li>
<li><p>支持热部署，更改后端是平滑的</p></li>
</ol>


<h3>4.2 劣势</h3>

<ol>
<li><p>缺少对session的支持</p></li>
<li><p>对四层tcp的支持不够好</p></li>
<li><p>post请求写文件系统，造成500 error</p></li>
<li><p>缺乏主动的后端服务器健康监测</p></li>
<li><p>默认的监控界面统计信息不全</p></li>
</ol>


<h2>五、Tengine</h2>

<h3>5.1 特性</h3>

<ol>
<li><p>继承Nginx-1.2.9的所有特性，100%兼容Nginx的配置；</p></li>
<li><p>动态模块加载（DSO）支持。加入一个模块不再需要重新编译整个Tengine；</p></li>
<li><p>输入过滤器机制支持。通过使用这种机制Web应用防火墙的编写更为方便；</p></li>
<li><p>动态脚本语言Lua支持。扩展功能非常高效简单；</p></li>
<li><p>支持管道（pipe）和syslog（本地和远端）形式的日志以及日志抽样；</p></li>
<li><p>组合多个CSS、JavaScript文件的访问请求变成一个请求；</p></li>
<li><p>更加强大的负载均衡能力，包括一致性hash模块、会话保持模块，还可以对后端的服务器进行主动健康检查，根据服务器状态自动上线下线；</p></li>
<li><p>自动根据CPU数目设置进程个数和绑定CPU亲缘性；</p></li>
<li><p>监控系统的负载和资源占用从而对系统进行保护；</p></li>
<li><p>显示对运维人员更友好的出错信息，便于定位出错机器；</p></li>
<li><p>更强大的防攻击（访问速度限制）模块；</p></li>
<li><p>更方便的命令行参数，如列出编译的模块列表、支持的指令等；</p></li>
<li><p>可以根据访问文件类型设置过期时间；</p></li>
</ol>


<h3>5.2 负载均衡</h3>

<p>负载均衡方面，Tengine主要有以下几个特点，基本上弥补了 nginx在负载均衡方面的欠缺：</p>

<ol>
<li><p>支持一致性Hash模块</p></li>
<li><p>会话保持模块</p></li>
<li><p>对后端服务器的主动健康检查。</p></li>
<li><p>增加了请求体不缓存到磁盘的机制</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[async源码分析]]></title>
    <link href="http://superhj1987.github.io/blog/2014/08/22/node-async-analysis/"/>
    <updated>2014-08-22T16:08:28+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/08/22/node-async-analysis</id>
    <content type="html"><![CDATA[<p>最近在使用到node js的async库的时候，对其waterfall的实现感觉很奇妙，于是看了一下源码：</p>

<pre>
    async.waterfall = function (tasks, callback) {
        callback = callback || function () {};
        if (!_isArray(tasks)) {
          var err = new Error('First argument to waterfall must be an array of functions');
          return callback(err);
        }
        if (!tasks.length) {
            return callback();
        }
        var wrapIterator = function (iterator) {
            return function (err) {
                if (err) {
                    callback.apply(null, arguments);
                    callback = function () {};
                }
                else {
                    var args = Array.prototype.slice.call(arguments, 1);
                    var next = iterator.next();
                    if (next) {
                        args.push(wrapIterator(next));
                    }
                    else {
                        args.push(callback);
                    }
                    async.setImmediate(function () {
                        iterator.apply(null, args);
                    });
                }
            };
        };
        wrapIterator(async.iterator(tasks))();
    };
 </pre>


<p></p>

<!-- more -->


<p></p>

<p>开始先对参数进行了检查，判断tasks是否是一个function数组。然后使用了一个内部函数wrapIterator封装了实现。wrapIterator的参数带出了async.iterator函数：</p>

<pre> 
    async.iterator = function (tasks) {
        var makeCallback = function (index) {
            var fn = function () {
                if (tasks.length) {
                    tasks[index].apply(null, arguments);
                }
                return fn.next(); //这个地方有必要么？？？
            };
            fn.next = function () {
                return (index < tasks.length - 1) ? makeCallback(index + 1): null;
            };
            return fn;
        };
        return makeCallback(0);
    };
</pre>


<p> <br/>
这个函数，其主要实现是其内部函数makeCallback。其功能就是迭代tasks，封装其中的每一个function,让其执行后返回下一个function,以此实现迭代。</p>

<p>接下来，再回到wrapIterator，此function是对iterator的封装。执行后返回的是一个匿名function。其明确的参数只有一个err。当err不为空的时候，直接执行callback function。否则从index为1开始取出参数列表，并把iterator的下一个function包装之后push到args中（如果没有下一个function了则push回调函数）。接下来，则执行当前的iterator，执行的参数是下一个iterator function（作为这一步的回调函数）以及参数（如果当前的iterator被调用时传递了其他参数）。这样在当前iterator中回调下一个iterator，依次迭代执行，直至执行完所有function和callback。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[技术的成长]]></title>
    <link href="http://superhj1987.github.io/blog/2014/08/14/grow-up-in-tech/"/>
    <updated>2014-08-14T16:38:01+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/08/14/grow-up-in-tech</id>
    <content type="html"><![CDATA[<p>最近因为一件事情，让自己突然对自己产生了巨大的怀疑。工作一年多，仔细想想貌似真的只是在积累项目经验，而在技术深度上却一直停滞不前。这其中确也有因为之前做产品没有太多空闲时间的缘故，但更多的还是自己一直不得章法。对nginx源码的学习，一拖再拖，想成为这方面的专家却也不知道努力挤出时间或者说没有好的方法让自己合理安排出时间。</p>

<p>毕业的时候自己选择这里，就是想安心的做技术，以求在技术上得到长足的进步。现在却发现在做着一些没那么有技术含量的东西，像某人所说：上学的时候给我一定的时间也能够做出来。虽然我觉得上学的时候，大部分进公司做的东西也能做出来（除非是那种需要基于一定的环境像大数据、高并发才能做的）。但其实我明白，那句话的意思主要强调的是应该潜心去研究一门技术，比如hadoop、storm等，成为一个领域的专家。这也的确是自己的软肋，也的确该好好加强。</p>

<!--more-->


<p>这也牵扯到了技术的广度和深度的问题。这两个的优先级不能一味的说谁优谁劣，技术研究的人肯定倾向于去拓展技术的深度，而面向产品、架构的人应该关心广度多一些吧。当然如果不去精通一门技术，广度却也是无法拓展的。所谓技术上的成长，抛开技术的深度和广度来言，我觉得还是主要指技术思维的拓展和进步。技术领域的很多东西都是触类旁通的，只要你有好的逻辑思维和方法论，那么对于很多东西都是能很快上手直至掌握、运用、精通的。</p>

<p>还有一个上手能力和学习能力的问题，上手能力指的是你掌握然后使用，而学习能力应该是理解并能改进。这两个概念以前没去区分过，现在想想却也是有很大不同的。上手容易，精通难。所谓学习能力，是上手之后能够快速地吸收为自己的东西，能够从自己的角度看待问题，甚至提出自己的改进。很多人接触一个新的技术的确能够很快地上手去运用，但是却很少会深入地去学习这种技术的原理、运行机制之类的东西。这也是优秀开发人员和一般开发人员本质的区别。
学习技术，更是要学习其精髓而非皮毛，知其然更要知其所以然。</p>

<p>其实，总结来看，作为一个技术人，追求的技术上的长进，从多个维度来看，关键的还是项目经验和思维能力的同步提高。当然，如果对某一个领域能深入研究从而成为专家那也是锦上添花的事情。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx源码分析之基本数据结构]]></title>
    <link href="http://superhj1987.github.io/blog/2014/07/25/nginx-data-structure/"/>
    <updated>2014-07-25T17:08:02+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/07/25/nginx-data-structure</id>
    <content type="html"><![CDATA[<h3>引言</h3>

<p>nginx实现中有很多结构体，一般命名为ngx_xxx_t。这些结构体分散在许多头文件中。src/core/ngx_core.h中把几乎所有的头文件都集合起来。也因此造成了nginx各部分源代码的耦合。但实际上nginx各个部分逻辑划分还是很明确的，整体上是一种松散的结构。</p>

<p>作者之所以重复造了这些轮子，无非是为了追求高效。查看这些数据结构的源码，的确是设计的比较精巧，也保证了对内存足够小的占用以及各种操作的高效。</p>

<!--more-->


<h3>数据结构</h3>

<p>nginx实现中有很多结构体，一般命名为ngx_XXX_t。这些结构体分散在许多头文件中。src/core/ngx_core.h中把几乎所有的头文件都集合起来。也因此造成了nginx各部分源代码的耦合。但实际上nginx各个部分逻辑划分还是很明确的，整体上是一种松散的结构。</p>

<ul>
<li><p>ngx_str_t</p>

<pre><code>  typedef struct{
      size_t len;
      u_char *data;
  }ngx_str_t;
</code></pre></li>
</ul>


<p>这是nginx对字符串的实现，源码在ngx_string.h中。len指的是字符串的长度（不包括\0），data指向字符串。这种设计一方面，在计算字符创长度时只需要读取len字段即可，另一方面可以重复引用一段字符串内存。</p>

<p>常用api:</p>

<pre><code>    #define ngx_string(str) { sizof(str) - 1},(u_char *) str } //从一个普通字符串构造出一个nginx字符串，用sizeof计算长度，故参数必须是一个常量字符串。

    #define ngx_null_string {0,NULL}

    ngx_strncmp(s1,s2,n)

    ngx_strcm(s1,s2)
</code></pre>

<ul>
<li><p>ngx_pool_t</p>

<pre><code>  struct ngx_pool_s {
      ngx_pool_data_t       d;
      size_t                max;
      ngx_pool_t           *current;
      ngx_chain_t          *chain;
      ngx_pool_large_t     *large;
      ngx_pool_cleanup_t   *cleanup;
      ngx_log_t            *log;
  };
</code></pre></li>
</ul>


<p>这个数据结构在nginx中是一个非常重要的数据结构。用来管理一系列的资源（如内存、文件等
，使得对这些资源的使用和释放统一进行。这个是在c语言编程中值得借鉴的一个东西，代码中如果到处都是malloc和free的话，不仅会导致内存泄露，也会使代码难以阅读和维护。</p>

<ul>
<li><p>ngx_array_t</p>

<pre><code>  struct ngx_array_s {
      void        *elts; //指向实际的存储区域
      ngx_uint_t   nelts; //数组实际元素个数
      size_t       size; //数组单个元素的大小，单位是字节
      ngx_uint_t   nalloc; //数组的容量
      ngx_pool_t  *pool; //该数组用来分配内存的内存池
  };
</code></pre></li>
<li><p>ngx_hash_t</p>

<ul>
<li>ngx_hash_t不像其他的hash表的实现，可以插入删除元素，只能一次初始化。</li>
<li><p>解决冲突使用的是开链法，但实际上是开了一段连续的存储空间，和数组差不多。            <br/>
      ngx_int_t ngx_hash_init(ngx_hash_init_t <em>hinit, ngx_hash_key_t </em>names,ngx_uint_t nelts);//ngx_hash_t的初始化。</p>

<pre><code>  ngx_hash_init_t提供了初始化一个hash表所需要的一些基本信息
  typedef struct {
      ngx_hash_t       *hash; //指向hash表
      ngx_hash_key_pt   key; //指向从字符串生成hash值的hash函数。默认的实现为ngx_hash_key_lc
      ngx_uint_t        max_size; //hash表中的桶的个数
      ngx_uint_t        bucket_size; //每个桶的最大限制大小，单位是字节
      char             *name; //hash表的名字
      ngx_pool_t       *pool; //hash表分配内存使用的pool
      ngx_pool_t       *temp_pool; //使用的临时pool,初始化完成后，可以释放和销毁
  } ngx_hash_init_t;

  typedef struct {                ngx_str_t         key;              ngx_uint_t        key_hash;             void             *value;            } ngx_hash_key_t;
  void *ngx_hash_find(ngx_hash_t *hash, ngx_uint_t key, u_char *name, size_t len); //在hash里面查找key对应的value。          
</code></pre></li>
</ul>
</li>
<li><p>ngx_chain_t</p></li>
</ul>


<p>nginx的filter模块在处理从别的filter模块或者是handler模块传递过来的数据，数据一个链表的形式（ngx_chain_t）进行传递。</p>

<pre><code>        struct ngx_chain_s {
            ngx_buf_t    *buf;
            ngx_chain_t  *next;
        };
</code></pre>

<p>创建ngx_chain_t对象</p>

<pre><code>        ngx_chain_t *ngx_alloc_chain_link(ngx_pool_t *pool);
</code></pre>

<p>释放一个ngx_chain_t类型的对象。如果要释放整个chain，则迭代此链表，对每个节点使用此宏即可。</p>

<pre><code>        释放一个ngx_chain_t类型的对象。如果要释放整个chain，则迭代此链表，对每个节点使用此宏即可。
</code></pre>

<ul>
<li>ngx_buf_t</li>
</ul>


<p>ngx_buf_t是ngx_chain_t的数据结点</p>

<pre><code>    struct ngx_buf_s {
        u_char          *pos;
        u_char          *last;
        off_t            file_pos;
        off_t            file_last;

        u_char          *start;         /* start of buffer */
        u_char          *end;           /* end of buffer */
        ngx_buf_tag_t    tag;
        ngx_file_t      *file;
        ngx_buf_t       *shadow;


        /* the buf's content could be changed */
        unsigned         temporary:1;

        /*
        * the buf's content is in a memory cache or in a read only memory
        * and must not be changed
        */
        unsigned         memory:1;

        /* the buf's content is mmap()ed and must not be changed */
        unsigned         mmap:1;

        unsigned         recycled:1;
        unsigned         in_file:1;
        unsigned         flush:1;
        unsigned         sync:1;
        unsigned         last_buf:1;
        unsigned         last_in_chain:1;

        unsigned         last_shadow:1;
        unsigned         temp_file:1;

        /* STUB */ int   num;
    };
</code></pre>

<ul>
<li>ngx_list_t</li>
</ul>


<p>和普通的链表实现相比，它的节点是一个固定大小的数组。在初始化的时候，我们需要设定元素需要占用的空间大小，每个节点数组的容量大小。在添加元素到这个list里面的时候，会在最尾部的节点里的数组上添加元素，如果这个节点的数组存满了，就再增加一个新的节点到这个list里面去。</p>

<pre><code>    typedef struct {
        ngx_list_part_t  *last; //指向该链表的最后一个节点
        ngx_list_part_t   part; //指向该链表首个存放具体元素的节点
        size_t            size; //链表中存放的具体元素所需内存大小
        ngx_uint_t        nalloc; //每个节点所含的固定大小的数组的容量
        ngx_pool_t       *pool; //该list使用的分配内存的pool
    } ngx_list_t;

    struct ngx_list_part_s {
        void             *elts; //节点中存放具体元素的内存的开始地址   
        ngx_uint_t        nelts; //节点中已有元素个数，不能大于 nalloc
        ngx_list_part_t  *next; //指向下一个节点
    };

    ngx_list_t *ngx_list_create(ngx_pool_t *pool, ngx_uint_t n, size_t size); //创建一个ngx_list_t类型的对象,并对该list的第一个节点分配存放元素的内存空间。

    pool:   分配内存使用的pool。
    n:  每个节点固定长度的数组的长度。
    size:   存放的具体元素的个数。
</code></pre>

<ul>
<li><p>ngx_queue_t</p>

<pre><code>  struct ngx_queue_s {
      ngx_queue_t  *prev;
      ngx_queue_t  *next;
  };
</code></pre></li>
</ul>


<p>链表节点的数据成员并没有生命在链表节点的结构体中，只是声明了前向和后向指针。使用的时候需要定义一个哨兵节点。具体存放数据的节点称之为数据节点。对于数据节点，需要在数据结构体中加入一个类型为ngx_queue_s的域。使用下面的函数进行数据插入，其中x为数据节点的queue_t域。</p>

<pre><code>    #define ngx_queue_insert_head(h, x)                         \
        (x)-&gt;next = (h)-&gt;next;                                  \
        (x)-&gt;next-&gt;prev = x;                                    \
        (x)-&gt;prev = h;                                          \
        (h)-&gt;next = x

    #define ngx_queue_insert_after   ngx_queue_insert_head

    #define ngx_queue_insert_tail(h, x)                          \
        (x)-&gt;prev = (h)-&gt;prev;                                   \
        (x)-&gt;prev-&gt;next = x;                                     \
        (x)-&gt;next = h;                                           \
        (h)-&gt;prev = x
    获得数据时，使用ngx_queue_data()宏。
    #define ngx_queue_data(q, type, link)                        \
        (type *) ((u_char *) q - offsetof(type, link))
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《白帽子讲Web安全》读书笔记]]></title>
    <link href="http://superhj1987.github.io/blog/2014/07/24/web-security-notes/"/>
    <updated>2014-07-24T21:30:20+08:00</updated>
    <id>http://superhj1987.github.io/blog/2014/07/24/web-security-notes</id>
    <content type="html"><![CDATA[<p>最近一直在忙着易信公众平台的开发工作，一直没能抽出空来总结一下。周末终于有了一些空闲，就把这本书的笔记写了一下。</p>

<p>整本书四篇十八章，包括世界观安全、客户端脚本安全、服务端应用安全以及互联网公司安全运营四大部分。</p>

<h3>一、世界观安全</h3>

<ol>
<li>黑帽子和白帽子这两个概念，前者指的是利用安全技术进行破坏的哪一类黑客，后者则指的是工作在反黑客领域的安全技术专家。</li>
<li>安全问题的本质是信任的问题。并且安全是一个持续的过程，并不存在所谓的银弹。</li>
<li>安全三要素：机密性、完整性、可用性</li>
<li>一个安全评估的过程可以分为4个阶段：资产等级划分、威胁分析、风险分析、确认解决方案。其中威胁分析的一种建模方法是微软提出的STRIDE模型；风险分析则是DREAD模型，Risk = Probability * Damage Potenial。</li>
<li>白帽子并发有以下几个原则：Secure By Default原则；纵深防御原则（Defense in Depth）；数据与代码分离原则；不可预测性原则。</li>
</ol>


<!--more-->


<h3>二、客户端脚本安全</h3>

<ol>
<li><p>浏览器安全</p>

<p> 同源策略（Same Origin Policy）防止了跨域读写某些资源。
浏览器提供了浏览器沙箱，使进程在一个相对独立的空间运行，能在一定程度上保护浏览器安全。</p></li>
<li><p>跨站脚本攻击</p>

<p> 跨站脚本攻击主要是注入到网站内容中，授权用户访问内容时执行一段恶意代码，从而获取用户的私密信息或者进行破坏。通常叫做XSS攻击，是针对动态网站的攻击。</p></li>
<li><p>跨站点请求伪造</p>

<p> CSRF，指的是伪造出一个请求，诱使授权用户访问，以授权用户的身份去执行请求，从而达到对授权用户信息的读取、攻击等。</p></li>
<li><p>点击劫持</p>

<p> Click jacking，是指将恶意代码隐藏在看似无害的内容后者按钮之下，诱导用户访问的一种手段。</p></li>
<li><p>Html5安全</p>

<ul>
<li>HTML引入了很多新的标签，一些XSS Filter可能并没有覆盖这些新增的标签和功能。比如video、audio、iframe的sandbox。此外使用canvas可以在浏览器环境中实现对验证码的在线破解，大大降低了攻击的门槛。</li>
<li>跨域请求的Orgin Header和Access-Control-Allow-Origin的设置。postMessage的引入，使XSS PayLoad变得更加的灵活。</li>
</ul>
</li>
</ol>


<h3>三、服务端安全</h3>

<ol>
<li><p>注入攻击</p>

<p> 注入攻击是一种普遍的利用数据库SQL语句进行攻击的方式。使用用户提交的数据拼接数据库操作字符串，如果这些字符串中包含一些特殊字符就有可能查询到数据库关键信息。</p></li>
<li><p>文件上传漏洞</p>

<p> 通常的一个问题就是对上传文件的格式控制不严格，并且文件存放的路径可以通过Web路径直接进行访问；另一种方式，就是文件路径是通过表单的方式提交的，可以使用一个特殊字符“\0”截断文件路径，从而实现对脚本文件的上传。</p></li>
<li><p>认证与会话管理</p>

<p> 用户的登录状态一般是进过认证之后保存在服务端的，与服务器端的一系列交互即会话。一般对会话的管理。。。</p></li>
<li><p>访问控制</p>

<p> 对于系统中不同的用户具有不同的权限，对这些权限进行控制即访问控制。如果访问控制不严就容易形成漏洞被利用。</p></li>
<li><p>加密算法与随机数</p>

<p> 系统中对数据进行加密使用的加密算法和随机数生成算法的安全性和健壮性都直接关系到整个系统的安全性。对称加密、非对称加密的密钥的安全性，随机数算法的随机性都是要考虑的问题。</p></li>
<li><p>Web框架安全</p>

<p> 一些经典的使用率较高的Web框架如：Spring、Struts、Hibernate本身会在整个执行体系中有一些安全漏洞。比如前一阵的Struts2的命令执行漏洞，就是因为在OGNL中可以执行JAVA静态方法造成的。</p></li>
<li><p>应用层拒绝服务攻击</p>

<p> DOS，这种攻击是以耗尽服务器资源为目的攻击。DDOS分布式 拒绝服务攻击，是DOS的加强版。防范拒绝服务攻击要从访问入口处进行，限制来自统一IP的访问频率或者就是最大化提升系统的负载能力。</p></li>
<li><p>PHP安全和Web服务器配置安全</p>

<p> 针对与PHP本身的一些API的特点，可以在代码层面进行安全控制。比如，对数据库SQL相关的操作，要对用户输入的参数进行mysql_real_esape等。此外，对于Web Server如Apache http server，对其magic_quote,GLOBAL等配置要权衡关闭和开启是否会对系统的安全造成威胁。</p></li>
</ol>


<h3>四、互联网公司安全运营</h3>

<p>除了在技术层面对安全进行保证外，还可以在业务层面对安全进行最大化的保障。此外，微软提出的 SDL安全开发流程，运用在项目开发过程中能够很好地保障系统的安全。而运营方面的安全保障则能够进一步保证整个系统的安全性。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[杂感一篇]]></title>
    <link href="http://superhj1987.github.io/blog/2013/07/06/no-name/"/>
    <updated>2013-07-06T16:57:45+08:00</updated>
    <id>http://superhj1987.github.io/blog/2013/07/06/no-name</id>
    <content type="html"><![CDATA[<p>最近两部关于青春的片子《致青春》和《中国合伙人》，对于前者这种爱情的东西，从某个时间段开始，我早已不愿关注，也许是害怕触动心里某些痛处吧。后者讲述的奋斗、梦想，却是我特别想看一看的。虽然我知道成功学这东西，完全是一群成功了的人在吹嘘当年自己有多苦逼，后来变得多NB。但是他们的成功却的确能触动自己心里的那根神经，唤起自己当初的激情。</p>

<p>十几年前，自己无意之中说出的一句话，到现在也算一直坚持了下来。虽然没有功成名就，但到现在还是不至于令自己失望的。平淡的日子往往让自己忘了自己当初的梦想，也忘了走向它的这条路。今天看《中国合伙人》这部影片又像当初看《社交网络》一样让自己全身瞬间充满了能量，同时也让自己拷问着自己：还坚持当初的梦想吗？正在为梦想努力吗？努力有收获吗？其实，现实中大多数人在说自己梦想的时候都能侃侃而谈，而真正能付诸于努力的人却寥寥可数。为梦想而努力，结果不一定是成功，但没有为此而努力过，那也许会成为一辈子最大的憾事。</p>

<p>电影里三个人的友情是让我感触颇深的另一个地方。想想自己，活了快26年，真正能称得上朋友的人其实就那么几个人。和他们在一起，你会很确定不管你怎么样，他们都不会嫌弃你；不管你跟他们说了什么话，他们也不会介意。心情不好的时候，一个电话，他们不管有多忙也会立马赶到你的身旁。其实，以前的自己挺自私的，有点像孟晓峻，自从经历了那件事之后，我才体会到友情是多么的珍贵，也才弥足珍惜现在的他们。</p>

<p>不说什么下决心的话，能做的就是脚踏实地，朝着自己想去的那个方向努力。</p>
]]></content>
  </entry>
  
</feed>
