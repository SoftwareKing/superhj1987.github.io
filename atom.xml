<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[后端技术杂谈 | 飒然Hang]]></title>
  <link href="http://www.rowkey.me/atom.xml" rel="self"/>
  <link href="http://www.rowkey.me/"/>
  <updated>2016-05-24T15:47:58+08:00</updated>
  <id>http://www.rowkey.me/</id>
  <author>
    <name><![CDATA[飒然Hang]]></name>
    <email><![CDATA[superhj1987@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[谈谈Java内存管理]]></title>
    <link href="http://www.rowkey.me/blog/2016/05/07/javamm/"/>
    <updated>2016-05-07T14:59:44+08:00</updated>
    <id>http://www.rowkey.me/blog/2016/05/07/javamm</id>
    <content type="html"><![CDATA[<h2>目录</h2>

<ul>
<li><a href="#%E4%B8%80.%20%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86">一. 背景知识</a></li>
<li><a href="#%E4%BA%8C.%20Jvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%86%85%E5%AD%98%E7%AE%80%E4%BB%8B">二. Jvm虚拟机内存简介</a></li>
<li><a href="#%E4%B8%89.%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86">三. 垃圾收集</a></li>
<li><a href="#%E5%9B%9B.%20Java7%E3%80%818%E5%B8%A6%E6%9D%A5%E7%9A%84%E4%B8%80%E4%BA%9B%E5%8F%98%E5%8C%96">四. Java7、8带来的一些变化</a></li>
</ul>


<p><img src="http://www.rowkey.me/images/blog_images/java.jpg" alt="java" /></p>

<p>对于一个Java程序员来说，大多数情况下的确是无需对内存的分配、释放做太多考虑，对Jvm也无需有多么深的理解的。但是，在写程序的过程中却也往往因为这样而造成了一些不容易察觉到的内存问题，并且在内存问题出现的时候，也不能很快的定位并解决。因此，了解并掌握Java的内存管理是一个合格的Java程序员必须的，也只有这样才能写出更好的程序，更好地优化程序的性能。</p>

<!--more-->


<h2><a name='一. 背景知识'></a>一. 背景知识</h2>

<p>根据网络可以找到的资料以及笔者能够打听到的消息，目前国内外著名的几个大型互联网的语言选型概括如下：</p>

<ol>
<li>Google: c/c++ python java js，不得不提的是Google贡献给java社区的guava包质量非常高。</li>
<li>Youtube、豆瓣: python</li>
<li>fackbook、yahoo、flickr、新浪：<strong>php</strong>(优化过的php)</li>
<li>网易、阿里、搜狐: java、php、node.js</li>
<li>Twitter: ruby->java,之所以如此就在于与jvm相比，Ruby的runtime是非常慢的。并且ruby的应用比起java还是比较小众的。</li>
</ol>


<p>可见，虽然最近这些年很多言论都号称java已死或者不久即死，但是Java的语言应用占有率一直居高不下。与高性能的c/c++相比，java具有gc机制，并且没有那让人望而生畏的指针，上手门槛相对较低；而与上手成本更低的php、ruby来说，又比这些脚本语言有性能上的优势(这里暂时忽略fb自己开发的php vm)。</p>

<p>对于Java来说，最终是要依靠字节码运行在jvm上的。目前，常见的jvm有以下几种：</p>

<ul>
<li>Sun HotSpot</li>
<li>BEA Jrockit</li>
<li>IBM J9</li>
<li>Dalvik(Android)</li>
</ul>


<p>其中以HotSpot应用最广泛。目前sun jdk的最新版本已经到了8，但鉴于新版的jdk使用并未普及，因此本文仅仅针对HotSpot虚拟机的jdk6来讲。</p>

<h2><a name='二. Jvm虚拟机内存简介'></a>二. Jvm虚拟机内存简介</h2>

<h3>2.1 Java运行时内存区</h3>

<p>Java的运行时内存组成如下图所示：</p>

<p><img src="http://www.rowkey.me/images/blog_images/java-runtime-memory.jpg" alt="java-runtime-memory.jpg" /></p>

<p>其中，对于这各个部分有一些是线程私有的，其他则是线程共享的。</p>

<p><strong>线程私有的如下：</strong></p>

<ul>
<li><p>程序计数器</p>

<p>  当前线程所执行的字节码的行号指示器</p></li>
<li><p>Java虚拟机栈</p>

<p>  Java方法执行的内存模型，每个方法被执行时都会创建一个栈帧，存储局部变量表、操作栈、动态链接、方法出口等信息。</p></li>
<li><p>本地方法栈</p>

<p>  Native方法服务。在HotSpot虚拟机中和Java虚拟机栈合二为一。</p></li>
</ul>


<p><strong>线程共享的如下：</strong></p>

<ul>
<li><p>Java堆</p>

<p>  存放对象实例，几乎所有的对象实例都在这里分配内存。</p></li>
<li><p>方法区</p>

<p>  存储已经被虚拟机加载的类信息、常量、静态变量、JIT编译后的代码等数据。</p></li>
<li><p>运行时常量池</p>

<p>  方法区的一部分。用于存放编译期生成的各种字面量和符号引用。</p></li>
<li><p>直接内存</p>

<p>  NIO、Native函数直接分配的堆外内存。DirectBuffer引用也会使用此部分内存。</p></li>
</ul>


<h3>2.2 对象访问</h3>

<p>Java是面向对象的一种编程语言，那么如何通过引用来访问对象呢？一般有两种方式：</p>

<ol>
<li><p>通过句柄访问</p>

<p> <image src="http://www.rowkey.me/images/blog_images/access_object_handler.png" width="500px"/></p></li>
<li><p>直接指针</p>

<p> <image src="http://www.rowkey.me/images/blog_images/access_direct.png" width="500px"/></p>

<p> 此种方式也是HotSpot虚拟机采用的方式。</p></li>
</ol>


<h3>2.3 内存溢出</h3>

<p>在JVM申请内存的过程中，会遇到无法申请到足够内存，从而导致内存溢出的情况。一般有以下几种情况：</p>

<ul>
<li>虚拟机栈和本地方法栈溢出

<ul>
<li>StackOverflowError: 线程请求的栈深度大于虚拟机所允许的最大深度(循环递归)</li>
<li>OutOfMemoryError: 虚拟机在扩展栈是无法申请到足够的内存空间，一般可以通过不停地创建线程引起此种情况</li>
</ul>
</li>
<li>Java堆溢出: 当创建大量对象并且对象生命周期都很长的情况下，会引发OutOfMemoryError</li>
<li>运行时常量区溢出：OutOfMemoryError:PermGen space，这里一个典型的例子就是String的intern方法，当大量字符串使用intern时，会触发此内存溢出</li>
<li>方法区溢出：方法区存放Class等元数据信息，如果产生大量的类(使用cglib)，那么就会引发此内存溢出，OutOfMemoryError:PermGen space，在使用Hibernate等框架时会容易引起此种情况。</li>
</ul>


<h2><a name='三. 垃圾收集'></a>三. 垃圾收集</h2>

<h3>3.1 理论基础</h3>

<h4>在通常情况下，我们掌握java的内存管理就是为了应对网站/服务访问慢，慢的原因一般有以下几点：</h4>

<ul>
<li>内存：垃圾收集占用cpu；放入了太多数据，造成内存泄露(java也是有这种问题的^_^)</li>
<li>线程死锁</li>
<li>I/O速度太慢</li>
<li>依赖的其他服务响应太慢</li>
<li>复杂的业务逻辑或者算法造成响应的缓慢</li>
</ul>


<p>其中，垃圾收集对性能的影响一般有以下几个：</p>

<ul>
<li>内存泄露</li>
<li>程序暂停</li>
<li>程序吞吐量显著下降</li>
<li>响应时间变慢</li>
</ul>


<h4>先来看垃圾收集的一些基本概念</h4>

<ul>
<li>Concurrent Collector:收集的同时可运行其他的工作进程</li>
<li>Parallel Collector: 使用多CPU进行垃圾收集</li>
<li>Stop-the-word(STW):收集时必须暂停其他所有的工作进程</li>
<li>Sticky-reference-count：对于使用“引用计数”（reference count）算法的GC，如果对象的计数器溢出，则起不到标记某个对象是垃圾的作用了，这种错误称为sticky-reference-count problem，通常可以增加计数器的bit数来减少出现这个问题的几率，但是那样会占用更多空间。一般如果GC算法能迅速清理完对象，也不容易出现这个问题。</li>
<li>Mutator：mutate的中文是变异，在GC中即是指一种JVM程序，专门更新对象的状态的，也就是让对象“变异”成为另一种类型，比如变为垃圾。</li>
<li>On-the-fly：用来描述某个GC的类型：on-the-fly reference count garbage collector。此GC不用标记而是通过引用计数来识别垃圾。</li>
<li>Generational gc：这是一种相对于传统的“标记-清理”技术来说，比较先进的gc，特点是把对象分成不同的generation，即分成几代人，有年轻的，有年老的。这类gc主要是利用计算机程序的一个特点，即“越年轻的对象越容易死亡”，也就是存活的越久的对象越有机会存活下去（姜是老的辣）。</li>
</ul>


<h4>牵扯到垃圾收集，还需要搞清楚吞吐量与响应时间的含义</h4>

<ul>
<li>吞吐量是对单位时间内完成的工作量的量度。如：每分钟的 Web 服务器请求数量</li>
<li>响应时间是提交请求和返回该请求的响应之间使用的时间。如：访问Web页面花费的时间</li>
</ul>


<p>吞吐量与访问时间的关系很复杂，有时可能以响应时间为代价而得到较高的吞吐量，而有时候又要以吞吐量为代价得到较好的响应时间。而在其他情况下，一个单独的更改可能对两者都有提高。通常，平均响应时间越短，系统吞吐量越大；平均响应时间越长，系统吞吐量越小；
但是，系统吞吐量越大， 未必平均响应时间越短；因为在某些情况（例如，不增加任何硬件配置）吞吐量的增大，有时会把平均响应时间作为牺牲，来换取一段时间处理更多的请求。</p>

<p>针对于Java的垃圾回收来说，不同的垃圾回收器会不同程度地影响这两个指标。例如：并行的垃圾收集器，其保证的是吞吐量，会在一定程度上牺牲响应时间。而并发的收集器，则主要保证的是请求的响应时间。</p>

<h4>对于GC(垃圾回收)的流程的基本描述如下：</h4>

<ul>
<li>找出堆中活着的对象</li>
<li>释放死对象占用的资源</li>
<li>定期调整活对象的位置</li>
</ul>


<h4>GC算法一般有以下几种：</h4>

<ul>
<li>Mark-Sweep 标记-清除</li>
<li>Mark-Sweep-Compact 标记-整理</li>
<li><p>Copying Collector 复制算法</p></li>
<li><p>Mark-标记</p>

<p> 从&#8221;GC roots&#8221;开始扫描(这里的roots包括线程栈、静态常量等)，给能够沿着roots到达的对象标记为&#8221;live&#8221;,最终所有能够到达的对象都被标记为&#8221;live&#8221;,而无法到达的对象则为&#8221;dead&#8221;。效率和存活对象的数量是线性相关的。</p></li>
<li><p>Sweep-清除</p>

<p> 扫描堆，定位到所有&#8221;dead&#8221;对象，并清理掉。效率和堆的大小是线性相关的。</p></li>
<li><p>Compact-压缩</p>

<p> 对于对象的清除，会产生一些内存碎片，这时候就需要对这些内存进行压缩、整理。包括：relocate(将存货的对象移动到一起，从而释放出连续的可用内存)、remap(收集所有的对象引用指向新的对象地址)。效率和存活对象的数量是线性相关的。</p></li>
<li><p>Copy-复制</p>

<p> 将内存分为&#8221;from&#8221;和&#8221;to&#8221;两个区域，垃圾回收时，将from区域的存活对象整体复制到to区域中。效率和存活对象的数量是线性相关的。</p></li>
</ul>


<p>其中，Copy对比Mark-sweep</p>

<ol>
<li>内存消耗：copy需要两倍的最大live set内存；mark-sweep则只需要一倍。</li>
<li>效率上：copy与live set成线性相关，效率高；mark-sweep则与堆大小线性相关，效率较低。</li>
</ol>


<h4>分代收集是目前比较先进的垃圾回收方案</h4>

<p>对于分代收集，有以下几个相关理论</p>

<ul>
<li>分代假设：大部分对象的寿命很短，“朝生夕死”，重点放在对年青代对象的收集，而且年青代通常只占整个空间的一小部分。</li>
<li>把年青代里活的很长的对象移动到老年代。</li>
<li>只有当老年代满了才去收集。</li>
<li>收集效率明显比不分代高。</li>
</ul>


<p>HotSpot虚拟机的分代收集，分为一个Eden区、两个Survivor去以及Old Generation/Tenured区，其中Eden以及Survivor共同组成New Generatiton/Young space。</p>

<p><image src="http://www.rowkey.me/images/blog_images/hotspot-gc.png" width="300px"/></p>

<ul>
<li>Eden区是分配对象的区域。</li>
<li>Survivor是minor/younger gc后存储存活对象的区域。</li>
<li>Tenured区域存储长时间存活的对象。</li>
</ul>


<h4>分代收集中典型的垃圾收集算法组合描述如下：</h4>

<ul>
<li>年青代通常使用Copy算法收集，会stop the world</li>
<li>老年代收集一般采用Mark-sweep-compact, 有可能会stop the world，也可以是concurrent或者部分concurrent。</li>
</ul>


<h3>3.2 HotSpot垃圾收集器</h3>

<p><image src="http://www.rowkey.me/images/blog_images/hotspot-collector.png" width="300px"/></p>

<p>上图即为HotSpot虚拟机的垃圾收集器组成。</p>

<h4>Serial收集器</h4>

<ul>
<li>-XX:+UserSerialGC参数打开此收集器</li>
<li>Client模式下新生代默认的收集器。</li>
<li>较长的stop the world时间</li>
<li>简单而高效</li>
</ul>


<p>此收集器的一个工作流程如下如所示：</p>

<p>收集前：</p>

<p><image src="http://www.rowkey.me/images/blog_images/serial_before.png" width="400px"/></p>

<p>收集后：</p>

<p><image src="http://www.rowkey.me/images/blog_images/serial_after.png" width="400px"/></p>

<h4>ParNew收集器</h4>

<ul>
<li>-XX:+UserParNewGC</li>
<li>+UseConcuMarkSweepGC时默认开启</li>
<li>Serial收集器的多线程版本</li>
<li>默认线程数与CPU数目相同</li>
<li>-XX:ParrallelGCThreads指定线程数目</li>
</ul>


<p>对比Serial收集器如下图所示：</p>

<p><image src="http://www.rowkey.me/images/blog_images/parnew.png" width="400px"/></p>

<h4>Parallel Scavenge收集器</h4>

<ul>
<li>新生代并行收集器</li>
<li>采用Copy算法</li>
<li>主要关注的是达到可控制的吞吐量，“吞吐量优先”</li>
<li>-XX:MaxGCPauseMillis -XX:GCTimeRAtion两个参数精确控制吞吐量</li>
<li>-XX:UseAdaptiveSizePolicy GC自适应调节策略</li>
<li>Server模式的默认新生代收集器</li>
</ul>


<h4>Serial Old收集器</h4>

<ul>
<li>Serial的老年代版本</li>
<li>Client模式的默认老年代收集器</li>
<li>CMS收集器的后备预案，Concurrent Mode Failure时使用</li>
<li>-XX:+UseSerialGC开启此收集器</li>
</ul>


<h4>Parallel Old收集器</h4>

<ul>
<li>-XX:+UseParallelGC -XX:+UseParallelOldGC启用此收集器</li>
<li>Server模式的默认老年代收集器</li>
<li>Parallel Scavenge的老年代版本，使用多线程和&#8221;mark-sweep&#8221;算法</li>
<li>关注点在吞吐量以及CPU资源敏感的场合使用</li>
<li>一般使用Parallel Scavenge + Parallel Old可以达到最大吞吐量保证</li>
</ul>


<h4>CMS收集器</h4>

<p>并发低停顿收集器</p>

<ul>
<li>-XX:UseConcMarkSweepGC 开启CMS收集器，(默认使用ParNew作为年轻代收集器，SerialOld作为收集失败的垃圾收集器)</li>
<li>以获取最短回收停顿时间为目标的收集器，重视响应速度，希望系统停顿时间最短，会和互联网应用。</li>
</ul>


<p>四个步骤：</p>

<ul>
<li>初始标记 Stop the world: 只标记GC roots能直接关联到的对象，速度很快。</li>
<li>并发标记：进行GC roots tracing，与用户线程并发进行</li>
<li>重新标记 Stop the world：修正并发标记期间因程序继续运行导致变动的标记记录</li>
<li>并发清除</li>
</ul>


<p>对比serial old收集器如下图所示：</p>

<p><image src="http://www.rowkey.me/images/blog_images/cms.png" width="400px"/></p>

<p>CMS有以下的缺点：</p>

<ul>
<li>CMS是唯一不进行compact的垃圾收集器，当cms释放了垃圾对象占用的内存后，它不会把活动对象移动到老年代的一端</li>
<li>对CPU资源非常敏感。不会导致线程停顿，但会导致程序变慢，总吞吐量降低。CPU核越多越不明显</li>
<li>无法处理浮动垃圾。可能出现“concurrent Mode Failure”失败， 导致另一次full GC ,可以通过调整-XX:CMSInitiatingOccupancyFraction来控制内存占用达到多少时触发gc</li>
<li>大量空间碎片。这个可以通过设置-XX:UseCMSCompacAtFullCollection(是否在full gc时开启compact)以及-XX:CMSFullGCsBeforeCompaction(在进行compact前full gc的次数)</li>
</ul>


<h4>G1收集器</h4>

<p>G1算法在Java6中还是试验性质的，在Java7中正式引入，但还未被广泛运用到生产环境中。它的特点如下：</p>

<ul>
<li>使用标记-清理算法</li>
<li>不会产生碎片</li>
<li>可预测的停顿时间</li>
<li>化整为零：将整个Java堆划分为多个大小相等的独立区域</li>
<li>-XX:+UseG1GC可以打开此垃圾回收器</li>
<li>-XX:MaxGCPauseMillis=200可以设置最大GC停顿时间，当然JVM并不保证一定能够达到，只是尽力。</li>
</ul>


<p><image src="http://www.rowkey.me/images/blog_images/g1.png" width="500px"/></p>

<h3>3.3 调优经验</h3>

<ul>
<li>需要打开gc日志并读懂gc日志：-XX:PrintHeapAtGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps</li>
<li>垃圾回收的最佳状态是只有young gc，也就是避免生命周期很长的对象的存在。</li>
<li>从young gc开始，尽量给年青代大点的内存，避免full gc</li>
<li>注意Survivor大小</li>
<li>注意内存墙：4G~5G</li>
</ul>


<h4>GC日志简介</h4>

<p><image src="http://www.rowkey.me/images/blog_images/gclog.png" width="500px"/></p>

<ul>
<li>第一个箭头：35592K->1814K(36288K)，箭头指向的是新生段的内存占用情况； - 第二个箭头：38508K->7792K(520256K)，箭头指向的是回收后的内存占用情况。</li>
<li>垃圾收集停顿时间：0.0336</li>
</ul>


<h4>老年代使用建议</h4>

<ul>
<li>Parallel GC(-XX:+UseParallel[Old]GC)

<ul>
<li>Parallel GC的minor GC时间是最快的， CMS的young gc要比parallel慢， 因为内存碎片</li>
<li>可以保证最大的吞吐量</li>
</ul>
</li>
<li><strong>确实有必要才改成CMS或G1(for old gen collections)</strong></li>
</ul>


<h4>开发建议</h4>

<ul>
<li>小对象allocate的代价很小，通常10个CPU指令；收集掉新对象也非常廉价；不用担心活的很短的小对象</li>
<li>大对象分配的代价以及初始化的代价很大；不同大小的大对象可能导致java堆碎片，尤其是CMS, ParallelGC 或 G1还好；尽量避免分配大对象</li>
<li>避免改变数据结构大小，如避免改变数组或array backed collections / containers的大小;对象构建（初始化）时最好显式批量定数组大小;改变大小导致不必要的对象分配，可能导致java堆碎片</li>
<li>对象池可能潜在的问题

<ul>
<li>增加了活对象的数量，可能增加GC时间</li>
<li>访问（多线程）对象池需要锁，可能带来可扩展性的问题</li>
<li>小心过于频繁的对象池访问</li>
</ul>
</li>
</ul>


<h2><a name='四. Java7、8带来的一些变化'></a>四. Java7、8带来的一些变化</h2>

<ul>
<li>Java7带来的内存方面的一个很大的改变就是String常量池从Perm区移动到了Heap中。调用String的intern方法时，如果存在堆中的对象，则会直接保存对象的引用，而不会重新创建对象。</li>
<li>Java8中，取消掉了方法区(永久代)，使用“元空间”替代，元空间只与系统内存相关。此外，java8带来了成熟的G1垃圾回收器。</li>
<li>Java 8 update 20所引入的一个很棒的优化就是G1回收器中的字符串去重（String deduplication）。由于字符串(包括它们内部的char[]数组）占用了大多数的堆空间，这项新的优化旨在使得G1回收器能识别出堆中那些重复出现的字符串并将它们指向同一个内部的char[]数组，以避免同一个字符串的多份拷贝，那样堆的使用效率会变得很低。你可以使用-XX:+UseStringDeduplication这个JVM参数来试一下这个特性。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[基于内容和用户画像的个性化推荐]]></title>
    <link href="http://www.rowkey.me/blog/2016/04/07/up-recommend/"/>
    <updated>2016-04-07T14:59:44+08:00</updated>
    <id>http://www.rowkey.me/blog/2016/04/07/up-recommend</id>
    <content type="html"><![CDATA[<p>基于内容和用户画像的个性化推荐，有两个实体：内容和用户。需要有一个联系这两者的东西，即为标签。内容转换为标签即为内容特征化，用户则称为用户特征化。因此，对于此种推荐，主要分为以下几个关键部分：</p>

<ul>
<li>标签库</li>
<li>内容特征化</li>
<li>用户特征化</li>
<li>隐语义推荐</li>
</ul>


<p>综合上面讲述的各个部分即可实现一个基于内容和用户画像的个性化推荐系统。如下图所示：</p>

<p><img src="http://www.rowkey.me/images/blog_images/up-recommend.png" alt="uc_interest" /></p>

<!--more-->


<h3>标签库</h3>

<p>标签是联系用户与物品、内容以及物品、内容之间的纽带，也是反应用户兴趣的重要数据源。标签库的最终用途在于对用户进行行为、属性标记。是将其他实体转换为计算机可以理解的语言关键的一步。</p>

<p>标签库则是对标签进行聚合的系统，包括对标签的管理、更新等。</p>

<p>一般来说，标签是以层级的形式组织的。可以有一级维度、二级维度等。</p>

<p>标签的来源主要有：</p>

<ul>
<li>已有内容的标签</li>
<li>网络抓取流行标签</li>
<li>对运营的内容进行关键词提取</li>
</ul>


<p>对于内容的关键词提取，使用<a href="https://github.com/fxsjy/jieba">结巴分词</a> + <a href="http://www.ruanyifeng.com/blog/2013/03/tf-idf.html">TFIDF</a>即可。此外，也可以使用<a href="http://www.tuicool.com/articles/UZ77Z3">TextRank</a>来提取内容关键词。</p>

<h3>内容特征化</h3>

<p>内容特征化即给内容打标签。目前有两种方式：</p>

<ul>
<li>人工打标签</li>
<li>机器自动打标签</li>
</ul>


<p>针对机器自动打标签，需要采取机器学习的相关算法来实现，即针对一系列给定的标签，给内容选取其中匹配度最高的几个标签。这不同于通常的分类和聚类算法。可以采取使用分词 + <a href="http://www.cnblogs.com/wowarsenal/p/3293586.html">Word2Vec</a>来实现，过程如下：</p>

<ul>
<li>将文本语料进行分词，以空格,tab隔开都可以，使用结巴分词。</li>
<li>使用word2vec训练词的相似度模型。</li>
<li>使用tfidf提取内容的关键词A,B,C。</li>
<li>遍历每一个标签，计算关键词与此标签的相似度之和。</li>
<li>取出TopN相似度最高的标签即为此内容的标签。</li>
</ul>


<h3>用户特征化</h3>

<p>用户特征化即为用户打标签。通过用户的行为日志和一定的模型算法得到用户的每个标签的权重。</p>

<ul>
<li>用户对内容的行为：点赞、不感兴趣、点击、浏览。对用户的反馈行为如<strong>点赞</strong>赋予权值1，<strong>不感兴趣</strong>赋予-1；对于用户的浏览行为，则可使用<strong>点击/浏览</strong>作为权值。</li>
<li>对内容发生的行为可以认为对此内容所带的标签的行为。</li>
<li>用户的兴趣是时间衰减的，即离当前时间越远的兴趣比重越低。时间衰减函数使用<strong>1/[log(t)+1]</strong>, t为事件发生的时间距离当前时间的大小。</li>
<li>要考虑到热门内容会干预用户的标签，需要对热门内容进行降权。使用<strong>click/pv</strong>作为用户浏览行为权值即可达到此目的。</li>
<li>此外，还需要考虑噪声的干扰，如标题党等。</li>
</ul>


<h3>隐语义推荐</h3>

<p>有了内容特征和用户特征，可以使用<a href="http://blog.csdn.net/harryhuang1990/article/details/9924377">隐语义模型</a>进行推荐。这里可以使用其简化形式，以达到实时计算的目的。</p>

<p>用户对于某一个内容的兴趣度(可以认为是CTR)：</p>

<p><img src="http://www.rowkey.me/images/blog_images/uc_interest.jpg" alt="uc_interest" /></p>

<p>其中i=1&hellip;N是内容c具有的标签，m(ci)指的内容c和标签i的关联度(可以简单认为是1),n(ui)指的是用户u的标签i的权重值,当用户不具有此标签时n(ui)=0，q&copy;指的是内容c的质量，可以使用点击率(click/pv)表示。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据杂谈]]></title>
    <link href="http://www.rowkey.me/blog/2016/02/23/data-talk/"/>
    <updated>2016-02-23T18:44:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2016/02/23/data-talk</id>
    <content type="html"><![CDATA[<h2>目录</h2>

<ul>
<li><a href="#%E5%89%8D%E8%A8%80">前言</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE">数据</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F">数据系统</a></li>
<li><a href="#%E5%A4%A7%E6%95%B0%E6%8D%AE">大数据</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1">数据统计</a></li>
<li><a href="#%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%A8%E8%8D%90">个性化推荐</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a></li>
<li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li>
</ul>


<h2><a name='前言'></a>前言</h2>

<p>记得几年前，曾经有人预测过未来最流行的三大技术：大数据、高并发、数据挖掘。到现在来看，这三种技术的确也随着这几年互联网的发展变得越发成熟和可靠。掌握这三种技术的人，不管是求职还是创业，都属于香饽饽。一个很深的印象就是当年研究生毕业的时候，专业是数据挖掘、大数据的学生都比较受各种企业的青睐，不管他是不是真的掌握了这些东西。虽然我对大部分高校的相关专业持怀疑态度，但是却也不得不承认，这些专业的确改变了很多东西，也给很多学生镀上了一层金。</p>

<p>自己一直从事的是Java EE中间件、基础架构等方面的研发工作，对数据这一块只是略知皮毛，在前东家的时候我也没有机会接触数据平台。但由于现公司业务的原因，却不得不去触碰这一块，到目前为止也就仅仅半年时间（其间穿插各种协调、管理的杂事）。因此，数据相关的东西对我来说完全是一个新的领域，算是离开了自己的舒适区。不过，逃离舒适区这个想想也挺兴奋的。</p>

<!--more-->


<h2><a name='数据'></a>数据</h2>

<h3>什么是数据？</h3>

<p>最近有一本很火的书叫《精益数据分析》，其核心的一个观点就是：需要用数据驱动产品和公司的发展，而不能靠直觉或者拍脑袋。可见，数据是多么的重要。在一个产品的生命周期中，会产生很多数据：用户信息、用户行为信息、ugc数据等等。这些数据表现形式可以为文字、图片、日志、视频、音频等等。</p>

<p>从技术角度来讲，数据一般分为结构化数据、半结构化数据和非结构化数据。</p>

<ul>
<li>结构化数据：指的是行数据库可以存储的，数据具有相同的字段，以及相同的存储大小,可以用二维表的逻辑结构来表达实现。</li>
<li>半结构化数据：半结构化数据，指的整体上是结构化数据形式，但字段数目不定，数据结构和内容混杂在一起。</li>
<li>非结构化数据：不方便用二维表描述的数据，如各种文档、图片、音/视频等。</li>
</ul>


<h3>能用来干什么?-数据挖掘</h3>

<p>说到数据的作用，不得不提数据分析师这个职位。此职位一般来说倾向的是数学相关专业人士，使用数据来指导产品、运营、市场等工作，是公司中使用数据最多的人。在公司中，市场运营销售这几个部门也都是和数据关系很密切的。市场需要参考数据分析哪一个渠道推广效果更好，运营部门需要根据数据分析什么内容更能提高产品的活跃度，销售部门则需要数据反映公司的收入情况。当然，除了这些，数据挖掘就是另一个很重要的使用数据的方面了，可以使用数据对用户进行行为分析，从而挖掘用户的兴趣，最终达到精准推荐、精准营销的目的。</p>

<p>概括来看，数据的作用就是数据挖掘，就是试图从海量数据中找出有用的知识，也可以称为“知识发现”。数据挖掘的支撑技术主要包含统计学以及机器学习两方面。从这个角度来看，数据主要有以下两点作用：</p>

<ul>
<li>数据统计：通过对数据的统计计算出一些和产品、用户相关的指标，从而指导产品、市场、运营、销售工作。</li>
<li>机器学习：使用相关技术让机器通过已有的数据学习到新的有用的知识。比如：从已有的用户行为数据分析得到用户的兴趣、爱好等信息，从而进一步实现用户个性化推荐。个性化推荐也是机器学习目前使用数据最为广泛的一点。</li>
</ul>


<h3>数据库&amp;&amp;数据仓库</h3>

<p>有了数据，就需要有存放数据的地方。数据库和数据仓库即存放数据库的两种形式。两者在本质上没有区别，都是为了存储数据。</p>

<ul>
<li><p>数据库：面向业务设计，一般针对的是在线业务，存储的是在线业务数据。如：Oracle、DB2、MySQL、Sybase、MS SQL Server等。可以分为：关系型数据库和NoSql数据库，其中后者又可分为KV数据库、文档型数据库、列数据库。</p></li>
<li><p>数据仓库：是数据库概念的升级，面向分析，存储的是历史数据。从数据量来说，数据仓库要比数据库更庞大得多。主要用于数据挖掘和数据分析，代表软件为Hive。</p></li>
</ul>


<p>ETL: 数据仓库很多时候是需要从其他地方传输数据到数据仓库，这个过程就是ETL：extract-抽取、transform-转换、load-加载。</p>

<h3>数据的生命周期</h3>

<p>无论是历史数据还是线上数据，都是有生命周期的。比如，对于一个产品的用户活跃度统计业务，最近半年的数据是热点数据，访问较频繁；而随着时间的推移，慢慢的这些数据不再被频繁关注，变为了一般数据；再随着时间的推移，总有一天这些数据不再会被关注就成为了冷数据。</p>

<p>热点数据→一般数据→冷数据，这就是数据的一个生命周期，对于不同的生命周期，所需要的技术选型也应该不一样。</p>

<h2><a name='数据系统'></a>数据系统</h2>

<p>不管是数据统计还是数据挖掘，构建一个数据系统都是做好这些的前提。一般来说，构建一个完备的数据系统有以下几点：</p>

<ol>
<li><p>数据采集</p>

<p> 无论是移动端还是web上，要做好数据采集集最重要的一点就是埋点。也就是要在你需要采集数据的地方做一个标记，向服务端发起一个日志请求。当然，对于服务端能够通过业务逻辑获取的内容，原则上不要打点。比如，统计某一篇新闻的阅读数目、点赞数，这些行为其实在用户打开此新闻、点赞时已经发起了服务端请求，不需要再埋一个点；此外，统计用户数目这种，在用户数据库中就可以计算出来，也不需要埋点。埋点主要针对的是通过产品的业务逻辑无法获取到的一些数据，如一个站点中某一个模块的pv、uv等。</p>

<p> 埋点后向服务端发起日志请求，这些请求在用户量规模并不很大的架构设计中直接实时计算数据入库即可，但是在用户请求量很大的情况下，这种设计是有问题的，会增加业务请求的压力，从而影响线上服务，因此好的设计应该是数据请求只形成一条日志（一般通过nginx日志实现）。因此，这里很关键的一点就是如何将这些日志收集起来进行处理。目前常用的技术有flume、Scribe、Chukwa等。其中，flume是目前比较成熟且应用比较广泛的方案。</p>

<p> 由于从数据源到来的数据并不一定是我们处理需要的数据或者数据格式，因此这里还有数据的清洗过程，包括分析，验证，清洗，转换，去重，</p></li>
<li><p>数据队列</p>

<p> 数据采集之后需要通过数据队列传输，这里的队列主要起的是缓冲作用以及其他非采集数据源的输入(比如某一业务逻辑产生了一条统计报文，可以直接写入队列中)，可以采取本地队列或者分布式队列。目前，比较成熟的队列有kafka、rabbitMQ等。其中，在数据统计领域kafka是应用比较广泛的。</p></li>
<li><p>数据处理</p>

<p> 对于采集到的数据，很多是需要计算才能得到需要的统计结果的。这时候就牵扯到了计算模型。这里分为离线计算和实时计算两种模型。离线计算针对实时来讲，就是非实时的，可以定时调度进行计算的，一般来说是耗时比较长，对结果需求没那么实时的业务场景，适合非线上业务；实时计算则是需要在数据一到达就开始进行计算、处理的，适合对实时性要求高的一些业务场景，比如广告的实时结算等。</p></li>
<li><p>数据存储</p>

<p> 服务端在数据统计中一个关键的功能是对采集到的内容进行存储。对于中小规模的数据，使用mysql等传统数据库即可应对，大一点规模采用分表、分库也能应对。再大一点的那就只能祭出大数据数据库了。此外，数据的存储结构也需要慎重考虑，尤其是在应对多维度查询的时候，不合理的数据结构设计会导致低下的查询效率和冗余的存储空间。</p></li>
<li><p>数据可视化</p>

<p> 数据存储的下一步是要把数据展示出来，也就是数据可视化。通常情况下，导出excel表格是一种形式，此外，web端/移动端甚至pc端也需要展示数据的话，就引出了数据可视化技术，尤其是在大数据量情况下如何更加高效快速地展示数据。</p></li>
</ol>


<p>数据采集+数据队列+数据处理+数据存储+数据可视化即组成了一个完整的数据系统。而从本质上来看，数据系统=数据+查询，万变不离其宗。</p>

<p>对于一般规模的产品，数据其实远远没有达到需要使用大数据技术的地步。使用传统的收集数据→定时调度程序计算，存储到mysql中即可解决。如果有大的并发请求，那么使用数据队列做缓冲。当数据规模大到一定规模时，例如mysql数据库在分表分库的情况下，单表数据量还是达到了千万的规模、单机存储依然不够或者单机计算已经慢到无法容忍。应对这种情况，就需要分布式技术出场了。</p>

<p>说到这里，借用《计算广告》一书中所讲，对于数据分为三种：</p>

<ul>
<li>小规模数据：此种数据可以通过采样部分数据即可反映出数据的特征。这时候，根本无需什么大数据技术，单机规模的传统数据系统架构即可应对这种场景。</li>
<li>中等规模数据：小规模数据无法反应数据特征，当数据规模达到一定规模时，再增大特征趋向于平稳，那么此时也无需大数据技术的出场。</li>
<li>大规模数据：不能通过采样来反应数据特征，必须全量采集数据才能获取到数据特征。此时，就需要大数据技术来解决问题。</li>
</ul>


<p>其中，大规模数据就不是一般架构可以解决的了的了。</p>

<h2><a name='大数据'></a>大数据</h2>

<p>麦肯锡的《大数据：创新、竞争和生产力的下一个前沿领域》中对大数据的定义：</p>

<pre>
大数据指的是规模超过现有数据库工具获取、存储、管理和分析能力的数据集，并同时强调并不是超过某个特定数量级的数据集才是大数据。
</pre>


<p></p>

<p>大数据系统通常被认为具有数据的五个主要特征，通常称为数据的5Vs。分别是大规模，多样性，高效性、准确性和价值性。</p>

<h3>相关技术</h3>

<p>大数据是一个很宽泛的概念。当单机无法处理数据时，就有了大数据。而应对各种不同的业务场景，诞生了很多不同的软件。完成一个功能完备的系统需要多个软件的组合。</p>

<ol>
<li><p>文件/数据存储</p>

<p> 传统的文件存储都是单机的，不能横跨不同的机器，一般会使用raid做安全冗余保障。但是还是无法从根本上解决问题。HDFS（Hadoop Distributed FileSystem）则是为了应对这种业务场景产生的，其基本原理来自于google的gfs，让大量的数据可以横跨成千上百万台机器。但是对用户来说，看到的文件和单机没任何区别，已经屏蔽掉了底层细节。</p>

<p> 除了文件存储，还有数据的存储，即数据库。传统的mysql等数据库，在存储结构化、小规模数据的时候可以妥妥应对。但当需要存储半结构化或者非结构化数据，或者用分表、分库来解决存储性能、空间问题带来了复杂的管理、join时，就需要一种更好的数据库的出现。大数据领域的Hbase就是为了这种场景产生的，其原理是google的BigTable。当然，hbase底层还是依赖于hdfs，是一个针对半结构化、非结构化、稀疏的数据的数据库。</p>

<p> 此外，hbase和hdfs相比起mysql这种毫秒级数据库，其响应速度是很慢的。如果线上业务场景需要使用这些数据，那么这时候就需要更好的数据库的出现。elasticserach就是其中的佼佼者，当然，使用这种基于索引、高效的查询数据库，并不建议存储全量数据(除非你钱有的是)。一般情况下，存储热点数据即可。</p></li>
<li><p>离线数据处理</p>

<p> 大数据的处理是非常关键的一个环节。当单机的处理程序无法在期望的时间内处理完数据时，就需要考虑使用分布式技术了。于是就出现了MapReduce、Tez、Spark这些技术。MapReduce是第一代计算引擎，Tez和Spark是第二代。MapReduce的设计，采用了很简化的计算模型，只有Map和Reduce两个计算过程（中间用Shuffle串联），用这个模型，已经可以处理大数据领域很大一部分问题了。但是，MR模型很简单，但也很笨重，有不少缺点，比如：编程模型非常复杂；计算过程磁盘IO过多。于是催生出了第二代数据处理技术，Tez、Spark这些鉴于MR模型的缺点，引入了内存cache之类新的feature，让Map和Reduce之间的界限更模糊，数据交换更灵活，更少的磁盘读写，以便更方便地描述复杂算法，取得更高的吞吐量。</p>

<p> 如上面所说，编写MR的编程复杂度非常高，于是就产生了Hive、Pig，在MR上面又抽象了一层更高级的语法出来，大大简化了MR的编程复杂度。其中以Hive为代表是Sql on xx的一个典型应用。之所以使用sql，一方面是容易编写、容易维护；另一方面SQL可以让没有编程技能的诸如数据分析师都可以不依赖工程师就可以使用数据。但由于一开始的hive还是基于MR之上的，因此，其运算速度还是受到不少人的诟病。于是Hive on Tez / Spark和SparkSQL也出现了。它们都旨在用新一代通用计算引擎Tez或者Spark来跑SQL，这样就避免了基于MR带来的运算瓶颈。</p>

<p> 对于程序的离线数据处理，hive一般情况下都能够满足需求。但是对于数据分析师的数据分析需求来说，这速度就真的有点龟速了。因此为了应对数据分析的需求，Impala、Presto、Drill这些交互式sql引擎应运而生。这些系统的唯一目标就是快，能够让用户更快速地处理SQL任务，因此牺牲了通用性稳定性等特性。</p>

<p> 一个典型的数据仓库系统可以满足中低速数据处理的需求：底层HDFS，之上是MR、Tez、Spark,再上面则是Hive、Pig；此外，直接跑在HDFS上的Presto、Impala等也是另一种方案。</p>

<p> 由于是离线计算，因此是需要一个任务调度工具来定时调度计算过程的。比较流行的一个任务调度工具是azkaban，是一个基于工作流的调度软件，在一定程度上能够满足目前的离线调度需求。</p></li>
<li><p>实时计算</p>

<p> 上面说的都是数据仓库以及离线处理需求，也是低速数据处理需求。对于高速的数据处理，则需要引出实时计算的概念，也叫流式计算。目前，storm是比较成熟和流行的流式计算技术，spark streaming则是另外一种基于批量计算的流式计算技术。所谓流式计算，就是指数据过来的时候立刻进行处理，基本无延迟，但是不够灵活，计算过的数据也不能回放，因此也无法替代上面说的数据仓库和离线计算技术。</p></li>
<li><p>资源调度</p>

<p> 综上的所有东西都在同一个集群上运行，需要达到一个有序工作的状况。因此，需要一个资源调度系统来调度这些工作，MR2.0带来的yarn就是负责此工作的一个框架。目前，docker on yarn，storm on yarn等on yarn技术的出现都得益于此框架，大大提高了大数据集群的资源使用率。此外，mesos也是另一种资源调度框架。</p></li>
<li><p>协调服务</p>

<p> 一个分布式系统能够有条不紊的运行离不开协调服务的功劳。不管是hadoop还是storm、kakfa等，都是需要通过zookeeper进行协调的。zookeeper在分布式服务中扮演的角色就类似其字面意思-动物园管理员，而大数据的各个组件就类似动物园中的动物们。</p></li>
<li><p>集群监控</p>

<p> 集群的稳定性对于一个数据系统是至关重要的。因此，集群监控技术也是需要重点考虑的一点。目前，ganglia是对hadoop进行监控一个较好的工具。除了hadoop之外，ganglia也可以对kafka、zookeeper、storm等集群进行监控。当然，只要支持jmx，任何集群都是可以通过ganglia进行监控的。</p></li>
<li><p>数据可视化</p>

<p> 最近几年，数据可视化是一个很火的概念。尤其是大数据的可视化，考虑到高效、速度以及体验等等问题，并非是个很简单的事情。目前，百度开源的echarts是比较好的一个可视化前端解决方案，在大数据可视化方面支持的也比较好。</p></li>
</ol>


<p>《大数据：可扩展实时系统的原理和最佳实践》一书的作者将big data相关的开源项目做了以下分类：</p>

<ol>
<li>批量计算系统：延时较高、吞吐量大，如Hadoop。</li>
<li>序列化框架：为对象和字段提供一种模式定义语言，实现传输通信以及不同语言环境之间的转化。如Thrift, Protocol Buffers, 和Avro。</li>
<li>支持任意存取的NoSQL数据库：牺牲了SQL强大的表现力优势，根据应用场景不同仅支持部分操作。按照CAP理论来说，就是牺牲C（一致性）或A（可用性）来实现AP或CP。如Cassandra, HBase, MongoDB,Voldemort, Riak, CouchDB等。</li>
<li>消息/排队系统：保证进程之间以容错和异步的方式传递消息，在实时处理系统中非常重要。如Kestrel。</li>
<li>实时计算系统：高吞吐、低延时的流处理系统。如Storm。</li>
</ol>


<h3>一般架构</h3>

<p>下图为一个典型的大数据系统架构：</p>

<p><img src="http://www.rowkey.me/images/blog_images/data-arch.png" alt="data-arch" /></p>

<p>这里还需要提到的是Lambda架构这个概念。Lambda架构是由Storm的作者Nathan Marz提出的一个实时大数据处理框架。目标是设计出一个能满足实时大数据系统关键特性的架构，包括有：高容错、低延时和可扩展等。Lambda架构整合离线计算和实时计算，融合不可变性（Immunability），读写分离和复杂性隔离等一系列架构原则，可集成Hadoop，Kafka，Storm，Spark，Hbase等各类大数据组件。</p>

<p><img src="http://www.rowkey.me/images/blog_images/lambda-arch.png" alt="lambda-arch" /></p>

<p>Lambda架构是由三层组成：批处理层、服务层和速度层，总体可由query = function(alldata)这个公式来表示。</p>

<ul>
<li>批处理层：Hadoop是理想的批处理层工具。特点是延时较高、高吞吐量，并且是append-only（没有delete和update的概念）的。包括对全部数据集的预计算。</li>
<li>服务层：用于加载和显示数据库中的批处理视图，以便用户能够查询。可以使用Impala作为这一层的工具（使用Hive元数据指向HDFS中的一个表）。</li>
<li>速度层：主要处理新数据和服务层更新造成的高延迟补偿，利用流处理系统如 (Storm, Spark)计算实时视图(HBase)。这些视图有效期一直到它们已经能通过批处理和服务层获得时为止。</li>
</ul>


<p>为了获得一个完整结果，批处理和实时视图都必须被同时查询和融合(实时代表新数据)。</p>

<p>当然，架构的引入是不能照本宣科的，还是需要根据实际情况进行调整，以更好地适应业务场景。</p>

<h2><a name='数据统计'></a>数据统计</h2>

<p>数据统计是数据首当其冲的一个作用。关于数据统计，有以下几个关键点：</p>

<ol>
<li>数据统计是业务导向的，需要和数据分析师、运营、市场等需求方做好充分的沟通，且很关键的一点要区分清楚哪些是真正的需求，哪些仅仅是临时需求，对于前者需要以对待产品的态度去对待，后者则一过性产生结果即可。</li>
<li>数据统计一般来说都是pv、uv这些累加指标。使用数据库自带的累加器即可，如hbase/redis的incr。</li>
<li>数据统计在牵扯到用户、IP时，有些业务是需要去重的。去重的方案有bitmap、bloomfilter等，其中，redis的hyperloglog在容许一定误差的情况下使用比较广泛。</li>
<li>用户统计中的用户质量模型是比较复杂的一个地方。这个地方需要一定的建模，才能做到更好的判断一个用户的质量。通常，把一个新增用户一周内以及一周后的活跃情况作为这个用户质量的判别标准。</li>
</ol>


<h2><a name='个性化推荐'></a>个性化推荐</h2>

<p>由于个性化推荐是“机器学习”的典型应用，因此这里首先要讲一下“机器学习”。</p>

<p>机器学习是为了让机器具有人的学习能力，目的是建模隐藏的数据结构，然后做识别、预测、分类等。大多数情况下，这相当于将一组数据传递给算法，并由算法判断出与这些数据的属性相关的信息，借助这些信息可以预测出未来有可能出现的其他数据。对于机器学习广泛的一个定义是“利用经验来改善计算机系统自身的性能”，而计算机中的经验都是以数据的形式存在的。机器学习的一个典型过程就是机器利用它所认定的出现于数据中的重要特征对数据进行“训练”，并借此得到一个模型。</p>

<p>此外，与机器学习相关的还有几个名词会被混淆或者概念不清。</p>

<ul>
<li>集体智慧：简称集智，它是一种共享的或群体的智能。百度百科、维基百科、百度知道、猪八戒网等都是目前使用集体智慧的一种形式；数据挖掘、机器学习同样需要大量群体的数据才能做出计算，是使用集体智慧的另一种形式。</li>
<li>数据挖掘：数据挖掘就是试图从海量数据中找出有用的信息。数据挖掘支撑技术包含了机器学习、数据库、统计学等。其中，数据库提供数据管理技术，机器学习和统计学提供了数据分析技术。但是由于机器学习并不以大数据作为处理对象，因此数据挖掘要对算法进行改造，使得算法性能和空间占用达到实用的地步。</li>
<li>模式识别：模式识别是一种目的。传统的模式识别的方法一般分为两种：统计方法和句法方法。句法分析一般是不可学习的，而统计分析则是发展了不少机器学习的方法。因此机器学习给模式识别提供了数据分析技术。当然，也就是因为几乎所有的非随机数据都会包含这样或者那样的“模式(pattern)”，才使得机器学习的预测是可能的。</li>
</ul>


<p>总之，机器学习也是使用数据的一个很关键的领域，典型应用有个性化推荐、CTR预估、模式识别等。牵扯到的算法、技术非常多。如此部分开头所说，其中的个性化推荐是应用最广泛的领域，用到了很多机器学习相关技术。</p>

<p>从本质上看，个性化推荐和大家接触很普遍的搜索引擎是一样的，同样是为了解决信息过载的问题。搜索引擎某种意义上也是一个个性化推荐系统，其输入特征是从搜索关键字可以直接得到的。而个性化推荐中，输入特征则是需要使用机器学习相关技术才能得到。</p>

<p>个性化推荐系统一般由日志系统、推荐算法、内容展示UI三部分组成。</p>

<ul>
<li>日志系统：这是推荐系统的输入源，是一个推荐系统所有信息的源头。</li>
<li>推荐算法：这是推荐系统的核心，根据输入数据得出最终的推荐结果的具体过程就在这里。</li>
<li>内容展示UI：对于推荐结果如何展示，也是一个值得权衡的地方。以更好地满足推荐系统的目标，并能更好的收集用户的行为信息等。</li>
</ul>


<p>其中，个性化推荐中最为核心的推荐算法，目前比较流行的有以下几种：</p>

<ul>
<li>基于内容的推荐：根据内容本身的属性(特征向量)所作的推荐。</li>
<li>基于关联规则的推荐：“啤酒与尿布”的方式，是一种动态的推荐，能够实时对用户的行为作出推荐。</li>
<li>协同过滤推荐：与基于关联规则的推荐相比是一种静态方式的推荐，是根据用户已有的历史行为作分析的基础上做的推荐。可分为物品协同过滤、用户协同过滤、基于模型的协同过滤。其中，基于模型的协同又可以分为以下几种类型：基于距离的协同过滤；基于矩阵分解的协同过滤，即Latent Factor Model(SVD)；基于图模型协同，即Graph，也叫社会网络图模型。</li>
</ul>


<p>个性化推荐系统的典型架构如下图所示：</p>

<p><img src="http://www.rowkey.me/images/blog_images/recommend-sys-arch.png" alt="recommend-sys" /></p>

<p>在线业务系统的日志接入数据高速公路，再由数据高速公路迅速运转到离线数据处理平台和在线流计算平台；离线数据处理平台周期性地以批处理方式加工过去一段时间的数据，得到人群标签和其他模型参数，存放在高速缓存中，供在线业务系统使用，与此同时，在线流计算平台实时对线上的日志数据做处理，对离线计算出的数据进行补充、修正等；在线业务系统综合离线特征和在线特征使用一定的逻辑得到输出供业务使用，产生的日志流入数据高速公路。</p>

<p>基于此框架，个性化推荐系统的典型流程如下：</p>

<p><img src="http://www.rowkey.me/images/blog_images/recommend-sys.png" alt="recommend-sys" /></p>

<p>其他更为详细的，个性化推荐牵扯到的算法、细节还有很多，留待后续推荐系统相关文章中再谈。</p>

<h2><a name='总结'></a>总结</h2>

<p>无论是互联网还是其他领域的产品，数据的作用正变得越来越重要。综合来看，数据统计和机器学习/个性化推荐是目前最关键的使用数据的领域。基于具体的需求，搭建合适的数据系统是解决问题的关键。其中，大数据是在应对大规模数据的情况下合适的技术选型架构。</p>

<h2><a name='参考资料'></a>参考资料</h2>

<ul>
<li><a href="https://book.douban.com/subject/26596778/">《计算广告》</a></li>
<li><a href="https://book.douban.com/subject/10769749/">《推荐系统实践》</a></li>
<li><a href="https://www.zhihu.com/question/27974418/answer/38965760">知乎@Xiaoyu Ma的有关回答</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2016年的几点规划]]></title>
    <link href="http://www.rowkey.me/blog/2016/02/18/2016plan/"/>
    <updated>2016-02-18T20:31:11+08:00</updated>
    <id>http://www.rowkey.me/blog/2016/02/18/2016plan</id>
    <content type="html"><![CDATA[<p>明天就要开始新的一年正式的上班了，回想一下过去的2015年，对于自己来说，虽然有不少的收获和成长，但还是令自己比较不满意的。由于某些原因，自己的学习进度以及工作情况都受到了很大的影响，并没有达到年初的期望。不过，至少没有浑浑噩噩的一年又一年，也算不错了。^_^</p>

<p><strong>工作学习方面：</strong></p>

<ol>
<li><p>大数据</p>

<p> 公司业务的增长让以前的架构达到了瓶颈。大数据技术的引入对于我自己来说算是离开了舒适区。从hadoop、flume、kafka到storm等等都是一个崭新的领域。虽然从本质上来看，大数据和普通的程序是没啥区别的。但是牵扯到分布式，各种需要考虑的东西也就多了起来，也就引出了一个个强大的软件。15年基本上完成了公司的lambda架构，16年需要做的是完善、优化已有的，而需要考虑引入的则包括elasticsearch、spark等大数据技术。</p></li>
<li><p>数据挖掘</p>

<p> 大数据是服务于数据统计的，而数据统计的最终目的一方面是指导市场运营的工作，更重要的一点则是服务于数据挖掘。目前接触的主要是怎样构建用户画像，从而形成一个良好的推荐机制，为用户推荐更多感兴趣的运营内容。15年，完成了用户画像以及初版的推荐机制；16年，需要做的是进一步验证已有系统的效果，考虑引入更好、更成熟的方案，此外在文本内容打标签、分类等方面也需要实现成熟的机器学习方案。</p></li>
<li><p>基础平台</p>

<p> 借鉴已有开源框架，实现了公司的dao框架、redis操作框架、java ee应用性能检测框架、分布式调度框架等。16年需要继续升级基础平台。</p>

<p> 值得一提的是，公司代码版本管理使用的gitbucket，自己在此之上做了不少二次开发，有些提交给了原项目，有些则是仅仅为了应对公司的需求。鉴于此，也接触到了scala的开发，不得不说，scala的学习曲线确实很陡，16年争取要能掌握并熟练运用此语言。</p></li>
<li><p>Github</p>

<p> 在github上写代码，一方面可以提高自己的编码水平，毕竟质量太差的代码，你也怕拿出来丢人；另一方面，github上那么多优秀的项目，只做拿来党是很可耻的，一些好的东西，分享出来帮助更多的同行给自己带来的成就感反过来也能督促自己技术的提升。15年自己开发或者基于原项目二次开发了一些star较多的项目。16年要坚持在github继续贡献更多好的代码。</p></li>
<li><p>技术分享</p>

<p> 在去年的研发招聘过程中，尤其是校招，感受到了目前后端工程师教育的匮乏。对于一个后端工程师的技术体系，先不说学生，不少工作很长时间的人都没有一个清晰的认识。于是自己萌生了写一本后端工程师技术体系书籍的想法，希望能够给选择后端这个方向的人一些指导。到目前为止也写了一些，希望16年至少能出一个初稿。</p>

<p> 此外，自己在开发者头条的<a href="http://toutiao.io/subjects/4944">《后端技术杂谈》</a>专栏，会继续分享自己的技术感悟和总结。一方面，增人玫瑰，手有余香；更重要的一点还是能够督促自己多总结，多思考。</p></li>
</ol>


<p><strong>工作学习之外：</strong></p>

<p>今年最大的一点感受：不管其他如何，健康才是一个人最最重要的东西。尤其是对于天天坐在电脑面前的程序员们来说，保持健康就是保证最大的竞争力。也让自己对北京这个城市有了更深的抵触，逃离这里是迟早的事情。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[也谈IO模型]]></title>
    <link href="http://www.rowkey.me/blog/2016/01/18/io-model/"/>
    <updated>2016-01-18T15:41:31+08:00</updated>
    <id>http://www.rowkey.me/blog/2016/01/18/io-model</id>
    <content type="html"><![CDATA[<h2>目录</h2>

<ul>
<li><a href="#%E5%89%8D%E8%A8%80">前言</a></li>
<li><a href="#IO%E6%A8%A1%E5%9E%8B">IO模型</a></li>
<li><a href="#%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B">网络编程模型</a></li>
<li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li>
</ul>


<h2><a name='前言'></a>前言</h2>

<p>说到IO模型，都会牵扯到同步、异步、阻塞、非阻塞这几个词。从词的表面上看，很多人都觉得很容易理解。但是细细一想，却总会发现有点摸不着头脑。自己也曾被这几个词弄的迷迷糊糊的，每次看相关资料弄明白了，然后很快又给搞混了。经历过这么几次之后，发现这东西必须得有所总结提炼才不至于再次混为一谈。尤其是最近看到好几篇讲这个的文章，很多都有谬误，很容易把本来就搞不清楚的人弄的更加迷糊。</p>

<p>最适合IO模型的例子应该是咱们平常生活中的去餐馆吃饭这个场景，下文就结合这个来讲解一下经典的几个IO模型。在此之前，先需要说明以下几点：</p>

<ul>
<li>IO有内存IO、网络IO和磁盘IO三种，通常我们说的IO指的是后两者。</li>
<li>阻塞和非阻塞，是函数/方法的实现方式，即在数据就绪之前是立刻返回还是等待。</li>
<li>以文件IO为例,一个IO读过程是文件数据从磁盘→内核缓冲区→用户内存的过程。同步与异步的区别主要在于数据从内核缓冲区→用户内存这个过程需不需要用户进程等待。(网络IO把磁盘换做网卡即可)</li>
</ul>


<!--more-->


<h2><a name='IO模型'></a>IO模型</h2>

<h3>同步阻塞</h3>

<p>去餐馆吃饭，点一个自己最爱吃的盖浇饭，然后在原地等着一直到盖浇饭做好，自己端到餐桌就餐。这就是典型的同步阻塞。当厨师给你做饭的时候，你需要一直在那里等着。</p>

<p>网络编程中，读取客户端的数据需要调用recvfrom。在默认情况下，这个调用会一直阻塞直到数据接收完毕，就是一个同步阻塞的IO方式。这也是最简单的IO模型，在通常fd较少、就绪很快的情况下使用是没有问题的。</p>

<p><img src="http://www.rowkey.me/images/blog_images/io/bio.png" alt="bio" /></p>

<h3>同步非阻塞</h3>

<p>接着上面的例子，你每次点完饭就在那里等着，突然有一天你发现自己真傻。于是，你点完之后，就回桌子那里坐着，然后估计差不多了，就问老板饭好了没，如果好了就去端，没好的话就等一会再去问，依次循环直到饭做好。这就是同步非阻塞。</p>

<p>这种方式在编程中对socket设置O_NONBLOCK即可。但此方式仅仅针对网络IO有效，对磁盘IO并没有作用。因为本地文件IO就没有被认为是阻塞，我们所说的网络IO的阻塞是因为网路IO有无限阻塞的可能，而本地文件除非是被锁住，否则是不可能无限阻塞的，因此只有锁这种情况下，O_NONBLOCK才会有作用。而且，磁盘IO时要么数据在内核缓冲区中直接可以返回，要么需要调用物理设备去读取，这时候进程的其他工作都需要等待。因此，后续的IO复用和信号驱动IO对文件IO也是没有意义的。</p>

<p><img src="http://www.rowkey.me/images/blog_images/io/nio.png" alt="bio" /></p>

<p>此外，需要说明的一点是nginx和node中对于本地文件的IO是用线程的方式模拟非阻塞的效果的，而对于静态文件的io，使用zero copy(例如sendfile)的效率是非常高的。</p>

<h3>IO复用</h3>

<p>接着上面的列子，你点一份饭然后循环的去问好没好显然有点得不偿失，还不如就等在那里直到准备好，但是当你点了好几样饭菜的时候，你每次都去问一下所有饭菜的状态(未做好/已做好)肯定比你每次阻塞在那里等着好多了。当然，你问的时候是需要阻塞的，一直到有准备好的饭菜或者你等的不耐烦(超时)。这就引出了IO复用，也叫多路IO就绪通知。这是一种进程预先告知内核的能力，让内核发现进程指定的一个或多个IO条件就绪了，就通知进程。使得一个进程能在一连串的事件上等待。</p>

<p><img src="http://www.rowkey.me/images/blog_images/io/mulio.png" alt="bio" /></p>

<p>IO复用的实现方式目前主要有select、poll和epoll。</p>

<p>select和poll的原理基本相同：</p>

<ul>
<li>注册待侦听的fd(这里的fd创建时最好使用非阻塞)</li>
<li>每次调用都去检查这些fd的状态，当有一个或者多个fd就绪的时候返回</li>
<li>返回结果中包括已就绪和未就绪的fd</li>
</ul>


<p>相比select，poll解决了单个进程能够打开的文件描述符数量有限制这个问题：select受限于FD_SIZE的限制，如果修改则需要修改这个宏重新编译内核；而poll通过一个pollfd数组向内核传递需要关注的事件，避开了文件描述符数量限制。</p>

<p>此外，select和poll共同具有的一个很大的缺点就是包含大量fd的数组被整体复制于用户态和内核态地址空间之间，开销会随着fd数量增多而线性增大。</p>

<p>select和poll就类似于上面说的就餐方式。但当你每次都去询问时，老板会把所有你点的饭菜都轮询一遍再告诉你情况，当大量饭菜很长时间都不能准备好的情况下是很低效的。于是，老板有些不耐烦了，就让厨师每做好一个菜就通知他。这样每次你再去问的时候，他会直接把已经准备好的菜告诉你，你再去端。这就是事件驱动IO就绪通知的方式-<strong>epoll</strong>。</p>

<p>epoll的出现，解决了select、poll的缺点：</p>

<ul>
<li>基于事件驱动的方式，避免了每次都要把所有fd都扫描一遍。</li>
<li>epoll_wait只返回就绪的fd。</li>
<li>epoll使用nmap内存映射技术避免了内存复制的开销。</li>
<li>epoll的fd数量上限是操作系统的最大文件句柄数目,这个数目一般和内存有关，通常远大于1024。</li>
</ul>


<p>目前，epoll是Linux2.6下最高效的IO复用方式，也是Nginx、Node的IO实现方式。而在freeBSD下，kqueue是另一种类似于epoll的IO复用方式。</p>

<p>此外，对于IO复用还有一个水平触发和边缘触发的概念：</p>

<ul>
<li>水平触发：当就绪的fd未被用户进程处理后，下一次查询依旧会返回，这是select和poll的触发方式。</li>
<li>边缘触发：无论就绪的fd是否被处理，下一次不再返回。理论上性能更高，但是实现相当复杂，并且任何意外的丢失事件都会造成请求处理错误。epoll默认使用水平触发，通过相应选项可以使用边缘触发。</li>
</ul>


<h3>信号驱动</h3>

<p>上文的就餐方式还是需要你每次都去问一下饭菜状况。于是，你再次不耐烦了，就跟老板说，哪个饭菜好了就通知我一声吧。然后就自己坐在桌子那里干自己的事情。更甚者，你可以把手机号留给老板，自己出门，等饭菜好了直接发条短信给你。这就类似信号驱动的IO模型。</p>

<p><img src="http://www.rowkey.me/images/blog_images/io/sigio.png" alt="bio" /></p>

<p>流程如下：</p>

<ul>
<li>开启套接字信号驱动IO功能</li>
<li>系统调用sigaction执行信号处理函数（非阻塞，立刻返回）</li>
<li>数据就绪，生成sigio信号，通过信号回调通知应用来读取数据。</li>
</ul>


<h3>异步非阻塞</h3>

<p>之前的就餐方式，到最后总是需要你自己去把饭菜端到餐桌。这下你也不耐烦了，于是就告诉老板，能不能饭好了直接端到你的面前或者送到你的家里(外卖)。这就是异步非阻塞IO了。</p>

<p><img src="http://www.rowkey.me/images/blog_images/io/aio.png" alt="bio" /></p>

<p>对比信号驱动IO，异步IO的主要区别在于：信号驱动由内核告诉我们何时可以开始一个IO操作(数据在内核缓冲区中)，而异步IO则由内核通知IO操作何时已经完成(数据已经在用户空间中)。</p>

<p>异步IO又叫做事件驱动IO，在Unix中，POSIX1003.1标准为异步方式访问文件定义了一套库函数，定义了AIO的一系列接口。使用aio_read或者aio_write发起异步IO操作。使用aio_error检查正在运行的IO操作的状态。</p>

<h2><a name='网络编程模型'></a>网络编程模型</h2>

<p>上文讲述了UNIX环境的五种IO模型。基于这五种模型，在Java中，随着NIO和NIO2.0(AIO)的引入，一般具有以下几种网络编程模型：</p>

<ul>
<li>BIO</li>
<li>NIO</li>
<li>AIO</li>
</ul>


<h3>BIO</h3>

<p>BIO是一个典型的网络编程模型，是通常我们实现一个服务端程序的过程，步骤如下：</p>

<ul>
<li>主线程accept请求阻塞</li>
<li>请求到达，创建新的线程来处理这个套接字，完成对客户端的响应。</li>
<li>主线程继续accept下一个请求</li>
</ul>


<p>这种模型有一个很大的问题是：当客户端连接增多时，服务端创建的线程也会暴涨，系统性能会急剧下降。因此，在此模型的基础上，类似于
tomcat的bio connector，采用的是线程池来避免对于每一个客户端都创建一个线程。有些地方把这种方式叫做伪异步IO(把请求抛到线程池中异步等待处理)。</p>

<h3>NIO</h3>

<p>JDK1.4开始引入了NIO类库，这里的NIO指的是Non-blcok IO，主要是使用Selector多路复用器来实现。Selector在Linux等主流操作系统上是通过epoll实现的。</p>

<p>NIO的实现流程，类似于select：</p>

<ul>
<li>创建ServerSocketChannel监听客户端连接并绑定监听端口，设置为非阻塞模式。</li>
<li>创建Reactor线程，创建多路复用器(Selector)并启动线程。</li>
<li>将ServerSocketChannel注册到Reactor线程的Selector上。监听accept事件。</li>
<li>Selector在线程run方法中无线循环轮询准备就绪的Key。</li>
<li>Selector监听到新的客户端接入，处理新的请求，完成tcp三次握手，建立物理连接。</li>
<li>将新的客户端连接注册到Selector上，监听读操作。读取客户端发送的网络消息。</li>
<li>客户端发送的数据就绪则读取客户端请求，进行处理。</li>
</ul>


<p>相比BIO，NIO的编程非常复杂。</p>

<h3>AIO</h3>

<p>JDK1.7引入NIO2.0，提供了异步文件通道和异步套接字通道的实现，是真正的异步非阻塞IO, 对应于Unix中的异步IO。</p>

<ul>
<li>创建AsynchronousServerSocketChannel，绑定监听端口</li>
<li>调用AsynchronousServerSocketChannel的accpet方法，传入自己实现的CompletionHandler。包括上一步，都是非阻塞的</li>
<li>连接传入，回调CompletionHandler的completed方法，在里面，调用AsynchronousSocketChannel的read方法，传入负责处理数据的CompletionHandler。</li>
<li>数据就绪，触发负责处理数据的CompletionHandler的completed方法。继续做下一步处理即可。</li>
<li>写入操作类似，也需要传入CompletionHandler。</li>
</ul>


<p>其编程模型相比NIO有了不少的简化。</p>

<h3>对比</h3>

<table>
<thead>
<tr>
<th>.  </th>
<th> 同步阻塞IO </th>
<th> 伪异步IO </th>
<th> NIO </th>
<th> AIO</th>
</tr>
</thead>
<tbody>
<tr>
<td>客户端数目 ：IO线程  </td>
<td> 1 : 1</td>
<td> m : n</td>
<td> m : 1 </td>
<td> m : 0</td>
</tr>
<tr>
<td>IO模型 </td>
<td> 同步阻塞IO </td>
<td> 同步阻塞IO </td>
<td> 同步非阻塞IO</td>
<td> 异步非阻塞IO</td>
</tr>
<tr>
<td>吞吐量 </td>
<td> 低</td>
<td>中</td>
<td>高</td>
<td>高</td>
</tr>
<tr>
<td>编程复杂度 </td>
<td> 简单</td>
<td>简单</td>
<td>非常复杂</td>
<td>复杂</td>
</tr>
</tbody>
</table>


<h2><a name='参考资料'></a>参考资料</h2>

<ul>
<li><a href="http://book.douban.com/subject/3924175/">构建高性能Web站点</a></li>
<li><a href="http://book.douban.com/subject/26373138/">Netty权威指南</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Git常用命令指南]]></title>
    <link href="http://www.rowkey.me/blog/2016/01/10/git-usage/"/>
    <updated>2016-01-10T10:15:30+08:00</updated>
    <id>http://www.rowkey.me/blog/2016/01/10/git-usage</id>
    <content type="html"><![CDATA[<p><strong><em>ps:本指南会持续更新</em></strong></p>

<p>其实一般情况下，只需要掌握git的几个常用命令即可，但是在使用的过程中难免会遇到各种复杂的需求，这时候经常需要搜索，非常麻烦，故总结了一下自己平常会用到的git操作。</p>

<p><img src="http://www.rowkey.me/images/blog_images/git-process.png" alt="git-process" /></p>

<p>上图所示，使用git的流程一般如此，通常使用图中的六个命令即可。</p>

<!--more-->


<h2>目录</h2>

<ul>
<li><a href="#config">配置</a></li>
<li><a href="#repo">取得项目的 Git 仓库</a></li>
<li><a href="#commit">记录每次更新到仓库</a></li>
<li><a href="#remote">远程仓库的使用</a></li>
<li><a href="#branch">分支的使用</a></li>
<li><a href="#tag">标签的使用</a></li>
<li><a href="#log">日志</a></li>
<li><a href="#revert">撤销</a></li>
<li><a href="#cherrypick">选择某些commits操作</a></li>
<li><a href="#submodule">Submodule</a></li>
<li><a href="#other">其他</a></li>
</ul>


<h2><a name="config"></a>配置</h2>

<ol>
<li><p>下面的命令将修改/home/[username]/.gitconfig文件，也就是说下面的配置只对每一个ssh的用户可见，所以每个人都需要做。</p>

<ul>
<li><p>提交代码的log里面会显示提交者的信息</p>

<pre><code>  git config --global user.name [username]
  git config --global user.email [email]
</code></pre></li>
<li><p>在git命令中开启颜色显示</p>

<pre><code>  git config --global color.ui true
</code></pre></li>
<li><p>兼容不同平台的换行符</p>

<p>  For Windows:</p>

<pre><code>  git config --global core.autocrlf true
</code></pre>

<p>  For Mac:</p>

<pre><code>  git config --global core.autocrlf input
</code></pre>

<p>  同时在ADD之前使用以下命令不再收到关于换行符的提示:</p>

<pre><code>  git config --global core.safecrlf false
</code></pre></li>
<li><p>如果使用HTTP clone遇到提交大小限制，请使用以下命令提高限值</p>

<pre><code>  git config http.postBuffer 524288000
</code></pre></li>
<li><p>此外，也可以使用以下命令做相应修改</p>

<pre><code>  git config -e --global
</code></pre></li>
</ul>
</li>
<li><p>下面的命令将修改/etc/gitconfig文件，这是全局配置，所以admin来做一次就可以了。</p>

<p> 配置一些git的常用命令alias</p>

<pre><code> sudo git config --system alias.st status     #git st
 sudo git config --system alias.ci commit   #git ci
 sudo git config --system alias.co checkout  #git co
 sudo git config --system alias.br  branch  #git br
</code></pre></li>
<li><p>也可以进入工作根目录，运行git config -e，这样就只会修改工作区的.git/config文件，但是暂时还用不着.</p>

<p> git config文件的override顺序是3>1>2.</p></li>
<li><p>显示配置列表</p>

<pre><code> git config --list
</code></pre></li>
<li><p>配置密钥</p>

<pre><code> ssh-keygen -t rsa -C superhj1987@126.com #生成密钥

 ssh -T git@github.com #测试是否成功
</code></pre></li>
</ol>


<h2><a name="repo"></a>取得项目的 Git 仓库</h2>

<p>有两种取得 Git 项目仓库的方法。第一种是在现存的目录下，通过导入所有文件来创建新的 Git 仓库。第二种是从已有的 Git 仓库克隆出一个新的镜像仓库来。</p>

<ol>
<li><p>在工作目录中初始化新仓库</p>

<p> 要对现有的某个项目开始用 Git 管理，只需到此项目所在的目录，执行：</p>

<pre><code> git init 在当前目录新建一个Git代码库
 git init [projectName] 新建一个目录并初始化为Git代码库
</code></pre></li>
<li><p>从现有仓库克隆</p>

<pre><code> git clone git://github.com/superhj1987/test.git
</code></pre>

<p> 这会在当前目录下创建一个名为“test”的目录，其中包含一个 .git 的目录，用于保存下载下来的所有版本记录，然后从中取出最新版本的文件拷贝。</p></li>
</ol>


<h2><a name="commit"></a>记录每次更新到仓库</h2>

<ol>
<li><p>检查当前文件状态</p>

<pre><code> git status
</code></pre></li>
<li><p>跟踪新文件、暂存已修改文件</p>

<p> 使用命令<strong>git add [dirName] [fileName1] [fileName2]</strong>(支持正则)开始跟踪一个新文件/文件夹(包括子文件夹)。实际上只是add file into staged area，并没有提交文件。</p>

<p> 此外：</p>

<pre><code> git add . 添加当前目录的所有文件到暂存区
 git add --a 添加所有文件和目录到暂存区(自己最常用的)
</code></pre></li>
<li><p>忽略未纳入版本管理的某些文件/文件夹</p>

<p> 一般我们总会有些文件无需纳入 Git的管理，也不希望它们总出现在未跟踪文件列表。通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。我们可以创建一个名为 .gitignore的文件，列出要忽略的文件模式。</p>

<p> 文件.gitignore 的格式规范如下：</p>

<ul>
<li>所有空行或者以注释符号 ＃ 开头的行都会被 Git 忽略。</li>
<li>可以使用标准的 glob 模式匹配。 * 匹配模式最后跟反斜杠（/）说明要忽略的是目录。 * 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。</li>
<li>所谓的 glob 模式是指 shell 所使用的简化了的正则表达式。星号（*）匹配零个或多个任意字符；[abc] 匹配任何一个列在方括号中的字符（这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）；问号（?）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配（比如 [0-9] 表示匹配所有 0 到 9 的数字）。</li>
</ul>


<p> 此外，忽略未纳入版本管理的文件或文件夹的方式还有：</p>

<ul>
<li>可以为自己配置一个全局的ignore文件，位于任何版本库之外：$ git config &ndash;global core.excludesfile ~/.gitignoreglobal</li>
<li>.git/info/exclude文件里设置你自己本地需要排除的文件,不会影响到其他人,也不会提交到版本库中去</li>
</ul>
</li>
<li><p>忽略已经在版本库里的文件/文件夹</p>

<ul>
<li><p>告诉git忽略对已经纳入版本管理的文件a的修改,git会一直忽略此文件直到重新告诉git可以再次跟踪此文件:</p>

<pre><code>  git update-index--assume-unchanged a
</code></pre></li>
<li><p>告诉git恢复跟踪a</p>

<pre><code>  git update-index —no-assume-unchanged a
</code></pre></li>
<li><p>查看当前被忽略的、已经纳入版本库管理的文件</p>

<pre><code>  git ls-files -v | grep -e "^[hsmrck]"
</code></pre></li>
</ul>
</li>
<li><p>查看已暂存和未暂存的更新、提交之间的差异</p>

<p> git status 的显示比较简单，仅仅是列出了修改过的文件，如果要查看具体修改了什么地方，可以用 git diff 命令。</p>

<ul>
<li>git diff #查看尚未暂存的文件更新了哪些部分</li>
<li>git diff &ndash;cached [file] #看已经暂存起来的文件和上次提交时的快照之间的差异</li>
<li>git diff [branch1] [branch2] #显示两次提交之间的差异</li>
</ul>
</li>
<li><p>提交更新</p>

<p> 每次准备提交前，先用git status看下，是不是都已暂存起来了，然后再运行提交命令git commit提交更新</p>

<ul>
<li>git commit [file1] [file2] 提交会提示输入本次提交说明</li>
<li>git commit -m [messag] 直接附带提交说明</li>
<li>git commit &ndash;amend#修改最后一次提交</li>
<li>git commit -v 提交时显示所有diff信息</li>
<li>git commit &ndash;amend -m [message] 使用一次新的commit，替代上一次提交,如果代码没有任何新变化，则用来改写上一次commit的提交信息</li>
<li>git commit &ndash;amend [file1] [file2] &hellip; 重做上一次commit，并包括指定文件的新变化</li>
</ul>
</li>
<li><p>跳过使用暂存区域</p>

<p> git commit -a 跳过git add步骤直接commit</p></li>
<li><p>移除文件
 要从 Git 中移除某个文件（包括暂存区域和工作目录），就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。
可以用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。</p>

<pre><code>  git rm [file1] [file2]
</code></pre>

<p>  最后提交的时候，该文件就不再纳入版本管理了。
  如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f（译注：即 force 的首字母），以防误删除文件后丢失修改的内容。</p>

<p>  另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。换句话说，仅是从跟踪清单中删除。比如一些 编译文件，不小心纳入仓库后，要移除跟踪但不删除文件，以便稍后在 .gitignore 文件中补上，用 &ndash;cached 选项即可：</p>

<pre><code>  git rm --cached [file]
</code></pre>

<p>  后面可以列出文件或者目录的名字，也可以使用 glob 模式。比方说：</p>

<pre><code>  git rm log/\*.log
</code></pre>

<p>  注意到星号 * 之前的反斜杠 \，因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开（译注：实际上不加反斜杠也可以运行，只不过按照 shell扩展的话，仅仅删除指定目录下的文件而不会递归匹配。上面的例子本来就指定了目录，所以效果等同，但下面的例子就会用递归方式匹配，所以必须加反斜杠。此命令删除所有 log/ 目录下扩展名为 .log 的文件。类似的比如：</p>

<pre><code>  git rm \*~
</code></pre>

<p>  会递归删除当前目录及其子目录中所有 ~ 结尾的文件。</p></li>
<li><p>移动文件</p>

<p> 要在 Git 中对文件改名，可以运行如下命令</p>

<pre><code> git mv file_from file_to
</code></pre>

<p> 其实，运行 git mv 就相当于运行了下面三条命令：</p>

<pre><code> $ mv README.txt README
 $ git rm README.txt
 $ git add README
</code></pre></li>
<li><p>回滚文件</p>

<pre><code>git branch backup // 先备份到一个新分支
git log // 找到要回滚的版本
git reset --hard 版本号 // 回滚
</code></pre></li>
</ol>


<h2><a name="remote"></a>远程仓库的使用</h2>

<p>远程仓库是指托管在网络上的项目仓库，可能会有好多个，其中有些你只能读，另外有些可以写。</p>

<ol>
<li><p>查看当前的远程库</p>

<p> 要查看当前配置有哪些远程仓库，可以用 git remote 命令，它会列出每个远程库的简短名字。在克隆完某个项目后，至少可以看到一个名为 origin 的远程库，也可以加上 -v 选项git remote -v（译注：此为 &ndash;verbose 的简写，取首字母），显示对应的克隆地址。</p></li>
<li><p>添加远程仓库</p>

<p> 要添加一个新的远程仓库，可以指定一个简单的名字，以便将来引用，运行 git remote add [shortname] [url]</p></li>
<li><p>从远程同步信息</p>

<pre><code> git fetch [remote] #下载仓库的所有变动
 git pull [remote] [branch] #取回远程仓库的变化冰河本地分支合并
</code></pre></li>
<li><p>推送数据到远程仓库</p>

<p> 项目进行到一个阶段，要同别人分享目前的成果，可以将本地仓库中的数据推送到远程仓库。实现这个任务的命令很简单：</p>

<pre><code> git push [remote-name] [branch-name]。
</code></pre>

<p> 如果要把本地的 master 分支推送到 origin 服务器上（再次说明下，克隆操作会自动使用默认的 master 和 origin 名字），可以运行下面的命令：</p>

<pre><code> git push origin master

 git push -u origin master //push同时设置默认跟踪分支
</code></pre>

<p> 只有在所克隆的服务器上有写权限，或者同一时刻没有其他人在推数据，这条命令才会如期完成任务。如果在你推数据前，已经有其他人推送了若干更新，那你的推送操作就会被驳回。你必须先把他们的更新merge到本地才能继续。</p>

<p> 此外，当你本地的版本落后于远程仓库，但是你想要用旧版本覆盖远程版本的话，使用</p>

<pre><code> git push --force origin master
</code></pre>

<p> 推送所有分支到远程仓库：</p>

<pre><code> git push [remote] --all
</code></pre></li>
<li><p>查看远程仓库信息</p>

<p> 我们可以通过命令 git remote show [remote-name]查看某个远程仓库的详细信息，比如要看所克隆的 origin 仓库，可以运行：</p></li>
<li><p>远程仓库的删除和重命名</p>

<p> 在新版 Git 中可以用 git remote rename 命令修改某个远程仓库在本地的简短名称。使用git remote rm 命令删除远程仓库。</p></li>
<li><p>检出远程仓库的某一分支</p>

<pre><code> git checkout -b &lt;local.branch&gt; &lt;remote.branch&gt;
 git checkout -t &lt;x
</code></pre></li>
</ol>


<h2><a name="branch"></a>分支的使用</h2>

<p>分支是在开发中经常使用的一个功能。</p>

<pre><code>git branch 列出本地分支
git branch -r 列出远端分支
git branch -a 列出所有本地分支和远程分支
git branch -v#查看各个分支最后一个提交对象的信息
git branch --merge#查看已经合并到当前分支的分支
git branch --no-merge#查看为合并到当前分支的分支

git branch [branch-name] 新建分支,但仍然停留在当前分支
git branch [branch] [commit] 新建一个分支，指向指定commit
git checkout [branch-name] 切换到分支
git checkout -b [branch-name] 新建+切换到该分支
git checkout -b [branch1] [branch2] 基于branch2新建branch1分支，并切换

git branch -d [branch-name] 删除分支
git branch -D [branch-name] 强制删除分支

git merge [branch-name] 将分支合并到当前分支
git rebase [branch-name] 将banch-name分支上超前的提交，变基到当前分支

git branch --set-upstream [branch] [remote-branch] 建立现有分支和指定远程分支的追踪关系

# 删除远程分支
git push origin --delete [branch-name]
git push origin :[branch-name]
git branch -dr [remote/branch-name]
</code></pre>

<h2><a name="tag"></a>标签的使用</h2>

<p>当你完成一个版本的开发，需要做发布的时候，会需要给此次版本打一个表标签：</p>

<pre><code>git tag #列出现有标签

git tag [tag] #新建标签
git tag [tag] #新建一个tag在当前commit
git tag [tag] [commit] #新建一个tag在指定commit
git tag -a [tag] -m 'tag cooment' #新建带注释标签
git checkout -b [branch] [tag] #新建一个分支，指向某个tag

git show [tag] #查看tag信息

git checkout [tagn] #切换到标签

git push [remote] [tag] #推送分支到源上
git push [remote] --tags #一次性推送所有分支

git tag -d [tag] #删除标签
git push origin :refs/tags/v0.1 #删除远程标签
</code></pre>

<h2><a name="log"></a>日志</h2>

<p>有时候需要查看版本的日志记录，以确定、跟踪代码的变化等</p>

<pre><code>git log #显示当前分支的版本历史
git log --stat #显示commit历史，以及每次commit发生变更的文件，每次提交的文件增删数量

#显示某个文件的版本历史，包括文件改名
git log --follow [file] 
git whatchanged [file]

git blame [file] #显示指定文件由谁何时修改过

git log -p [file] #显示指定文件相关额每一次diff

git show [commit] #显示每次提交的元数据和内容变化
git show --name-only [commit] #显示某次提交发生变化的文件
git show [commit]:[filename] #显示某次提交某个文件的内容

git reflog #显示当前分支的最近几次提交


##下面是git log的高级用法##

git log --oneline #把每一个提交压缩到一行

git log --decorate #显示指向这个提交的所有引用（比如说分支、标签等）
git shortlog #把每个提交按作者分类，显示提交信息的第一行。这样可以容易地看到谁做了什么
git log --graph #绘制一个ASCII图像来展示提交历史的分支结构
git log -&lt;n&gt; #限制显示的提交数量

# 按照现实日期过滤显示结果，日期可以使用多种格式，如2015-1-1, yesterday
git log --after="&lt;date&gt;" #在日期之后
git log --before="&lt;date&gt;" #在日期之前

git log --author="&lt;author&gt;" #按照作者(作者的邮箱地址也算作是作者的名字)

git log --no-merges #排除外来的和并提交
git log --merges #只显示外来合并提交

git log master..feature #从master分支fork到feature分支后发生的变化

git log -- xxx.java #--告诉后面是文件名不是分支名

git log --grep="xxx" #按提交信息来过滤提交

git log -S "xxx"(-G"&lt;regex&gt;") #根据内容(源代码)来过滤提交
git log --pretty=format:"&lt;string&gt;" #自定义输出格式，占位符：%cn-作者名字 %h-缩略标识 %cd-提价日期
</code></pre>

<h2><a name="revert"></a>撤销</h2>

<p>在提交了错误的修改或者想撤销文件的变动时，需要以下命令：</p>

<pre><code>git checkout [file] #恢复暂存区的指定文件到工作区
git checkout [commit] [file] #恢复某个commit的指定文件到工作区
git checkout . #回复上一个commit的所有文件到工作区

git reset --hard #重置暂存区和工作区到上一次commit
git reset [commit] [file] #重置当前分支到commit，重置暂存区，但工作区不变
git reset —soft #只回退commit,此时可以直接git commi
git reset --hard [commit] #重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致
git reset --keep [commit] #重置当前HEAD为指定commit,但保持暂存区和工作区不变

#新建一个commit撤销指定commit,后者的所有变化都将被前者抵消，并且应用到当前分支
git revert [commit] 
#回退所有内容到上一个版本
git　reset　HEAD^
#回退文件的版本到上一个版本
git　reset　HEAD^　[file]
#向前回退到第3个版本
git　reset　--soft　HEAD~3   

# 清空未进入暂存区的改动
git clean -f -d
</code></pre>

<h2><a name="cherrypick"></a>选择某些commit操作</h2>

<p>git cherry-pick可以选择某一个分支中的一个或几个commit(s)来进行操作。例如，假设我们有个稳定版本的分支，叫v2.0，另外还有个开发版本的分支v3.0，我们不能直接把两个分支合并，这样会导致稳定版本混乱，但是又想增加一个v3.0中的功能到v2.0中，这里就可以使用cherry-pick了。</p>

<pre><code>git cherry-pick &lt;commit id&gt;
</code></pre>

<h2><a name="submodule"></a>Submodule</h2>

<p>当你的工程的部分文件是另一个git库时，可以使用submodule（现在subtree已经替代了submodule）。</p>

<ol>
<li><p>添加</p>

<p> 为当前工程添加submodule，命令如下：</p>

<pre><code> git submodule add 仓库地址 路径
</code></pre></li>
<li><p>删除</p>

<p> submodule的删除稍微麻烦点：首先，要在“.gitmodules”文件中删除相应配置信息。然后，执行“git rm –cached ”命令将子模块所在的文件从git中删除。</p></li>
<li><p>下载的工程带有submodule</p>

<p> 当使用git clone下来的工程中带有submodule时，初始的时候，submodule的内容并不会自动下载下来的，此时，只需执行如下命令：</p>

<pre><code> git submodule update --init --recursive
</code></pre></li>
</ol>


<h2><a name="other"></a>其他</h2>

<pre><code>git help #获取命令的帮助信息
git archive #生成一个可供发布的压缩包
git rev-list --max-count=1 HEAD #查看当前分支的最新rev
</code></pre>

<p><strong><em>ps: 以上部分参考自网上资料，如有侵权请联系superhj1987@126.com</em></strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[研发招聘之殇]]></title>
    <link href="http://www.rowkey.me/blog/2015/12/31/dev-job-talk/"/>
    <updated>2015-12-31T22:01:02+08:00</updated>
    <id>http://www.rowkey.me/blog/2015/12/31/dev-job-talk</id>
    <content type="html"><![CDATA[<p><strong><em>ps: 本文完成于2015年12月31号</em></strong></p>

<p>对于一个公司来说，要想健康长久的发展，招聘是一个永久的话题。而对于一个互联网公司，尤其是以产品为主的公司来说，研发是招聘中的关键职位，高质量的研发人才也是所有企业都急缺的。一直持有一个观点：招一个优秀的人给他两倍的薪资带来的效果远远大于招两个普通的人。也一直秉着这个观点来招聘。</p>

<!--more-->


<p>今年十月份去西安、武汉两地进行校招，发现了目前很多学生存在的问题(其实之前在前东家参与校招的时候也发现了)：</p>

<ol>
<li><p>技术脱离业界前沿。现在高校里开的课以及实验室用的技术基本都脱离业界，面试了很多学生，他们的技能还千篇一律都是ssh系列。而这种技术选项，目前也就在传统it行业流行，互联网公司早就摒弃了这一套。此外，分布式缓存、消息队列等技术更是鲜少有人涉及。更为遗憾的是，对于服务端工程师、前端工程师、客户工程师等职位应该具有的技术栈，在高校里也缺乏相应的课程和相关的人来指导(大公司一般都设置有入职培训针对这一点)。</p></li>
<li><p>基础素质欠缺。对于应届生来说，基础素质是最关键的一点，项目经验是加分项，但不是必需和最关键的。很多学生被问起hashmap的实现原理以及怎样解决冲突时就不知所云(明明就是数据结构课讲过的)，被问到tcp/ip、操作系统时更是乱七八糟。也有些学生做过很多项目，自认为经验丰富，但当被问起使用的技术比如spring mvc的原理、mysql的索引机制时，没有任何思路。其实项目经验、工具这些东西决定了你的下限，你的基础知识和素质才决定了你的上限。互联网行业需要的是学习能力强、基本功扎实的优秀工程师，而非很多传统IT企业需要的螺丝钉。</p></li>
<li><p>没有畏惧心。这一点可能因人而异，毕竟有些人的性格就是桀骜不驯。但是在研发这个圈子里，大神太多，是大神但比你还努力的人也太多。技术也太广，任何一门技术都很难精通。做为一个研发工程师，你必须对所有人、所有技术都有一颗为畏惧心。每个人都有亮点值得你学习，每一种技术都需要你下大功夫才能精通。记得有些学生在基础知识被问得绊绊磕磕的时候，急得号称自己精通java，但试着去问了，却发现很多知识都似是而非。说到这里，最近公司的几个实习生让我体会挺深刻的，有些学生的确会对技术有畏惧感，很谦虚，抱着一种学习的态度；但是也有很多学生自视甚高，甚至有人待了一周(很多东西都没接触到)就离职，觉得我们这技术水平入不了他的法眼，总是拿一个我听都没听过的公司跟我说这个公司很厉害的，早就给offer了等等。不敢说我们公司的技术业界领先，至少我们做出了拥有几亿用户的产品。人，还是应该有一颗畏惧心，不论对人还是对事。</p></li>
<li><p>知其然不知其所以然。这一点的反面(知其然更知其所以然)对于研发人员其实是最关键的素质。能做出东西来只能证明你上手能力强，但并不代表你学习能力强。学习能力强，是指的能够快速吸纳理解新的知识，融汇贯通。比如，就拿最简单的spring ioc来说，用过的人基本都知道大概是个什么事情，但是抛开spring，让你自己去实现ioc，很多人估计就不知所措了。</p></li>
</ol>


<p>校招毕竟只是研发招聘的补充，最关键的还是社招。但是面试了很多有经验的工程师之后，却也发现了很多问题。除了上面校招提到的一些，最令我印象深刻的就是薪资。本科毕业一两年的，之前在一些不知名的公司工作过的人，动辄就漫天要价。好吧，我觉得可能是真的很优秀，那倒也匹配的上。结果，面试过n次这种人之后，我发现帝都的薪资真的不能拿常人的眼光来看，也算是给我这种来自杭州的人开了眼界。毕竟帝都这地方互联网企业一大把，舍得给钱的、面向vc的创业公司也一大把。你觉得不值，还有一大批公司觉得值。这种现象，在今年上半年达到了顶峰。不能说正确与否，只能说市场如此，带来的效应就这样。</p>

<p>关于招聘，是一门学问。自己非专业的，所以很多东西肯定看的不够清楚。但对于研发招聘，自己经历过很多次被面试，也面试过很多人。有自己觉得好的面试形式，也有自己很嗤之以鼻的。</p>

<ol>
<li>N轮算法题目面试。这种形式是被微软和谷歌所推崇的，不一定好，但是至少客观，不会掺杂面试官的主管因素，而且据说后续的结果证明了算法好的人在工作上的成绩好的概率非常大。自己曾有幸经历过一次，由于自己对算法不感兴趣，也一直没刷过题目，所以结局很惨烈。不过，自己却也信服口服。应对这种面试，能做的就是做大量的题目(至少《算法导论》上的算法都要搞明白)，总结方法，锻炼自己的思维。当然参加一下acm比赛也不妨为一种好方法。剩下的，就看你的天赋和运气了。</li>
<li>掺杂计算机基础知识、算法以及项目经验的面试。这种形式是国内大部分公司采取的。优点是能从多方面考察面试者的技术水平；缺点就是容易被面试官的主观因素所影响，尤其是很多水平很差的面试官，或者是面试官和被面试者方向不对路。</li>
<li>软件设计。这个不同于算法题目，一般是面向某一场景的软件设计题目。每个人提交代码，然后根据代码的效率、模式设计等判定结果。现场面试的时候，面试官当场提出问题、需求，现场进行优化编程。这个面试方式，我见过某土豪日企(应届生起薪30W+)采用过。这个我暂时说不上是好是坏，应该是针对特定企业的工业场景的一种面试方式。</li>
<li>现场结对编程/ppt讲解。记得之前看过一篇文章讲世界上研发面试最难的公司是Thoughtworks。面试官和你结对编程，然后再进行圆桌会议等等一系列复杂的流程。不过，在国内的thougtworks也许是为了迎合中国国情吧，倒是没见过这么招聘。记得校招的时候，初试出一道软件设计题目，你解决好后提交代码，现场面试的时候，就针对这个问题进行ppt演示，面试官当场提出问题，看你的应对。</li>
<li>只看学历、学校。这种面试方式，我知道的一次貌似只有hw校招。当时听同学说，面试官声称不关心你会不会或者专业对不对口，只要学校符合，其他的都能培养出来。当然，我相信，这只是某种形势下hw的招聘策略，毕竟hw里面招的牛人还是大有人在的。尤其是2000年左右，进hw那可是人人羡慕的。</li>
<li>群面。这种方式多见于非研发职位。不敢说在研发面试中出现好不好，但至少对我来说，如果有公司这么干，我肯定去都不去。码农们都不擅长和人打交道的好不。。。虽然，这不一定算是件好事。不过，研发总归还是要看技术的么。</li>
</ol>


<p>目前，我们公司采取的是国内最流行的第二种，基础知识考查这个人的基本素质，也就是看看能否胜任当前工作；项目经验看看这人做过的东西有没有消化、深入理解，看这人的学习主动性、研究问题的深度、对技术的热情如何；开放性问题看看这人是否足够聪明。坚决杜绝问RTFM的问题，也坚决不出什么脑筋急转弯。也会采取一些措施，比如两轮平行面试，来避免掺杂主观因素。</p>

<p>那么怎么定义一个优秀的研发工程师呢？我们希望招到的研发人员或者说我们觉得优秀的研发人员，抛开具体技术来说，共性应该是这样的：</p>

<ol>
<li><p>聪明、思维灵活。研发最重要的一点就是要聪明，这个观点貌似雷军也说过。很难想象一个不聪明的人是如何解决复杂的工程问题的。而什么叫聪明呢？我们现在在面试的时候，会随机从现实的项目中出一道曾遇到过的问题。面试的很多人都会说没遇到过、不知道。其实最终的答案并没有对错，没遇到过这个问题也是我们最希望的，如果你能给出解决方案或者思路才说明你有足够解决现实问题的能力。</p></li>
<li><p>对技术有热情。只有对技术有热情，才不会把工作仅仅当做工作，还会当做乐趣。这样才会对接触过的技术能深入研究下去，快速学习，快速成长起来。相比起聪明，这一点也是至关重要的。如果仅仅是聪明，而对技术不具有热情，那么很多人会浅尝辄止，不求甚解，最后聪明反被聪明误。而没有那么聪明的人如果足够有热情，找到合适的方法，努力学习原理层的东西，也会很快成为技术大牛的。</p></li>
<li><p>基础知识扎实。和上面校招那一部分说的一样，基础知识决定一个人的上限。如果一直停留在表面应用业务的开发，不接触到底层计算机原理，那么即使你在nb闪闪发光的大公司里，你也是可有可无的一个人，价值慢慢会趋于0。而基础知识扎实，那么学起其他的业务层技术也根本不会成为问题，上限也会很高。</p></li>
<li><p>有执行力。执行力在某种方面说就是结果导向。见过很多聪明、对技术有热情的人，却总是钻牛角尖，容易陷在一个细节上出不来，这一点自己也不例外。但是有人会考虑到整个项目的进度，做好控制，先用快速的方案实现，后续再调整和优化；有些人却往往为了一个细节，纠结来纠结去，最后造成进度延误，这就是一种没有执行力的表现。当然，如果你效率高，那么你随便钻牛角尖，不然你应该以全局为重。</p></li>
</ol>


<p>以上是今年招聘的一些感悟，希望来年能招到更多符合期望的人才。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[前端这些年]]></title>
    <link href="http://www.rowkey.me/blog/2015/12/21/front-these-years/"/>
    <updated>2015-12-21T18:53:48+08:00</updated>
    <id>http://www.rowkey.me/blog/2015/12/21/front-these-years</id>
    <content type="html"><![CDATA[<h2>前言</h2>

<p>本人一直从事的是服务端开发工作，写前端貌似有点跑题，不过自己初中也就是2000年左右的时候，引领我进入计算机大门的也的确是前端，后来也做过不少的前端工作。于是，就想着从自己的角度写点前端这些年的发展。但毕竟不是专业所长，有所纰漏在所难免。</p>

<!--more-->


<h2>正文</h2>

<h3>第一代</h3>

<p>还记得2000年左右的时候，那时的四大门户：新浪、搜狐、网易、中华网（是的，那时候还没腾讯啥事）。我第一次访问这些网站的时候就被震撼到了，一直很奇怪这是怎么写出来的。恰巧，初中开了一个计算机课，老师当时在给我们讲微软的frontpage，拖着拖着就能出来一个网页。幼稚的我恍然大悟:原来用这东西就能拖出来个新浪网啊。学会了拖网页，学校里家庭条件比较好、接触电脑比较早的同学还把自己的网页传到了网上的免费空间（网易的yeah.net免费空间），然后就俨然成了公众人物。毕竟，那个时候在我们那个小城市，家里有电脑的少，能上网的更少，能有自己的网站还能通过网络访问的则少之又少了。当然，开始大家拖出来的网页都是静态页面（这里的静态指的是静止不动），然后有些人发现加上一段代码，网页上就能有各种类似动画的效果。比如: 标题动态改变、鼠标后跟着一串文字、状态栏滚动字幕等等。frontpage已经不能满足这些了，这时候一款更加NB的软件出现在了我的眼前-dreamweaver。这款软件我后来一直用到了大学本科毕业，当然，从开始的完全依赖dw来拖页面，到后来把它当成了一个写代码的IDE。说起来，那个时候没有那么多前端框架，写个页面就是html+css+js。页面布局用table，然后table里面嵌套table，控制样式一般也使用html tag。现在想想也是醉了，还记得当时还有个原则是最外面的table宽度要设置为960px，100%，居中。这算是我接触前端的第一个时代吧，那个时候国内貌似也就ie浏览器，兼容性的问题根本不存在，技术体系相对来说也比较简单。总体概括来说：</p>

<ul>
<li>table布局网页主体</li>
<li>使用各种html标签控制样式，比如b、i、strong、br等</li>
<li>使用原生js实现动态效果</li>
</ul>


<h3>第二代</h3>

<p>后来，业界兴起了div+css的概念。说白了就是内容和样式要分开，div组织内容，css控制样式。与此同时，js技术也飞速发展中。jquery横空出世，成为了前端开发必不可少的一个框架。大家也在乐此不彼的收集着各种各样的jquery插件。那时候觉得jquery真是太好用了，觉得会写jquery插件的人好nb。除此之外，extjs也成为了开发web必不可少的框架，不知多少管理系统都长的一模一样。。。最让我记忆尤甚的是浏览器的兼容性问题，firefox、chrome、safari这些浏览器一下全火了起来，然后兼容性问题就成为了令广大前端开发者最头疼的一件事情，尤其是万恶的ie6。当时在做一个英国的项目的时候，甲方的boss竟然细致到1px都要度量的份上，于是无数个夜晚，我就在那里调整像素，还是要调整在多个浏览器下的像素。不知是幸运还是不幸的我也由此接触到了n多浏览器兼容的问题，记得最深的一个就是ie6的1px问题。对于这些兼容性问题，自己当时总结了一下，基本上使用css reset初始化所有样式，然后使用css hack针对不同浏览器做兼容，其他的针对具体问题具体分析。同样的，js里也存在兼容性的问题，一个典型的就是解析json字符串，有些浏览器里是默认有JSON的方法的，但有些浏览器却没有，只能使用eval来做。这方面，jquery则做了很好的兼容。其实，到了这个时候，整个前端已经乱了，尤其因为微软的自我，ie给大家带来了数不清的麻烦。针对这种情况，W3C适时的提出了新的标准，以求统一浏览器的渲染，也推出了es想统一一下前端脚本语言。不过，由于某些原因，ie6在很长一段时间都曾是国内前端开发者的梦靥，其他兼容性问题也一直成为了遗留问题。此外，随着前端样式和脚本变得越来越多、越来越复杂，页面的性能优化变得被人重视起来，雅虎前端优化35条原则、CSSSprites这些技术应运而生。这算是我经历的第二代前端。由于浏览器的多种多样，这一代的前端开发者真的挺苦逼的。总体概括如下：</p>

<ul>
<li>布局使用Div</li>
<li>样式控制使用Css</li>
<li>Dom操作使用jQuery</li>
<li>ExtJs类似的前端组件框架开始兴起</li>
<li>以Chrome、Firefox为代表的各种浏览器的崛起</li>
<li>前端的性能优化: 资源缓存、雅虎前端35条优化原则、CSSSprites、iframe使用的优缺点</li>
</ul>


<p>其中，对于资源缓存一般包括以下两种解决方案：</p>

<ul>
<li>对比服务器协商缓存(服务器返回304)，推荐使用超长时间的本地缓存(Response加入头cache-control/expires)。</li>
<li>文件的路径名包含<strong>文件摘要信息</strong>达到非覆盖发布以及资源缓存更新。</li>
</ul>


<h3>第三代</h3>

<p>经历了两代前端，其实自己后面就没怎么关注过这一块了，顶多就是留意一下业界的新闻，技术体系也基本就停留在了第二代上。最近由于某些原因，需要带一下公司的前端团队，就恶补了一下最新的前端知识，发现自己还真的有点out了。发展到现在，前端工程师真正成为了一个举足轻重的职位。以前由于只有pc端的前端开发，很多人瞧不上前端，觉得前端不过就是做个表单验证，做个小动画，没啥技术含量。而现在由于移动互联网的兴起，移动前端开发成了越来越重要的一部分。与此同时，“富前端”的概念也提了出来，就是让web程序的体验和本地程序体验尽可能一致，于是对前端开发者的要求也就变得越来越高。html5也适时的席卷了整个生态圈，如果说几年前h5还只是个噱头，那么现在h5在移动页面以及移动app混合开发中则已经举足轻重了。与此同时，多种终端的出现，也相应催生了“响应式”页面设计，意思就是能让你的页面根据不同的终端自动适配，能够极大地优化用户体验。而nodejs的出现，则让“全栈工程师”这个名词盛行起来，发展到现在也逐步证明并实现了前后端分离的可行性。此外，页面语义化、页面性能调优、前端工程化、前端模块化、css预处理、js预处理、liveload等也成为了前端领域越来越火的研究方向，相应的诞生了很多新兴框架、技术。总体概括如下：</p>

<ul>
<li>CSS预处理器使得大家可以使用普通的编程思维来编写css: Sass、Less。这个技术还是很实用的，毕竟css的编写方式还是非常不灵活的</li>
<li>JS预处理器：Coffescript、Typescript。这个技术我感觉是提供给不熟悉js编程的人活着是不喜欢js语法的人提供的。Google之前推出的gwt也貌似是为了这个目的。</li>
<li>Liveload技术可以自动侦测代码改变刷新浏览器</li>
<li>“富前端”，技术以AngularJs为代表，也带来了MVVM的概念: module view viewModule</li>
<li>前端模块化，以RequireJs和SeaJs为代表，前者是预执行，后者是懒执行</li>
<li>ReactJs引入的虚拟dom和组件化开发以及React Native统一三端的开发。其中React的高性能dom操作值得研究</li>
<li>手机、平板网页等多种终端催生响应式页面</li>
<li>客户端混合开发，其中技术以Phonegap为代表</li>
<li>前段工程：自动化构建工具以Grunt、Gulp为代表，当然gulp是比较先进的。</li>
<li>对比之前的Div布局，页面语义化理念的提出</li>
<li>CSS3带来的n多新特性</li>
<li>ES6标准落地，带来了新的feature:async/await、decorator、fetch等</li>
</ul>


<p>此外，随着大数据的日益火热，数据可视化技术也成为了前端一个很重要的部分。尤其是大数据的可视化。这方面，国内的echarts做的还不错，虽然也被不少人吐槽。</p>

<p>关于前端技术体系，详细的内容可以阅读这篇文章：<a href="http://blog.csdn.net/borishuai/article/details/8676573">http://blog.csdn.net/borishuai/article/details/8676573</a>。</p>

<h2>结语</h2>

<p>不管前端怎么变，其核心只有一个：视图呈现。所有的前端技术都是围绕着这一点进行的。只不过有的是从速度上，有的是从交互上，有的则从开发效率上。</p>

<p>说到前端，不得不说一下前端工程师。在最近公司的招聘中，发现前端工程师是一个相对难招的职业，尤其是好的前端工程师，一方面是由于之前大家对前端的轻视所致，另一方面也有前端技术更新迭代太快的原因。那么如何定义一个好的前端工程师呢？除了研发职位普遍具有的一些共性之外，以下几点，我觉得是前端的特质：</p>

<ul>
<li>有一定的审美观: 很难想象一个没有审美观的人开发出来的页面是如何让人觉得赏心悦目的。</li>
<li>耐心、细致：有时候前端显示的问题，真的需要一点又一点慢慢地找出来的，尤其是css方面。</li>
<li>有一定的产品思维：很多情况下，前端算是和用户直接打交道的（和客户端类似，开发出的东西是直接面向用户的）。因此，具有一定的产品思维，才能让你更好的优化视图、交互，做到更好的用户体验。</li>
</ul>


<p>最后，打个广告^_^。中华万年历，携2亿用户急需优秀的人才加入，七险一金、待遇优厚。各种职位虚位以待。<a href="http://www.lagou.com/gongsi/j1826.html">http://www.lagou.com/gongsi/j1826.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2015图书阅读清单]]></title>
    <link href="http://www.rowkey.me/blog/2015/11/20/2015book-to-read/"/>
    <updated>2015-11-20T17:13:46+08:00</updated>
    <id>http://www.rowkey.me/blog/2015/11/20/2015book-to-read</id>
    <content type="html"><![CDATA[<h2>技术</h2>

<h3>1. 精益数据分析</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/26278639/">http://book.douban.com/subject/26278639/</a></li>
<li>说明：一本讲述数据驱动创业的书籍，比如在你的产品中如何区分虚荣指标，如何抓住关键指标等。对于每一个商业模式都有其特定的关键指标和底线。而且对于一个公司的几个阶段（移情、黏性、病毒性、营收、规模化）指标也不是相同的。商业模式+阶段决定了你需要关注的指标。</li>
<li>进度：100%</li>
</ul>


<h3>2. 推荐系统实践</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/10769749/">http://book.douban.com/subject/10769749/</a></li>
<li>说明：讲述了构建一个推荐系统的基本知识、算法以及架构等。基本涵盖了能实现一个基本的推荐系统所需的相关技术等。看完这本书，基本能对推荐系统入门。</li>
<li>进度：100%</li>
<li>备注：此书上大学时曾经看过，但当时由于没有实战环境，所以没啥印象。此次阅读是基于项目需要，但其中部分牵扯到具体算法的部分没有细看</li>
</ul>


<!--more-->


<h3>3. 集体智慧编程</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/3288908/">http://book.douban.com/subject/3288908/</a></li>
<li>说明：讲述集体智慧的书籍，也是推荐系统相关的一本书</li>
<li>进度：0%</li>
</ul>


<h3>4. 快学scala</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/19971952/">http://book.douban.com/subject/19971952/</a></li>
<li>说明：学习scala的一本书，应该算是快速指引</li>
<li>进度：20%</li>
<li>备注：scala的学习曲线很陡，之前找到twitter的scala school，但是发现讲的有点不到位。鉴于此，找一本经典的书籍快速入门一下也不错。</li>
</ul>


<h2>非技术</h2>

<h3>1. 他来了，请闭眼</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/25912734/">http://book.douban.com/subject/25912734/</a></li>
<li>说明：犯罪心理学&hellip;</li>
<li>进度：100%</li>
<li>备注：看了电视剧，不过瘾，就直接找书来看了</li>
</ul>


<h3>2. 三体</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/2567698/">http://book.douban.com/subject/2567698/</a></li>
<li>说明：不用多说了，今年最火的小说。一共有三部</li>
<li>进度：30%</li>
<li>备注：看到了第二部《黑暗森林》，然后一直没时间看后面了..</li>
</ul>


<h3>3. 藏地密码</h3>

<ul>
<li>豆瓣：<a href="http://book.douban.com/subject/2201813/">http://book.douban.com/subject/2201813/</a></li>
<li>说明：一共有十部，讲述了一群人为了一个共同的秘密，在藏地进行探险的故事。</li>
<li>进度：100%</li>
<li>备注：继鬼吹灯、盗墓笔记之后，又一部让我恨不得一口气看完的小说</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[搭建自己的github]]></title>
    <link href="http://www.rowkey.me/blog/2015/11/13/your-own-github/"/>
    <updated>2015-11-13T10:27:40+08:00</updated>
    <id>http://www.rowkey.me/blog/2015/11/13/your-own-github</id>
    <content type="html"><![CDATA[<p>说起github，大家应该都是非常熟悉的。正是github的兴起，带来了开源的一个高潮，也诞生了无数优秀的开源项目。最最著名的Linux也在github上有了自己的repository。当然，github的核心技术git也是李纳斯的代表作。</p>

<p>记得几年前由于项目的需要，曾尝试自己去搭建一套git服务给项目组使用，折腾了好久，才总算搭建了一个基础的系统, 刚刚能用，权限控制都没有(<a href="http://srhang.iteye.com/blog/1339110">http://srhang.iteye.com/blog/1339110</a>)。但最终因为git的上手门槛有点高，还是选择了svn。后来随着github的兴起，git才如火如荼地在国内火了起来。许多大的互联网公司，也都开始把项目由svn转到git。但如果仅仅是搭建一个git服务，那么github这种网站提供的可视化ui带来的便捷却也不复存在了。对于一些小的有钱的团队，使用github的收费私人repository倒也是一种解决办法。但是，对于大部分公司来说，还是不会把公司内部的代码放到这种公共服务上的。这种需求场景下，就诞生了很多github的克隆实现，以方便部署内网的github。</p>

<!--more-->


<p>说到github的克隆实现，最出名的莫过于<a href="https://gitlab.com">gitlab</a>。这是一个ROR的实现，应该是目前市面上最成熟的一个github克隆项目，功能也是最丰富的。它在原来最基础的git库管理、权限管理、用户管理的基础上又加入了诸如code review、ci等极大方便开发者的功能。基本把github克隆了一遍，还加上了github没有的功能。功能强大倒是强大，但是gitlab本身的部署非常复杂，需要安装很多依赖包和依赖组件，整个过程非常痛苦。虽然现在提供了集成安装包，但对操作系统又有要求，比如要求CentOS 6以上，CentOs 5的用户就享受不了这个便利了。。。一想到这么多事情，对于我这种懒人来说，还是没有选择gitlab。</p>

<p>在前东家的时候，git项目是从gitlab迁移到了gitbucket（其中的原因当然不仅仅是因为gitlab部署的繁琐）。说起<a href="https://gitbucket.github.io/gitbucket-news/">gitbucket</a>，在百度上也搜不出什么信息来。能搜到的估计也就github库的地址和其他一些简单介绍。这个项目是日本的同行使用scala开发的一个github克隆。所以，抛开编程方面，对于java系的程序员还是比较友好的，部署也只需要把war包往tomcat之类的容器里一扔就ok。这个对比gitlab那可是天壤之别。而谈到二次开发，scala语言的学习曲线还是非常陡的，所以对比起来，貌似gitlab的二次开发相比较起来还是容易一些的（gitlab的二次开发没参与过，这里只是猜测）。当然，gitbucket是一个相对年轻的项目，对比gitlab，功能还显得比较单薄，bug也不少。我自己在使用的过程中，fix过几个小bug并提交到了项目的主分支，但是还有不少bug被公司的同事吐槽中（实在没时间专门fix这个）。另外，不得不说的是，gitbucket的markdown解析引擎，作者不知道什么原因从之前的一个叫pegdown的替换成了自己实现的markedj，让我们公司的一堆md文档都显示的各种乱，实在无语。。。不得不去clone了markedj的代码，fix了其中的一些bug，部署在我们内网的maven库里。bug虽然挺多，但比起gitlab来，还是喜欢gitbucket部署升级的简单（去官网下个war包，扔到tomcat里，恭喜你，你就拥有了自己的github）。当然，也有纯粹个人对jvm系语言的偏爱的原因^_^。</p>

<p>其实，除了gitlab和gitbucket还有很多github的克隆实现。这篇文章列出了很多并做了简单介绍:
<a href="http://www.oschina.net/news/50222/git-code-platforms">http://www.oschina.net/news/50222/git-code-platforms</a></p>

<p>其实，开发工具这种东西，选择最适合自己以及自己团队的才是上上之选。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[系统负载能力浅析]]></title>
    <link href="http://www.rowkey.me/blog/2015/09/09/load-analysis/"/>
    <updated>2015-09-09T18:42:58+08:00</updated>
    <id>http://www.rowkey.me/blog/2015/09/09/load-analysis</id>
    <content type="html"><![CDATA[<p><strong><em>&mdash;本文于2015.12.23号最新更新&mdash;</em></strong></p>

<p>互联网时代，高并发是一个老生常谈的话题。无论对于一个web站点还是app应用，高峰时能承载的并发请求都是衡量一个系统性能的关键标志。像阿里双十一顶住了上亿的峰值请求、订单也确实体现了阿里的技术水平（当然有钱也是一个原因）。</p>

<p>那么，何为系统负载能力？怎么衡量？相关因素有哪些？又如何优化呢？</p>

<!--more-->


<h2>一. 衡量指标</h2>

<p>用什么来衡量一个系统的负载能力呢？有一个概念叫做每秒请求数（Requests per second），指的是每秒能够成功处理请求的数目。比如说，你可以配置tomcat服务器的maxConnection为无限大，但是受限于服务器系统或者硬件限制，很多请求是不会在一定的时间内得到响应的，这并不作为一个成功的请求，其中成功得到响应的请求数即为每秒请求数，反应出系统的负载能力。</p>

<p>通常的，对于一个系统，增加并发用户数量时每秒请求数量也会增加。然而，我们最终会达到这样一个点，此时并发用户数量开始“压倒”服务器。如果继续增加并发用户数量，每秒请求数量开始下降，而反应时间则会增加。这个并发用户数量开始“压倒”服务器的临界点非常重要，此时的并发用户数量可以认为是当前系统的最大负载能力。</p>

<h2>二. 相关因素</h2>

<p>一般的，和系统并发访问量相关的几个因素如下：</p>

<ul>
<li>带宽</li>
<li>硬件配置</li>
<li>系统配置</li>
<li>应用服务器配置</li>
<li>程序逻辑</li>
<li>系统架构</li>
</ul>


<p>其中，带宽和硬件配置是决定系统负载能力的决定性因素。这些只能依靠扩展和升级提高。我们需要重点关注的是在一定带宽和硬件配置的基础上，怎么使系统的负载能力达到最大。</p>

<h3>2.1 带宽</h3>

<p>毋庸置疑，带宽是决定系统负载能力的一个至关重要的因素，就好比水管一样，细的水管同一时间通过的水量自然就少（这个比喻解释带宽可能不是特别合适）。一个系统的带宽首先就决定了这个系统的负载能力，其单位为Mbps,表示数据的发送速度。</p>

<h3>2.2 硬件配置</h3>

<p>系统部署所在的服务器的硬件决定了一个系统的最大负载能力，也是上限。一般说来，以下几个配置起着关键作用：</p>

<ul>
<li>cpu频率/核数：cpu频率关系着cpu的运算速度，核数则影响线程调度、资源分配的效率。</li>
<li>内存大小以及速度：内存越大，那么可以在内存中运行的数据也就越大，速度自然而然就快；内存的速度从原来的几百hz到现在几千hz，决定了数据读取存储的速度。</li>
<li>硬盘速度：传统的硬盘是使用磁头进行寻址的，io速度比较慢，使用了SSD的硬盘，其寻址速度大大较快。</li>
</ul>


<p>很多系统的架构设计、系统优化，最终都会加上这么一句：使用ssd存储解决了这些问题。</p>

<p>可见，硬件配置是决定一个系统的负载能力的最关键因素。</p>

<h3>2.3 系统配置</h3>

<p>一般来说，目前后端系统都是部署在Linux主机上的。所以抛开win系列不谈，对于Linux系统来说一般有以下配置关系着系统的负载能力。</p>

<ul>
<li>文件描述符数限制：Linux中所有东西都是文件，一个socket就对应着一个文件描述符，因此系统配置的最大打开文件数以及单个进程能够打开的最大文件数就决定了socket的数目上限。</li>
<li>进程/线程数限制: 对于apache使用的prefork等多进程模式，其负载能力由进程数目所限制。对tomcat多线程模式则由线程数所限制。</li>
<li>tcp内核参数：网络应用的底层自然离不开tcp/ip，Linux内核有一些与此相关的配置也决定了系统的负载能力。</li>
</ul>


<h4>2.3.1 文件描述符数限制</h4>

<ul>
<li><p>系统最大打开文件描述符数：/proc/sys/fs/file-max中保存了这个数目,修改此值</p>

<pre><code>  临时性
      echo 1000000 &gt; /proc/sys/fs/file-max
  永久性：在/etc/sysctl.conf中设置
      fs.file-max = 1000000
</code></pre></li>
<li><p>进程最大打开文件描述符数：这个是配单个进程能够打开的最大文件数目。可以通过ulimit -n查看/修改。如果想要永久修改，则需要修改/etc/security/limits.conf中的nofile。</p></li>
</ul>


<p>通过读取/proc/sys/fs/file-nr可以看到当前使用的文件描述符总数。另外，对于文件描述符的配置，需要注意以下几点：</p>

<ul>
<li>所有进程打开的文件描述符数不能超过/proc/sys/fs/file-max</li>
<li>单个进程打开的文件描述符数不能超过user limit中nofile的soft limit</li>
<li>nofile的soft limit不能超过其hard limit</li>
<li>nofile的hard limit不能超过/proc/sys/fs/nr_open</li>
</ul>


<h4>2.3.2 进程/线程数限制</h4>

<ul>
<li>进程数限制：ulimit -u可以查看/修改单个用户能够打开的最大进程数。/etc/security/limits.conf中的noproc则是系统的最大进程数。</li>
<li><p>线程数限制</p>

<ul>
<li>可以通过/proc/sys/kernel/threads-max查看系统总共可以打开的最大线程数。</li>
<li>单个进程的最大线程数和PTHREAD_THREADS_MAX有关，此限制可以在/usr/include/bits/local_lim.h中查看,但是如果想要修改的话，需要重新编译。</li>
<li>这里需要提到一点的是，Linux内核2.4的线程实现方式为linux threads，是轻量级进程，都会首先创建一个管理线程，线程数目的大小是受PTHREAD_THREADS_MAX影响的。但Linux2.6内核的线程实现方式为NPTL,是一个改进的LWP实现，最大一个区别就是，线程公用进程的pid（tgid），线程数目大小只受制于资源。</li>
<li>线程数的大小还受线程栈大小的制约：使用ulimit -s可以查看/修改线程栈的大小，即每开启一个新的线程需要分配给此线程的一部分内存。减小此值可以增加可以打开的线程数目。</li>
</ul>
</li>
</ul>


<h4>2.3.3 tcp内核参数</h4>

<p>在一台服务器CPU和内存资源额定有限的情况下，最大的压榨服务器的性能，是最终的目的。在节省成本的情况下，可以考虑修改Linux的内核TCP/IP参数，来最大的压榨服务器的性能。如果通过修改内核参数也无法解决的负载问题，也只能考虑升级服务器了，这是硬件所限，没有办法的事。</p>

<pre><code>netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
</code></pre>

<p>使用上面的命令，可以得到当前系统的各个状态的网络连接的数目。如下：</p>

<pre><code>LAST_ACK 13
SYN_RECV 468
ESTABLISHED 90
FIN_WAIT1 259
FIN_WAIT2 40
CLOSING 34
TIME_WAIT 28322
</code></pre>

<p>这里，TIME_WAIT的连接数是需要注意的一点。此值过高会占用大量连接，影响系统的负载能力。需要调整参数，以尽快的释放time_wait连接。</p>

<p>一般tcp相关的内核参数在/etc/sysctl.conf文件中。为了能够尽快释放time_wait状态的连接，可以做以下配置：</p>

<ul>
<li>net.ipv4.tcp_syncookies = 1 //表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；</li>
<li>net.ipv4.tcp_tw_reuse = 1 //表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；</li>
<li>net.ipv4.tcp_tw_recycle = 1 //表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭；</li>
<li>net.ipv4.tcp_fin_timeout = 30 //修改系統默认的 TIMEOUT 时间。</li>
</ul>


<p>这里需要注意的一点就是当打开了tcp_tw_recycle，就会检查时间戳，移动环境下的发来的包的时间戳有些时候是乱跳的，会把带了“倒退”的时间戳的包当作是“recycle的tw连接的重传数据，不是新的请求”，于是丢掉不回包，造成大量丢包。另外，当前面有LVS，并且采用的是NAT机制时，开启tcp_tw_recycle会造成一些异常，可见：<a href="http://www.pagefault.info/?p=416">http://www.pagefault.info/?p=416</a>。如果这种情况下仍然需要开启此选项，那么可以考虑设置net.ipv4.tcp_timestamps=0，忽略掉报文的时间戳即可。</p>

<p>此外，还可以通过优化tcp/ip的可使用端口的范围，进一步提升负载能力。，如下：</p>

<ul>
<li>net.ipv4.tcp_keepalive_time = 1200 //表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。</li>
<li>net.ipv4.ip_local_port_range = 10000 65000 //表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为10000到65000。（注意：这里不要将最低值设的太低，否则可能会占用掉正常的端口！）</li>
<li>net.ipv4.tcp_max_syn_backlog = 8192 //表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。</li>
<li>net.ipv4.tcp_max_tw_buckets = 5000 //表示系统同时保持TIME_WAIT的最大数量，如果超过这个数字，TIME_WAIT将立刻被清除并打印警告信息。默认为180000，改为5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于Squid，效果却不大。此项参数可以控制TIME_WAIT的最大数量，避免Squid服务器被大量的TIME_WAIT拖死。</li>
</ul>


<h3>2.4 应用服务器配置</h3>

<p>说到应用服务器配置，这里需要提到应用服务器的几种工作模式,也叫并发策略。</p>

<ul>
<li>multi process:多进程方式，一个进程处理一个请求。</li>
<li>prefork：类似于多进程的方式，但是会预先fork出一些进程供后续使用，是一种进程池的理念。</li>
<li>worker：一个线程对应一个请求，相比多进程的方式，消耗资源变少，但同时一个线程的崩溃会引起整个进程的崩溃，稳定性不如多进程。</li>
<li>master/worker：采用的是非阻塞IO的方式，只有两种进程：worker和master,master负责worker进程的创建、管理等，worker进程采用基于事件驱动的多路复用IO处理请求。mater进程只需要一个，woker进程根据cpu核数设置数目。</li>
</ul>


<p>前三者是传统应用服务器apache和tomcat采用的方式，最后一种是nginx采用的方式。当然这里需要注意的是应用服务器和nginx这种做反向代理服务器（暂且忽略nginx+cgi做应用服务器的功能）的区别。应用服务器是需要处理应用逻辑的，有时候是耗cup资源的；而反向代理主要用作IO，是IO密集型的应用。使用事件驱动的这种网络模型，比较适合IO密集型应用，而并不适合CPU密集型应用。对于后者，多进程/线程则是一个更好地选择。</p>

<p>当然，由于nginx采用的基于事件驱动的多路IO复用的模型，其作为反向代理服务器时，可支持的并发是非常大的。淘宝tengine团队曾有一个测试结果是“24G内存机器上，处理并发请求可达200万”。</p>

<h4>2.4.1 nginx/tengine</h4>

<p>ngixn是目前使用最广泛的反向代理软件，而tengine是阿里开源的一个加强版nginx,其基本实现了nginx收费版本的一些功能，如：主动健康检查、session sticky等。对于nginx的配置，需要注意的有这么几点：</p>

<ul>
<li>worker数目要和cpu（核）的数目相适应</li>
<li>keepalive timout要设置适当</li>
<li>worker_rlimit_nofile最大文件描述符要增大</li>
<li>upstream可以使用http 1.1的keepalive</li>
</ul>


<p>典型配置可见：<a href="https://github.com/superhj1987/awesome-config/blob/master/nginx/nginx.conf">https://github.com/superhj1987/awesome-config/blob/master/nginx/nginx.conf</a></p>

<h4>2.4.2 tomcat</h4>

<p>tomcat的关键配置总体上有两大块：jvm参数配置和connector参数配置。</p>

<ul>
<li><p>jvm参数配置：</p>

<ul>
<li>堆的最小值：Xms</li>
<li>堆的最大值：Xmx</li>
<li>新生代大小: Xmn</li>
<li>永久代大小: XX:PermSize：</li>
<li>永久代最大大小: XX:MaxPermSize：</li>
<li>栈大小：-Xss或-XX:ThreadStackSize</li>
</ul>


<p>  这里对于栈大小有一点需要注意的是：在Linux x64上ThreadStackSize的默认值就是1024KB，给Java线程创建栈会用这个参数指定的大小。如果把-Xss或者-XX:ThreadStackSize设为0，就是使用“系统默认值”。而在Linux x64上HotSpot VM给Java栈定义的“系统默认”大小也是1MB。所以普通Java线程的默认栈大小怎样都是1MB。这里有一个需要注意的地方就是java的栈大小和之前提到过的操作系统的操作系统栈大小（ulimit -s）：这个配置只影响进程的初始线程；后续用pthread_create创建的线程都可以指定栈大小。HotSpot VM为了能精确控制Java线程的栈大小，特意不使用进程的初始线程（primordial thread）作为Java线程。</p>

<p>  其他还要根据业务场景，选择使用那种垃圾回收器，回收的策略。另外，当需要保留GC信息时，也需要做一些设置。</p>

<p>  典型配置可见：<a href="https://github.com/superhj1987/awesome-config/blob/master/tomcat/java_opts.conf">https://github.com/superhj1987/awesome-config/blob/master/tomcat/java_opts.conf</a></p></li>
<li><p>connector参数配置</p>

<ul>
<li>protocol: 有三个选项：bio；nio；apr。建议使用apr选项，性能为最高。</li>
<li>connectionTimeout：连接的超时时间</li>
<li>maxThreads：最大线程数，此值限制了bio的最大连接数</li>
<li>minSpareThreads: 最大空闲线程数</li>
<li>acceptCount：可以接受的最大请求数目（未能得到处理的请求排队）</li>
<li>maxConnection: 使用nio或者apr时，最大连接数受此值影响。</li>
</ul>


<p>  典型配置可见：<a href="https://github.com/superhj1987/awesome-config/blob/master/tomcat/connector.conf">https://github.com/superhj1987/awesome-config/blob/master/tomcat/connector.conf</a></p>

<p>  一般的当一个进程有500个线程在跑的话，那性能已经是很低很低了。Tomcat默认配置的最大请求数是150。当某个应用拥有250个以上并发的时候，应考虑应用服务器的集群。</p>

<p>  另外，并非是无限调大maxTreads和maxConnection就能无限调高并发能力的。线程越多，那么cpu花费在线程调度上的时间越多，同时，内存消耗也就越大，那么就极大影响处理用户的请求。受限于硬件资源，并发值是需要设置合适的值的。</p></li>
</ul>


<p>对于tomcat这里有一个争论就是：<strong><em>使用大内存tomcat好还是多个小的tomcat集群好？</em></strong>（针对64位服务器以及tomcat来说）</p>

<p>其实，这个要根据业务场景区别对待的。通常，大内存tomcat有以下问题：</p>

<ul>
<li>一旦发生full gc，那么会非常耗时</li>
<li>一旦gc，dump出的堆快照太大，无法分析</li>
</ul>


<p>因此，如果可以保证一定程度上程序的对象大部分都是朝生夕死的，老年代不会发生gc,那么使用大内存tomcat也是可以的。但是在伸缩性和高可用却比不上使用小内存（相对来说）tomcat集群。</p>

<p>使用小内存tomcat集群则有以下优势：</p>

<ul>
<li>可以根据系统的负载调整tc的数量，以达到资源的最大利用率，</li>
<li>可以防止单点故障。</li>
</ul>


<h4>2.4.3 数据库</h4>

<h5>mysql</h5>

<p>mysql是目前最常用的关系型数据库，支持复杂的查询。但是其负载能力一般，很多时候一个系统的瓶颈就发生在mysql这一点，当然有时候也和sql语句的效率有关。比如，牵扯到联表的查询一般说来效率是不会太高的。</p>

<p>影响数据库性能的因素一般有以下几点：</p>

<ul>
<li>硬件配置：这个无需多说</li>
<li>数据库设置：max_connection的一些配置会影响数据库的连接数</li>
<li>数据表的设计：使用冗余字段避免联表查询；使用索引提高查询效率</li>
<li>查询语句是否合理：这个牵扯到的是个人的编码素质。比如，查询符合某个条件的记录，我见过有人把记录全部查出来，再去逐条对比</li>
<li>引擎的选择：myisam和innodb两者的适用场景不同，不存在绝对的优劣</li>
</ul>


<p>抛开以上因素，当数据量单表突破千万甚至百万时（和具体的数据有关），需要对mysql数据库进行优化，一种常见的方案就是分表：</p>

<ul>
<li>垂直分表：在列维度的拆分</li>
<li>水平分表：行维度的拆分</li>
</ul>


<p>此外，对于数据库，可以使用读写分离的方式提高性能，尤其是对那种读频率远大于写频率的业务场景。这里一般采用master/slave的方式实现读写分离，前面用程序控制或者加一个proxy层。可以选择使用MySQL Proxy，编写lua脚本来实现基于proxy的mysql读写分离；也可以通过程序来控制，根据不同的sql语句选择相应的数据库来操作，这个也是笔者公司目前在用的方案。由于此方案和业务强绑定，是很难有一个通用的方案的，其中比较成熟的是阿里的TDDL，但是由于未全部开源且对其他组件有依赖性，不推荐使用。</p>

<p>现在很多大的公司对这些分表、主从分离、分布式都基于mysql做了自己的二次开发，形成了自己公司的一套分布式数据库系统。比如阿里的<a href="https://github.com/alibaba/cobar">Cobar</a>、网易的DDB、360的Atlas等。当然，很多大公司也研发了自己的mysql分支，比较出名的就是姜承尧带领研发的InnoSQL。</p>

<h5>redis</h5>

<p>当然，对于系统中并发很高并且访问很频繁的数据，关系型数据库还是不能妥妥应对。这时候就需要缓存数据库出马以隔离对mysql的访问,防止mysql崩溃。</p>

<p>其中，redis是目前用的比较多的缓存数据库（当然，也有直接把redis当做数据库使用的）。redis是单线程基于内存的数据库，读写性能远远超过mysql。一般情况下，对redis做读写分离主从同步就可以应对大部分场景的应用。但是这样的方案缺少ha，尤其对于分布式应用，是不可接受的。目前，redis集群的实现方案有以下几个：</p>

<ul>
<li>redis cluster:这是一种去中心化的方案，是redis的官方实现。是一种非常“重”的方案，已经不是Redis单实例的“简单、可依赖”了。目前应用案例还很少，貌似国内的芒果台用了，结局不知道如何。</li>
<li><a href="https://github.com/twitter/twemproxy">twemproxy</a>：这是twitter开源的redis和memcached的proxy方案。比较成熟，目前的应用案例比较多，但也有一些缺陷，尤其在运维方面。比如无法平滑的扩容/缩容，运维不友好等。</li>
<li><a href="https://github.com/wandoulabs/codis">codis</a>: 这个是豌豆荚开源的redis proxy方案，能够兼容twemproxy，并且对其做了很多改进。由豌豆荚于2014年11月开源，基于Go和C开发。现已广泛用于豌豆荚的各种Redis业务场景。现在比Twemproxy快近100%。目前据我所知除了豌豆荚之外，hulu也在使用这套方案。当然，其升级项目<a href="https://github.com/reborndb/reborn">reborndb</a>号称比codis还要厉害。</li>
</ul>


<h3>2.5 系统架构</h3>

<p>影响性能的系统架构一般会有这几方面：</p>

<ul>
<li>负载均衡</li>
<li>同步 or 异步</li>
<li>28原则</li>
</ul>


<h4>2.5.1 负载均衡</h4>

<p>负载均衡在服务端领域中是一个很关键的技术。可以分为以下两种：</p>

<ul>
<li>硬件负载均衡</li>
<li>软件负载均衡</li>
</ul>


<p>其中，硬件负载均衡的性能无疑是最优的，其中以F5为代表。但是，与高性能并存的是其成本的昂贵。所以对于很多初创公司来说，一般是选用软件负载均衡的方案。</p>

<p>软件负载均衡中又可以分为四层负载均衡和七层负载均衡。
上文在应用服务器配置部分讲了nginx的反向代理功能即七层的一种成熟解决方案，主要针对的是七层http协议（虽然最新的发布版本已经支持四层负载均衡）。对于四层负载均衡，目前应用最广泛的是lvs。其是阿里的章文嵩博士带领的团队所研发的一款linux下的负载均衡软件，本质上是基于iptables实现的。分为三种工作模式：</p>

<ul>
<li>NAT: 修改数据包destination ip，in和out都要经过lvs。</li>
<li>DR：修改数据包mac地址，lvs和realserver需要在一个vlan。</li>
<li>IP TUUNEL：修改数据包destination ip和源ip，realserver需要支持ip tunnel协议。lvs和realserver不需要在一个vlan。</li>
</ul>


<p>三种模式各有优缺点，目前还有阿里开源的一个FULL NAT是在NAT原来的DNAT上加入了SNAT的功能。</p>

<p>此外，haproxy也是一款常用的负载均衡软件。但限于对此使用较少，在此不做讲述。</p>

<h4>2.5.2 同步 or 异步</h4>

<p>对于一个系统，很多业务需要面对使用同步机制或者是异步机制的选择。比如，对于一篇帖子，一个用户对其分享后，需要记录用户的分享记录。如果你使用同步模式（分享的同时记录此行为），那么响应速度肯定会受到影响。而如果你考虑到分享过后，用户并不会立刻去查看自己的分享记录，牺牲这一点时效性，可以先完成分享的动作，然后异步记录此行为，会提高分享请求的响应速度（当然，这里可能会有事务准确性的问题）。有时候在某些业务逻辑上，在充分理解用户诉求的基础上，是可以牺牲某些特性来满足用户需求的。</p>

<p>这里值得一提的是，很多时候对于一个业务流程，是可以拆开划分为几个步骤的，然后有些步骤完全可以异步并发执行，能够极大提高处理速度。</p>

<h4>2.5.3 28原则</h4>

<p>对于一个系统，20%的功能会带来80%的流量。这就是28原则的意思，当然也是我自己的一种表述。因此在设计系统的时候，对于80%的功能，其面对的请求压力是很小的，是没有必要进行过度设计的。但是对于另外20%的功能则是需要设计再设计、reivew再review，能够做负载均衡就做负载均衡，能够缓存就缓存，能够做分布式就分布式，能够把流程拆开异步化就异步化。</p>

<p>当然，这个原则适用于生活中很多事物。</p>

<h2>三. 一般架构</h2>

<p>一般的Java后端系统应用架构如下图所示：LVS+Nginx+Tomcat+MySql/DDB+Redis/Codis</p>

<p><img src="http://www.rowkey.me/images/blog_images/web-arch.png" alt="web-arch" /></p>

<p>其中，虚线部分是数据库层，采用的是主从模式。也可以使用redis cluster(codis等)以及mysql cluster(Cobar等)来替换。</p>

<pre><code>如需转载，请注明来自: http://superhj1987.github.com

版权声明：本文为博主原创文章，未经博主允许不得转载

本文部分参考自网络相关资料，由于时间太久，无法追朔原作者。如有侵权，请联系superhj1987@126.com
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hbase关键的几个点]]></title>
    <link href="http://www.rowkey.me/blog/2015/06/10/hbase-about/"/>
    <updated>2015-06-10T10:59:59+08:00</updated>
    <id>http://www.rowkey.me/blog/2015/06/10/hbase-about</id>
    <content type="html"><![CDATA[<h2>一. 什么时候需要HBase</h2>

<ol>
<li><p>半结构化或非结构化数据</p>

<p> 对于数据结构字段不够确定或杂乱无章很难按一个概念去进行抽取的数据适合用HBase。当业务发展需要增加存储比如一个用户的email，phone，address信息时RDBMS需要停机维护，而HBase支持动态增加.</p></li>
<li><p>记录非常稀疏</p>

<p> RDBMS的行有多少列是固定的，为null的列浪费了存储空间。而如上文提到的，HBase为null的Column不会被存储，这样既节省了空间又提高了读性能。</p></li>
<li><p>多版本数据</p>

<p> 根据Row key和Column key定位到的Value可以有任意数量的版本值，因此对于需要存储变动历史记录的数据，用HBase就非常方便了。对于某一值，业务上一般只需要最新的值，但有时可能需要查询到历史值。</p></li>
<li><p>超大数据量</p>

<p> 当数据量越来越大，RDBMS数据库撑不住了，就出现了读写分离策略，通过一个Master专门负责写操作，多个Slave负责读操作，服务器成本倍增。随着压力增加，Master撑不住了，这时就要分库了，把关联不大的数据分开部署，一些join查询不能用了，需要借助中间层。随着数据量的进一步增加，一个表的记录越来越大，查询就变得很慢，于是又得搞分表，比如按ID取模分成多个表以减少单个表的记录数。经历过这些事的人都知道过程是多么的折腾。采用HBase就简单了，只需要加机器即可，HBase会自动水平切分扩展，跟Hadoop的无缝集成保障了其数据可靠性（HDFS）和海量数据分析的高性能（MapReduce）</p></li>
</ol>


<h2>二. HTable一些基本概念</h2>

<ol>
<li><p>Row key</p>

<p> 行主键， HBase不支持条件查询和Order by等查询，读取记录只能按Row key（及其range）或全表扫描，因此Row key需要根据业务来设计以利用其存储排序特性（Table按Row key字典序排序如1,10,100,11,2）提高性能。</p></li>
<li><p>Column Family（列族）</p>

<p> 在表创建时声明，每个Column Family为一个存储单元。</p></li>
<li><p>Column（列）</p>

<p> HBase的每个列都属于一个列族，以列族名为前缀，如列article:title和article:content属于article列族，author:name和author:nickname属于author列族。</p>

<p> Column不用创建表时定义即可以动态新增，同一Column Family的Columns会群聚在一个存储单元上，并依Column key排序，因此设计时应将具有相同I/O特性的Column设计在一个Column Family上以提高性能。</p></li>
<li><p>Timestamp</p>

<p> HBase通过row和column确定一份数据，这份数据的值可能有多个版本，不同版本的值按照时间倒序排序，即最新的数据排在最前面，查询时默认返回最新版本。Timestamp默认为系统当前时间（精确到毫秒），也可以在写入数据时指定该值。</p></li>
<li><p>Value</p>

<p> 每个值通过4个键唯一索引，tableName+RowKey+ColumnKey+Timestamp=>value</p></li>
<li><p>存储类型</p>

<ul>
<li>TableName 是字符串</li>
<li>RowKey 和 ColumnName 是二进制值（Java 类型 byte[]）</li>
<li>Timestamp 是一个 64 位整数（Java 类型 long）</li>
<li>value 是一个字节数组（Java类型 byte[]）。</li>
</ul>
</li>
</ol>


<p>将HTable的存储结构理解为</p>

<p><img src="http://www.rowkey.me/images/blog_images/hbase_data.jpg" alt="hbase-data" /></p>

<p>即HTable按Row key自动排序，每个Row包含任意数量个Columns，Columns之间按Column key自动排序，每个Column包含任意数量个Values。理解该存储结构将有助于查询结果的迭代。</p>

<h2>三. 模式设计应遵循的原则</h2>

<ol>
<li><p>列族的数量以及列族的势</p>

<p> 列族的数量越少越好，牵扯到了hbase的flushing；同一个表中不同列族所存储的记录数量的差别也需要考虑（列族的势），会造成记录数量少的列族的数据分散在多个region上，影响查询效率。</p></li>
<li><p>行键的设计</p>

<p> 避免使用时序或者单调（递增/递减）行键，否则会导致连续到来的数据会被分配到统一region中。</p></li>
<li><p>尽量最小化行键和列族的大小</p>

<p> 避免hbase的索引过大，加重系统存储的负担</p></li>
<li><p>版本的数量</p>

<p> HColumnDescriptor设置版本的数量，避免设置过大，版本保留过多。</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于Spring mvc中model的attribute无法指定别名的解决方案]]></title>
    <link href="http://www.rowkey.me/blog/2015/01/21/springm-mvc-model-attribute-alias/"/>
    <updated>2015-01-21T12:00:00+08:00</updated>
    <id>http://www.rowkey.me/blog/2015/01/21/springm-mvc-model-attribute-alias</id>
    <content type="html"><![CDATA[<p>最近由于项目需要，发现spring mvc在绑定参数时有这么一个缺陷。</p>

<p><strong>Url</strong>: <a href="http://localhost:8080/api/test?user_name=testUser">http://localhost:8080/api/test?user_name=testUser</a></p>

<p><strong>Controller</strong>:</p>

<pre>
@Controller
@RequestMapping("/api")
public class ApiController extends BaseController {

    @RequestMapping(value = "/test", headers = "Accept=application/json")
    public void authUser(ModelMap modelMap, Account acc) {
        ResultPack.packOk(modelMap);
    }
}

public class Account{
    private static final long serialVersionUID = 750752375611621980L;

    private long id;
    private String userName;
    private String password;
    private AccountType type = AccountType.ADMIN;
    private long timeTag;
    private int status = 1;
    ...
    ...
}
</pre>


<p>user_name无法映射到acc的userName上。如果使用json的方式，可以使用JsonProperty注解来解决。否则，spring貌似没提供解决方案。</p>

<p>于是追踪了一下spring mvc的源代码，发现可以通过重写ServletModelAttributeMethodProcessor来支持这个功能。</p>

<p><strong>Github</strong>:  <a href="https://github.com/superhj1987/spring-mvc-model-attribute-alias">https://github.com/superhj1987/spring-mvc-model-attribute-alias</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[工作总结@2014]]></title>
    <link href="http://www.rowkey.me/blog/2015/01/15/2014-final-note/"/>
    <updated>2015-01-15T16:08:48+08:00</updated>
    <id>http://www.rowkey.me/blog/2015/01/15/2014-final-note</id>
    <content type="html"><![CDATA[<p>突然发觉已经是2015年的1月15号了，即兴补上一篇2014年的总结吧。</p>

<p>对自己来说，今年最大的事情莫过于离开一座城市，到达另一座城市，开始了新的职业生涯。</p>

<p>进入新的公司，一个创业公司，截然不同的运作方式让我一开始有点措手不及。相比之前在大公司，小公司更需要一个人的快速成长以及自我约束，以及那种随叫随到、不怕脏累的奋斗精神。而技术层面，要尽最大化压榨硬件资源，用有限的硬件资源达到最大的性能。这些都让自己的架构方式和代码编写不得不去改变、去适应，这也算是一种成长吧。公司的基础架构、公共组件、项目管理、技术体系、项目架构都是一个初级的水平，改变这些是一个很难很长的路，但又不得不做。到现在，在做这些改变的过程中，自己的基础知识得到了巩固、架构能力也有了一定的提升，技术视野也开阔了一些。熟悉了公司的流程和整体的氛围，也算融入了这个团队，要做的还有很多，阻力也有很多。一切都在逼迫自己去学习、去思考、去提高。这也是与以前相比，给自己最大动力的事情。</p>

<p>2015年，工作上希望自己能做到这些</p>

<ul>
<li>合理设计并实现整个公司的基础架构</li>
<li>构建合理的项目管理流程、监督机制</li>
<li>提升团队的整体水平</li>
<li>保证产品的研发进度以及线上稳定性</li>
<li>招一些优秀的人加入</li>
</ul>


<p>自身方面，希望能做到这些：</p>

<ul>
<li>提升自身的技术水平和视野</li>
<li>深入学习一门技术：docker netty kafka rabbitmq elasticsearch solr</li>
<li>阅读至少五本非技术书籍</li>
</ul>


<p>Stay hungry,stay foolish!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spring mvc的controller传递HttpServletResponse参数的一点事]]></title>
    <link href="http://www.rowkey.me/blog/2014/12/09/spring-mvc-httpservletresponse/"/>
    <updated>2014-12-09T10:05:41+08:00</updated>
    <id>http://www.rowkey.me/blog/2014/12/09/spring-mvc-httpservletresponse</id>
    <content type="html"><![CDATA[<pre>
    @RequestMapping(value = "cardDown", method = RequestMethod.GET, headers = "Accept=text/html")
    public void cardDown(ModelMap modelMap, HttpServletRequest request, HttpServletResponse response, String id, int status){
    ......
    }
</pre>


<p>之前在使用Spring mvc的时候发现这么一回事：在spring mvc的controller的参数里如果有HttpServletResponse(类似上面的代码),那么必须有返回值框架才会去在执行完handler后去搜索相应的viewResolver和view从而展现数据。如果没有返回值，那么默认就是返回null的。我初步推测框架的处理过程大致如此：如果controller参数里传递HttpServletResposne的话，框架就认为视图由handler自己生成可以不参于这个过程,但是如果handler有返回值的话，那么仍然认为还需要参与到视图生成的过程中。</p>

<!--more-->


<p>翻了一下spring mvc的代码，验证了自己的想法。在DispatchServlet的921行</p>

<pre>
// Actually invoke the handler.
mv = ha.handle(processedRequest, response, mappedHandler.getHandler());
</pre>


<p>这里的mv就是视图生成的结果。接着经历下面的过程：</p>

<ol>
<li>AbstractHandlerMethodAdapter.handle</li>
<li>RequestMappingHandlerAdapter.handleInternal</li>
<li><p>RequestMappingHandlerAdapter.invokeHandleMethod</p>

<p> 这地方有一个关键的变量mavContainer
 <pre>
 ModelAndViewContainer mavContainer = new ModelAndViewContainer();
 </pre>
 mavContainer有一个属性requestHandled，其标志着此次请求是否是由handler自己控制的。默认为false。</p></li>
<li><p>ServletInvocableHandlerMethod.invokeAndHandle</p></li>
<li>InvocableHandlerMethod.invokeForRequest</li>
<li><p>InvocableHandlerMethod.getMethodArgumentValues</p>

<p> 这个方法的功能在名字上大体就能看出来：获取controller中每一个参数的值。关键的地方在于
 <pre>
 args[i] = argumentResolvers.resolveArgument(parameter, mavContainer, request, dataBinderFactory);
 </pre>
 这一行代码关联的是对每一中paramerter的处理类。接下来的调用见7</p></li>
<li><p>HandlerMethodArgumentResolverComposite.resolveArgument</p>

<p> <pre>
 HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter);
 Assert.notNull(resolver, &ldquo;Unknown parameter type [&rdquo; + parameter.getParameterType().getName() + &ldquo;]&rdquo;);
 return resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);
 </pre></p>

<p> 这里的代码就三行，第一步是根据参数不同，获取不同的argumentResolver。当参数为HttpServletResponse的时候，就会调用ServletResponseMethodArgumentResolver.resolveArgument</p></li>
<li><p>ServletResponseMethodArgumentResolver.resolveArgument</p>

<p> 最核心的一段代码来了</p>

<p> <pre>
 if (mavContainer != null) {
     mavContainer.setRequestHandled(true);
 }
 </pre></p>

<p> 这里就把mavContainer的requestHandled设置为了true.</p></li>
<li><p>回到4，调用完InvocableHandlerMethod.invokeForRequest</p>

<p> <pre>
 if (returnValue == null) {
     if (isRequestNotModified(webRequest) || hasResponseStatus() || mavContainer.isRequestHandled()) {
         mavContainer.setRequestHandled(true);
         return;
     }
 }else if (StringUtils.hasText(this.responseReason)) {
     mavContainer.setRequestHandled(true);
     return;
 }</p>

<p> mavContainer.setRequestHandled(false);
 </pre></p>

<p> 当handler的返回值为null的时候，直接返回。否则将mavContainer的requestHandled设置为false。</p></li>
<li><p>接着回到3，调用完ServletInvocableHandlerMethod.invokeAndHandle后，接着调用getModelAndView(mavContainer, modelFactory, webRequest)</p></li>
<li><p>ServletInvocableHandlerMethod.getModelAndView</p>

<p><pre>
modelFactory.updateModel(webRequest, mavContainer);</p>

<p>if (mavContainer.isRequestHandled()) {
    return null;
}
</pre></p>

<p>这里当mavContainer的requestHandled被设置为true时,视图返回null。</p></li>
</ol>


<p>整个大体的流程就是这样的，如果需要使用HttpServletResponse同时还需要框架控制视图生成的话，可以给controller method一个返回值（随便什么都行）。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ShellShock这点事]]></title>
    <link href="http://www.rowkey.me/blog/2014/09/29/shell-shock/"/>
    <updated>2014-09-29T21:49:46+08:00</updated>
    <id>http://www.rowkey.me/blog/2014/09/29/shell-shock</id>
    <content type="html"><![CDATA[<h2>前言</h2>

<p>在微博上看到最近安全界爆出了一个危害比之前的“心脏流血”（Heartbleed Bug）还要大很多的Bash代码注入漏洞：CVE-2014-6271 “shellshock”漏洞，然后随之而来一系列相关漏洞。详情可以看这些链接：<a href="http://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2014-6271">CVE-2014-6271</a> 、<a href="http://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2014-7169">CVE-2014-7169</a>、<a href="https://access.redhat.com/security/cve/CVE-2014-7186">CVE-2014-7186</a>、<a href="https://access.redhat.com/security/cve/CVE-2014-7187">CVE-2014-7187</a>、<a href="https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2014-6277">CVE-2014-6277</a>。世界上Linux服务器的占有份额是很大的，而bash又是Linux不可或缺的一个部分。可想而知，这个漏洞的破坏力有多大。这个从名字上就可以看出来，ShellShock是医学上的一种严重的疾病，中文叫做“弹震症”，指的是受到爆炸冲击后导致浑身颤抖、思维混乱等症状。这个命名很形象地反映了问题的严重性。</p>

<!--more-->


<h2>漏洞的原理是什么</h2>

<p>参照shellshock官网<a href="https://shellshocker.net/">https://shellshocker.net/</a>，测试本机是否受这个漏洞的影响，先要执行一段shell代码：</p>

<pre>
env x='() { :;}; echo vulnerable' bash -c ""
</pre>


<p>如果发现有以下输出说明你系统受到这个漏洞的影响。</p>

<pre>
vulnerable
</pre>


<p>为什么会这样呢？看一下代码，首先设置一个环境变量x，x指向的是一个函数，这个函数仅仅有一句:;的代码，就是返回true。后面跟着的echo vulnerable，按说是不应该为执行的。后面的bash -c &hellip;，这里使用bash命令开启了子shell，子shell会在启动的时候继承父shell的环境变量，于是在继承x这个变量的时候，就把echo vulnerable这行执行了。结果就是打印出了vulnerable。</p>

<p>官网上提到如果这一步就发现自己收到了影响，那么先update bash吧。</p>

<p>在升级完bash后，并非就高枕无忧了，又有人发现了更NB的利用这个漏洞的办法。执行下面的shell代码：</p>

<pre>
env X='() { (shellshocker.net)=>\' bash -c "echo date"; cat echo ; rm -f echo
</pre>


<p>如果这行代码，打印出了日期（可能会伴有一些错误），那么说明你仍然没有逃脱这个漏洞的影响。</p>

<pre>
bash: X: line 1: syntax error near unexpected token `='
bash: X: line 1: `'
bash: error importing function definition for `X'
2014年 9月29日 星期一 21时04分30秒 CST
</pre>


<p>update bash之后，只是让子shell继承父shell的时候不去执行后面的语句。但是这个代码变态之处在于它故意使用（shellshocker.net）=让shell报错，后面的>\则留在了缓冲区中，子shell继承到了>\,然后执行echo date，此时相当于下面的代码：</p>

<pre>
>\
echo date
</pre>


<p>\是命令换行的，于是就相当于>echo date，>是重定向符号，最后其实等价于date  > echo，这样最终把命令给执行了。</p>

<p>此外，官网还列出了其他的exploit，都是利用了子进程对环境变量的继承：</p>

<ol>
<li><p>Exploit 3 (???)</p>

<p> Here is another variation of the exploit. Please leave a comment below if you know the CVE of this exploit.
 <pre>
env -i X=&lsquo; () { }; echo hello&rsquo; bash -c &lsquo;date&rsquo;
</pre></p>

<p>  If the above command outputs &ldquo;hello&rdquo;, you are vulnerable.</p></li>
<li><p>Exploit 4 (CVE-2014-7186)</p></li>
<li><p>Exploit 5 (CVE-2014-7187)</p></li>
</ol>


<h2>怎样利用这个漏洞</h2>

<p>看了上面说的bash漏洞，那我们怎样来利用呢？举一个典型的列子，现在有很多网站是使用的apache运行在Linux系统上的，也是以子进程的方式来运行web程序的，其中用户端传来的HTTP_USER_AGENT、HTTP_HEADER等是会传递到子进程中的，而且这些变量是用户端任意可以指定的，如果按照开始讲的那样传递一个x过来，但是并不仅仅是echo一个字符串，那危害。。。可想而知。如下面的一个http请求（如果不是仅仅ping一个ip地址）：</p>

<pre>
http-user-agent = shellshock-scan () http-header = Cookie:() { :; }; ping -c 163.com
http-header = Host:() { :; }; ping -c 163.com
http-header = Referer:() { :; }; ping -c 163.com
</pre>


<p>除此之外，现在已经有利用这个漏洞攻击DHCP客户端、VoIP设备、Git版本控制系统、qmail等的成功例子了，可以说有Linux的地方就有shellshock的“用武之地”，包括Mac os。这篇文章总结了现在发现的各种各样的攻击方式：<a href="http://www.fireeye.com/blog/uncategorized/2014/09/shellshock-in-the-wild.html">http://www.fireeye.com/blog/uncategorized/2014/09/shellshock-in-the-wild.html</a></p>

<p>看到这里，可能有人会说：”让你们天天说Linux有多安全”。其实Windows也逃不开这个漏洞的危害，很多windows系统里都有bash环境，即使没有bash环境，只要你的系统使用了含有bash的组件（如负载均衡、CDN）也难逃shellshock的魔掌。</p>

<h2>总结</h2>

<p>修复Shellshock漏洞就像打地鼠，堵了一头另一头又冒出，修复一部分，很快就有其他的攻击方式出现，层出不穷，问题的关键其实还是在于bash在设计的时候对于环境变量的依赖。只要存在对环境变量的导出，那么攻击者就可以使用各种方式诱骗bash视其为命令，进行执行。</p>

<h3>参考文章</h3>

<ul>
<li><a href="http://www.oschina.net/news/55694/shellshock-flaw">http://www.oschina.net/news/55694/shellshock-flaw</a></li>
<li><a href="http://news.cnblogs.com/n/504675/">http://news.cnblogs.com/n/504675/</a></li>
<li><a href="http://weibo.com/p/1005051401527553/weibo">http://weibo.com/p/1005051401527553/weibo</a></li>
<li><a href="https://shellshocker.net/">https://shellshocker.net/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JVM内存GC的骗局（转载）]]></title>
    <link href="http://www.rowkey.me/blog/2014/09/25/jvm-cheat/"/>
    <updated>2014-09-25T21:29:52+08:00</updated>
    <id>http://www.rowkey.me/blog/2014/09/25/jvm-cheat</id>
    <content type="html"><![CDATA[<h2>概述</h2>

<p>在日常程序开发中，很多JAVA程度员不太关心内存的使用情况。当然，如果程序员运气较好或者系统没有大规模的被测试或者被用户使用时，这个问题或许永远不出现，使得程序员一直认为内存反正是无限的，可以一直使用。确实，JVM的垃圾回收器会帮我们处理好所有的事情，可如果运气不是那么好，不幸就有可能发生在我们的身上，比如：进程会抛出OOM异常，不再接收新的请求；响应时间在固定时间段内变长，超时或者不响应，CPU使用率时常像过山车一样等。内存使用在大部分的工作时间可以正常工作，这样会导致很多的人对JAVA应用的内存使用情况不明了或者得不到充分的性能测试，而导致程序无法正常工作。出现上面的情况程序员一般会比较好的较快的发现问题或能总结一定的规律。</p>

<!--more-->


<h2>问题</h2>

<p>有时候JVM还会发生欺骗你的场景， JVM不停的在垃圾回收，可是每次回收完后堆却还是满的，很明显程序内存被使用完了，已经无法正常工作了，但JVM就是不抛出OutOfMemoryError(OOM)这个异常来告诉程序员内部发出了什么，只是不停的做老好人尝试帮我们做垃圾回收，把服务器的资源耗光了，但是此时服务器已经无法响应用户的正常请求了，让我们一起来看看这些情况发生时候的现象，体会一下被欺骗的感觉。</p>

<h2>现状：</h2>

<p>同事在模拟用户不停的发送请求给某系统，在运行一段时间后，突然，系统上邮件报告测试用例请求失败，登录测试系统的服务器，首先看下JVM的参数设置，如下：</p>

<p>-server –Xms4g –Xmx4g -XX:MaxPermSize=256m  -verbose:gc -XX:+PrintGCDetails -Xloggc:$CATALINA_BASE/logs/gc.log -XX:+PrintGCTimeStamp，再使用TOP命令看看服务器发生了什么。</p>

<p>观察一段时间后，CPU一直运行在100%，于是想当然的认为可能是那段程序里面触发了BUG,有可能是正则表达式或者某段代码里面有个死循环的坑跳进去，没有出来。这不是很简单的事吗？直接使用jstack + pid 把堆栈打出来即可，直接操作吧，界面上马上输出操作日志，从堆栈日志可以看出，所有的线程都被BLOCKED住了，然后堆栈里面也找不到任何业务的相关代码，难道直觉出错了，感觉一下子不太好了，但是至少可以排查到不是上面的二种原因了，好吧，那再看看应用的GC的情况，部分日志如下。</p>

<p>1403682.561: [GC [PSYoungGen: 1375104K->11376K(1386176K)] 4145665K->2782002K(4182400K), 0.0174410 secs] [Times: user=0.27 sys=0.00, real=0.02 secs]</p>

<p>1407799.743: [GC [PSYoungGen: 1386160K->11632K(1386432K)] 4156786K->2793538K(4182656K), 0.0285330 secs] [Times: user=0.48 sys=0.00, real=0.03 secs]</p>

<p>1409230.024: [GC [PSYoungGen: 1386416K->10688K(1377984K)] 4168322K->2803822K(4174208K), 0.0265000 secs] [Times: user=0.43 sys=0.00, real=0.02 secs]</p>

<p>1409230.051: [Full GC [PSYoungGen: 10688K->7014K(1377984K)] [PSOldGen: 2793134K->2796224K(2796224K)] 2803822K->2803238K(4174208K) [PSPermGen: 48439K->48439K(262144K)], 7.8892780 secs] [Times: user=7.92 sys=0.00, real=7.89 secs]</p>

<p>1410502.582: [Full GC [PSYoungGen: 1366336K->85344K(1377984K)] [PSOldGen: 2796224K->2796224K(2796224K)] 4162560K->2881568K(4174208K) [PSPermGen: 48577K->48577K(262144K)], 8.2720110 secs] [Times: user=8.29 sys=0.00, real=8.27 secs]</p>

<p>PS：这里使用-XX:+PrintGCDateStamps替代-XX:+PrintGCTimeStamp,可以打印出真实时间戳。</p>

<h2>解释一下：</h2>

<p>第一行：
1403682.561: [GC [PSYoungGen: 1375104K->11376K(1386176K)] 4145665K->2782002K(4182400K), 0.0174410 secs] [Times: user=0.27 sys=0.00, real=0.02 secs]</p>

<p>发生的时间点，：JVM运行的时间长度，以度为单位，也可以格式化成固定的时间格式</p>

<p>PSYoungGen：发生了何种类型的GC，此处代表发生了年轻代的GC</p>

<p>1375104K：回收前的大小</p>

<p>11376K：回收后的大小</p>

<p>1386176K：YOUNG代的大小</p>

<p>4145665 K：回收前总的占用大小</p>

<p>2782002K：回收后的占用大小</p>

<p>4182400K：总占用大小</p>

<p>0.27和0.00：代表在用户态(user)和系统状(sys)的CPU运行时间</p>

<p>0.02 secs：代表实际的GC的运行时间</p>

<p>注：上面总的运行时间小于用户态和系统态的时间总和，是由于后者仅指CPU的运行时间，包括等待或IO阻塞的时间，而且现在的GC是采用多线程收集的，同时机器也是多个CPU，因此，大部分是二者之和要比前面的值大，如果是采用串形化收集器( serial collector)的话，二者时间几乎相差不多。关于各种收集器的差别，后续有时间再安排详细总结。</p>

<p>接下来的二行，不再重复说明，第四行有Full字样，代表JVM发生了Full GC，不过多了二个分区的收集，PSOldGen：老生代的回收前后空间大小及总空间；PSPermGen：持久代的回收前后空间大小和总空间。从第三行，可以看出老空间的使用率达到饱和，从而触发了FULL GC，但是很遗憾的是第五行后又接着发生了FULL GC，后面的都是一直在持续进行，但是系统一直不抛出OOM异常或者进程退出，导致这台机器服务进程一直存在，但是基本无法正常工作。</p>

<p>GC，无论Young GC还是Full GC，每次都会导致JVM STW(STOP WORLD)暂停用户的业务工作，来处理垃圾回收任务，短时间内无法响应用户请求，特别是大量的Full GC会导致系统响应速度降低，另外还有OOM的巨大风险。Young GC频繁，就算GC采用多线程回收方式，尽管回收的时候非常短，但是如果GC次数和频率很高，因此对应用的影响是不可忽视的。 Full GC 包括整个分区的垃圾回收，包括新生代、旧生代、持久代等。因此其回收成本高，应用也会暂停更长时间，无法及时响应用户的请求，所以需要特别注意这个种情况，一般来讲，排除主动的调用GC操作外，JVM会在以下几种情况发生Full GC。</p>

<ol>
<li><p>旧生代内存不足</p></li>
<li><p>持久代内存不足</p></li>
<li><p>统计新生代 GC晋升到旧生代的平均大小大于旧生代的剩余空间</p></li>
</ol>


<h2>解决</h2>

<p>知道发生的原因后，就可以使用JMAP -heap直接看一下JVM内存的对像值，或者使用JMAP -dump直接JVM的堆栈DUMP出来，使用MAT打开分析就行。如果这种现像发生之后，DUMP出来的文件会较大，有些会达到十多个G，因为一般不直接在工作机器上进行，需要把文件转发到其他的非线上服务并且内存足够的机器上分析，最后可以用MAT把分析后的文件打开即可，打开后，首页会给出可疑的建议对象实例，直接跳转到列表中，打开折叠细节即可看到真面目，里面包括了三十多万个对象，找相关的人员对根据业务需要，直接把不需要的实例在使用完后移除，其他几行的问题类似处理就即可。</p>

<h2>总结</h2>

<p>从上面GC的发生的情况来看，JVM一次次不停的努力的帮我们进行GC操作，直到把CPU全部占光，但是就是不直接抛出异常直接告诉我们内存不够了，感觉把我们带了到一个巨大的庞氏骗局，也许我们把JVM的内存加大，这个坑还将帮我们隐藏下去，如果程序设置了定时重启之类的操作，这个坑就永远发现不了。一般产品开发人员非常希望应用程序能在用户发觉之前发现这个问题，JVM无法判断出这个问题，因为也就不能帮我们抛出几乎OOM的异常，不过可以通过调整GCTimeLimit和GCHeapFreeLimit参数来重新定义何时抛出OutOfMemoryError错误。GCTimeLimit 的默认值是98%，也就是说如果98%时间都用花在GC上，则会抛出OutOfMemoryError。GCHeapFreeLimit 是回收后可用堆的大小。默认值是2%。当然最好的办法就是开发工程师开始就很清楚如何使用相关的容器类的正确用法，并且在上线前能经过充分的测试或运行。本文只是引用GC方面的一个具体的安全来说明GC是怎么骗人的，关于GC和JVM内存相关的细节如何及时的发现此类的问题，有机会再通过示例和大家探讨学习。</p>

<p>注：以上资料仅以HOTSPOT VM 1.7.65 版本参考。</p>

<p>参考资料：</p>

<p>JVM <a href="http://docs.oracle.com/javase/8/docs/technotes/guides/vm/gc-ergonomics.html">http://docs.oracle.com/javase/8/docs/technotes/guides/vm/gc-ergonomics.html</a></p>

<p>HotSpot JVM就是个庞氏骗局 <a href="http://it.deepinmind.com/gc/2014/04/01/hotspot-jvm-ponzi-scheme.html">http://it.deepinmind.com/gc/2014/04/01/hotspot-jvm-ponzi-scheme.html</a></p>

<p>Java内存泄露分析 <a href="http://doc.hz.netease.com/pages/viewpage.action?pageId=36468038">http://doc.hz.netease.com/pages/viewpage.action?pageId=36468038</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx源码分析之启动过程]]></title>
    <link href="http://www.rowkey.me/blog/2014/09/24/nginx-bootstrap/"/>
    <updated>2014-09-24T17:38:57+08:00</updated>
    <id>http://www.rowkey.me/blog/2014/09/24/nginx-bootstrap</id>
    <content type="html"><![CDATA[<p>nginx的启动过程代码主要分布在src/core以及src/os/unix目录下。启动流程的函数调用序列：main(src/core/nginx.c)→ngx_init_cycle(src/core/ngx_cycle.c)→ngx_master_process_cycle(src/os/)。nginx的启动过程就是围绕着这三个函数进行的。</p>

<p>main函数的处理过程总体上可以概括如下：</p>

<!--more-->


<ol>
<li>简单初始化一些数据接结构和模块：ngx_debug_init、ngx_strerror_init、ngx_time_init、ngx_regex_init、ngx_log_init、ngx_ssl_init等</li>
<li>获取并处理命令参数：ngx_get_options。</li>
<li><p>初始化ngx_cycle_t结构体变量init_cycle，设置其log、pool字段等。
 <pre>
 ngx_memzero(&amp;init_cycle, sizeof(ngx_cycle_t));
 init_cycle.log = log;
 ngx_cycle = &amp;init_cycle;</p>

<p> init_cycle.pool = ngx_create_pool(1024, log);
 if (init_cycle.pool == NULL) {
     return 1;
 }
</pre></p></li>
<li>保存参数，设置全局变量：ngx_argc ngx_os_argv ngx_argv ngx_environ</li>
<li>处理控制台命令行参数，设置init_cycle的字段。这些字段包括：conf_prefix、prefix（-p prefix）、conf_file(-c filename)、conf_param(-g directives)。此外，还设置init_cyle.log.log_level=NGX_LOG_INFO。</li>
<li>调用ngx_os_init来设置一些和操作系统相关的全局变量：ngx_page_size、ngx_cacheline_size、ngx_ncpu、ngx_max_sockets、ngx_inherited_nonblocking。</li>
<li>调用ngx_crc32_table_init初始化ngx_crc32_table_short。用于后续做crc校验。</li>
<li>调用ngx_add_inherited_sockets(&amp;init_cycle)→ngx_set_inherited_sockets，初始化init_cycle的listening字段（一个ngx_listening_t的数组）。</li>
<li>对所有模块进行计数
 <pre>
 ngx_max_module = 0;
 for (i = 0; ngx_modules[i]; i++) {
     ngx_modules[i]->index = ngx_max_module++;
 }
</pre></li>
<li>调用ngx_init_cycle进行模块的初始化，当解析配置文件错误时，退出程序。这个函数传入init_cycle然后返回一个新的ngx_cycle_t。</li>
<li>调用ngx_signal_process、ngx_init_signals处理信号。</li>
<li>在daemon模式下，调用ngx_daemon以守护进程的方式运行。这里可以在./configure的时候加入参数&ndash;with-debug，并在nginx.conf中配置:
<pre>
master_process  off; # 简化调试 此指令不得用于生产环境
daemon          off; # 简化调试 此指令可以用到生产环境
</pre>
可以取消守护进程模式以及master线程模型。</li>
<li>调用ngx_create_pidfile创建pid文件，把master进程的pid保存在里面。</li>
<li><p>根据进程模式来分别调用相应的函数
<pre>
if (ngx_process == NGX_PROCESS_SINGLE) {
    ngx_single_process_cycle(cycle);</p>

<p>} else {
    ngx_master_process_cycle(cycle);
}
</pre>
多进程的情况下，调用ngx_master_process_cycle。单进程的情况下调用ngx_single_process_cycle完成最后的启动工作。</p></li>
</ol>


<p>整个启动过程中一个关键的变量init_cycle，其数据结构ngx_cycle_t如下所示：</p>

<pre>
struct ngx_cycle_s {
    void                  ****conf_ctx;
    ngx_pool_t               *pool;

    ngx_log_t                *log;
    ngx_log_t                 new_log;

    ngx_connection_t        **files;
    ngx_connection_t         *free_connections;
    ngx_uint_t                free_connection_n;

    ngx_queue_t               reusable_connections_queue;

    ngx_array_t               listening;
    ngx_array_t               paths;
    ngx_list_t                open_files;
    ngx_list_t                shared_memory;

    ngx_uint_t                connection_n;
    ngx_uint_t                files_n;

    ngx_connection_t         *connections;
    ngx_event_t              *read_events;
    ngx_event_t              *write_events;

    ngx_cycle_t              *old_cycle;

    ngx_str_t                 conf_file;
    ngx_str_t                 conf_param;
    ngx_str_t                 conf_prefix;
    ngx_str_t                 prefix;
    ngx_str_t                 lock_file;
    ngx_str_t                 hostname;
};
</pre>


<p>它保存了一次启动过程需要的一些资源。</p>

<p>ngx_init_cycle函数的处理过程如下：</p>

<ol>
<li>调用ngx_timezone_update()、ngx_timeofday、ngx_time_update()来更新时区、时间等，做时间校准，用来创建定时器等。</li>
<li><p>创建pool,赋给一个新的cycle（ngx_cycle_t）。这个新的cycle的一些字段从旧的cycle传递过来，比如：log,conf_prefix,prefix,conf_file,conf_param。
 <pre>
 cycle->conf_prefix.len = old_cycle->conf_prefix.len;
 cycle->conf_prefix.data = ngx_pstrdup(pool, &amp;old_cycle->conf_prefix);
 if (cycle->conf_prefix.data == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }</p>

<p> cycle->prefix.len = old_cycle->prefix.len;
 cycle->prefix.data = ngx_pstrdup(pool, &amp;old_cycle->prefix);
 if (cycle->prefix.data == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }</p>

<p> cycle->conf_file.len = old_cycle->conf_file.len;
 cycle->conf_file.data = ngx_pnalloc(pool, old_cycle->conf_file.len + 1);
 if (cycle->conf_file.data == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }
 ngx_cpystrn(cycle->conf_file.data, old_cycle->conf_file.data,
             old_cycle->conf_file.len + 1);</p>

<p> cycle->conf_param.len = old_cycle->conf_param.len;
 cycle->conf_param.data = ngx_pstrdup(pool, &amp;old_cycle->conf_param);
 if (cycle->conf_param.data == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }
 </pre>
还有一些字段会首先判断old_cycle中是否存在，如果存在，则申请同样大小的空间，并初始化。这些字段如下：
 <pre>
 n = old_cycle->paths.nelts ? old_cycle->paths.nelts : 10;</p>

<p> //paths
 cycle->paths.elts = ngx_pcalloc(pool, n * sizeof(ngx_path_t *));
 if (cycle->paths.elts == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }</p>

<p> cycle->paths.nelts = 0;
 cycle->paths.size = sizeof(ngx_path_t *);
 cycle->paths.nalloc = n;
 cycle->paths.pool = pool;</p>

<p> //open_files
 if (old_cycle->open_files.part.nelts) {
     n = old_cycle->open_files.part.nelts;
     for (part = old_cycle->open_files.part.next; part; part = part->next) {
         n += part->nelts;
     }</p>

<p> } else {
     n = 20;
 }</p>

<p> //shared_memory
 if (old_cycle->shared_memory.part.nelts) {
     n = old_cycle->shared_memory.part.nelts;
     for (part = old_cycle->shared_memory.part.next; part; part = part->next)
     {
         n += part->nelts;
     }</p>

<p> } else {
     n = 1;
 }</p>

<p> //listening
 n = old_cycle->listening.nelts ? old_cycle->listening.nelts : 10;</p>

<p> cycle->listening.elts = ngx_pcalloc(pool, n * sizeof(ngx_listening_t));
 if (cycle->listening.elts == NULL) {
     ngx_destroy_pool(pool);
     return NULL;
 }</p>

<p> cycle->listening.nelts = 0;
 cycle->listening.size = sizeof(ngx_listening_t);
 cycle->listening.nalloc = n;
 cycle->listening.pool = pool;
</pre></p>

<p>  此外，new_log.log_level重新赋值的为NGX_LOG_ERR；old_cycle为传递进来的cycle；hostname为gethostname;初始化resuable_connection_queue。</p>

<p>  这里有一个关键变量的初始化：conf_ctx。初始化为ngx_max_module个void *指针。说明其实所有模块的配置结构的指针。</p></li>
<li><p>调用所有模块的create_conf，返回的配置结构指针放到conf_ctx数组中，索引为ngx_modules[i]->index。</p></li>
<li>从命令行和配置文件读取配置更新到conf_ctx中。ngx_conf_param是读取命令行中的指令，ngx_conf_parse是把读取配置文件。ngx_conf_param最后也是通过调用ngx_cong_parse来读取配置的。ngx_conf_parse函数中有一个for循环，每次都调用ngx_conf_read_token取得一个配置指令，然后调用ngx_conf_handler来处理这条指令。ngx_conf_handler每次会遍历所有模块的指令集，查找这条配置指令并分析其合法性，如果正确则创建配置结构并把指针加入到cycle.conf_ctx中。
 遍历指令集的过程首先是遍历所有的核心类模块，若是 event类的指令，则会遍历到ngx_events_module，这个模块是属于核心类的，其钩子set又会嵌套调用ngx_conf_parse去遍历所有的event类模块，同样的，若是http类指令，则会遍历到ngx_http_module，该模块的钩子set进一步遍历所有的http类模块，mail类指令会遍历到ngx_mail_module，该模块的钩子进一步遍历到所有的mail类模块。要特别注意的是：这三个遍历过程中会在适当的时机调用event类模块、http类模块和mail类模块的创建配置和初始化配置的钩子。从这里可以看出，event、http、mail三类模块的钩子是配置中的指令驱动的。</li>
<li>调用core module的init_conf。</li>
<li><p>读取核心模块ngx_core_module的配置结构，调用ngx_create_pidfile创建pid文件。
 <pre>
 ccf = (ngx_core_conf_t *) ngx_get_conf(cycle->conf_ctx, ngx_core_module);
</pre></p>

<p>  这里代码中有一句注释：
  <pre>
   we do not create the pid file in the first ngx_init_cycle() call
   because we need to write the demonized process pid
</pre>
  当不是第一次初始化cycles时才会调用ngx_create_pidfile写入pid。</p></li>
<li>调用ngx_test_lockfile,ngx_create_paths并打开error_log文件复制给cycle->new_log.file。</li>
<li>遍历cycle的open_files.part.elts，打开每一个文件。open_files填充的文件数据是读取配置文件时写入的。</li>
<li>创建共享内存。这里和对open_files类似。先预分配空间，再填充数据。</li>
<li>处理listening sockets，遍历cycle->listening数组与old_cycle->listenning进行比较，设置cycle->listening的一些状态信息，调用ngx_open_listening_sockets启动所有监听socket，循环调用socket、bind、listen完成服务端监听监听socket的启动。并调用ngx_configure_listening_sockets配置监听socket,根据ngx_listening_t中的状态信息设置socket的读写缓存和TCP_DEFER_ACCEPT。</li>
<li>调用每个module的init_module。</li>
<li>关闭或者删除一些残留在old_cycle中的资源，首先释放不用的共性内存，关闭不使用的监听socket，再关闭不适用的打开文件。最后把old_cycle放入ngx_old_cycles。最后再设定一个定时器，定期回调ngx_cleaner_event清理ngx_old_cycles。周期设置为30000ms。</li>
</ol>


<p>接下来是进程的启动，包括master和worker进程。main函数最后调用ngx_master_process_cycle来启动master进程模式(这里对单进程模式不做讲述)。</p>

<ol>
<li>设置一些信号，如下：
 <pre>
 sigaddset(&amp;set, SIGCHLD);
 sigaddset(&amp;set, SIGALRM);
 sigaddset(&amp;set, SIGIO);
 sigaddset(&amp;set, SIGINT);
 sigaddset(&amp;set, ngx_signal_value(NGX_RECONFIGURE_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_REOPEN_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_NOACCEPT_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_TERMINATE_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_SHUTDOWN_SIGNAL));
 sigaddset(&amp;set, ngx_signal_value(NGX_CHANGEBIN_SIGNAL));
</pre></li>
<li>调用ngx_setproctitle设置进程标题：&#8221;master process&#8221; + ngx_argv[0&hellip;]</li>
<li>启动worker进程,数量为ccf->worker_processes。
 <pre>
 ngx_start_worker_processes(cycle, ccf->worker_processes,
                            NGX_PROCESS_RESPAWN);
</pre></li>
<li>启动文件cache管理进程。
 <pre>
 ngx_start_cache_manager_processes(cycle, 0);
</pre>
 这里的cahche在一些模块中是需要的，如fastcgi模块等,这些模块会把文件cache路径添加到cycle->paths中，文件cache管理进程会定期调用这些模块的文件cache处理钩子处理一下文件cache。</li>
<li>master主循环，主要是循环处理信号量。在循环过程中，判断相应的条件然后进入相应的处理。这里的相关标志位基本都是在信号处理函数中赋值的。
 <pre>
 for ( ;; ) {
  // delay用来设置等待worker退出的时间，master接收了退出信号后首先发送退出信号给worker，
  // 而worker退出需要一些时间
  if (delay) {
      delay = 2;
          &hellip;
      itv.it_interval.tv_sec = 0;
      itv.it_interval.tv_usec = 0;
      itv.it_value.tv_sec = delay / 1000;
      itv.it_value.tv_usec = (delay % 1000 ) * 1000;
      // 设置定时器
      if (setitimer(ITIMER_REAL, &amp;itv, NULL) == -1) {
          ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
          “setitimer() failed”);
      }
  }
  ngx_log_debug0(NGX_LOG_DEBUG_EVENT, cycle->log, 0, “sigsuspend”);
  // 挂起信号量，等待定时器
  sigsuspend(&amp;set);
  ngx_time_update(0, 0);
  ngx_log_debug0(NGX_LOG_DEBUG_EVENT, cycle->log, 0, “wake up”);
  // 收到了SIGCHLD信号，有worker退出（ngx_reap==1）
  if (ngx_reap) {
      ngx_reap = 0;
      ngx_log_debug0(NGX_LOG_DEBUG_EVENT, cycle->log, 0, “reap children”);
      // 处理所有worker，如果有worker异常退出则重启这个worker，如果所有worker都退出
      // 返回0赋值给live
      live = ngx_reap_children(cycle);
  }
  // 如果worker都已经退出，
  // 并且收到了NGX_CMD_TERMINATE命令或者SIGTERM信号或者SIGINT信号(ngx_terminate=1)
  // 或者NGX_CMD_QUIT命令或者SIGQUIT信号(ngx_quit=1)，则master退出
  if (!live &amp;&amp; (ngx_terminate || ngx_quit)) {
      ngx_master_process_exit(cycle);
  }
  // 收到了NGX_CMD_TERMINATE命令或者SIGTERM信号或者SIGINT信号，
  // 通知所有worker退出，并且等待worker退出
  if (ngx_terminate) {
      // 设置延时
      if (delay == 0) {
          delay = 50;
      }
      if (delay > 1000) {
          // 延时已到，给所有worker发送SIGKILL信号，强制杀死worker
          ngx_signal_worker_processes(cycle, SIGKILL);
      } else {
          // 给所有worker发送SIGTERM信号，通知worker退出
          ngx_signal_worker_processes(cycle,
          ngx_signal_value(NGX_TERMINATE_SIGNAL));
      }
      continue;
  }
  // 收到了NGX_CMD_QUIT命令或者SIGQUIT信号
  if (ngx_quit) {
      // 给所有worker发送SIGQUIT信号
      ngx_signal_worker_processes(cycle,
      ngx_signal_value(NGX_SHUTDOWN_SIGNAL));
      // 关闭所有监听的socket
      ls = cycle->listening.elts;
      for (n = 0; n &lt; cycle->listening.nelts; n++) {
          if (ngx_close_socket(ls[n].fd) == -1) {
              ngx_log_error(NGX_LOG_EMERG, cycle->log, ngx_socket_errno,
                  ngx_close_socket_n ” %V failed”,&amp;ls[n].addr_text);
          }
      }
      cycle->listening.nelts = 0;
  continue;
  }
  // 收到了SIGHUP信号
  if (ngx_reconfigure) {
      ngx_reconfigure = 0;
      // 代码已经被替换，重启worker，不需要重新初始化配置
      if (ngx_new_binary) {
          ngx_start_worker_processes(cycle, ccf->worker_processes,
              NGX_PROCESS_RESPAWN);
          ngx_start_cache_manager_processes(cycle, 0);
          ngx_noaccepting = 0;
          continue;
      }
      ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, “reconfiguring”);
      // 重新初始化配置
      cycle = ngx_init_cycle(cycle);
      if (cycle == NULL) {
          cycle = (ngx_cycle_t ) ngx_cycle;
          continue;
      }
      // 重启worker
      ngx_cycle = cycle;
      ccf = (ngx_core_conf_t *) ngx_get_conf(cycle->conf_ctx,
      ngx_core_module);
      ngx_start_worker_processes(cycle, ccf->worker_processes,
          NGX_PROCESS_JUST_RESPAWN);
      ngx_start_cache_manager_processes(cycle, 1);
      live = 1;
      ngx_signal_worker_processes(cycle,
          ngx_signal_value(NGX_SHUTDOWN_SIGNAL));
  }
  // 当ngx_noaccepting=1的时候会把ngx_restart设为1，重启worker
  if (ngx_restart) {
      ngx_restart = 0;
      ngx_start_worker_processes(cycle, ccf->worker_processes,
          NGX_PROCESS_RESPAWN);
      ngx_start_cache_manager_processes(cycle, 0);
      live = 1;
  }
  // 收到SIGUSR1信号，重新打开log文件
  if (ngx_reopen) {
      ngx_reopen = 0;
      ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, “reopening logs”);
      ngx_reopen_files(cycle, ccf->user);
      ngx_signal_worker_processes(cycle,
      ngx_signal_value(NGX_REOPEN_SIGNAL));
  }
  // 收到SIGUSR2信号，热代码替换
  if (ngx_change_binary) {
      ngx_change_binary = 0;
      ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, “changing binary”);
      // 调用execve执行新的代码
      ngx_new_binary = ngx_exec_new_binary(cycle, ngx_argv);
  }
  // 收到SIGWINCH信号，不再接收请求，worker退出，master不退出
  if (ngx_noaccept) {
      ngx_noaccept = 0;
      ngx_noaccepting = 1;
      ngx_signal_worker_processes(cycle,
      ngx_signal_value(NGX_SHUTDOWN_SIGNAL));
  }
}
</pre>
信号处理函数是在main函数中进行的初始化：ngx_init_signals(cycle->log)。其中的signal handler代码如下所示：</li>
</ol>


<pre>
void
ngx_signal_handler(int signo)
{
    char            *action;
    ngx_int_t        ignore;
    ngx_err_t        err;
    ngx_signal_t    *sig;

    ignore = 0;

    err = ngx_errno;

    for (sig = signals; sig->signo != 0; sig++) {
        if (sig->signo == signo) {
            break;
        }
    }

    ngx_time_sigsafe_update();

    action = "";

    switch (ngx_process) {

    case NGX_PROCESS_MASTER:
    case NGX_PROCESS_SINGLE:
        switch (signo) {

        case ngx_signal_value(NGX_SHUTDOWN_SIGNAL):
            ngx_quit = 1;
            action = ", shutting down";
            break;

        case ngx_signal_value(NGX_TERMINATE_SIGNAL):
        case SIGINT:
            ngx_terminate = 1;
            action = ", exiting";
            break;

        case ngx_signal_value(NGX_NOACCEPT_SIGNAL):
            if (ngx_daemonized) {
                ngx_noaccept = 1;
                action = ", stop accepting connections";
            }
            break;

        case ngx_signal_value(NGX_RECONFIGURE_SIGNAL):
            ngx_reconfigure = 1;
            action = ", reconfiguring";
            break;

        case ngx_signal_value(NGX_REOPEN_SIGNAL):
            ngx_reopen = 1;
            action = ", reopening logs";
            break;

        case ngx_signal_value(NGX_CHANGEBIN_SIGNAL):
            if (getppid() > 1 || ngx_new_binary > 0) {

                /*
                 * Ignore the signal in the new binary if its parent is
                 * not the init process, i.e. the old binary's process
                 * is still running.  Or ignore the signal in the old binary's
                 * process if the new binary's process is already running.
                 */

                action = ", ignoring";
                ignore = 1;
                break;
            }

            ngx_change_binary = 1;
            action = ", changing binary";
            break;

        case SIGALRM:
            ngx_sigalrm = 1;
            break;

        case SIGIO:
            ngx_sigio = 1;
            break;

        case SIGCHLD:
            ngx_reap = 1;
            break;
        }

        break;

    case NGX_PROCESS_WORKER:
    case NGX_PROCESS_HELPER:
        switch (signo) {

        case ngx_signal_value(NGX_NOACCEPT_SIGNAL):
            if (!ngx_daemonized) {
                break;
            }
            ngx_debug_quit = 1;
        case ngx_signal_value(NGX_SHUTDOWN_SIGNAL):
            ngx_quit = 1;
            action = ", shutting down";
            break;

        case ngx_signal_value(NGX_TERMINATE_SIGNAL):
        case SIGINT:
            ngx_terminate = 1;
            action = ", exiting";
            break;

        case ngx_signal_value(NGX_REOPEN_SIGNAL):
            ngx_reopen = 1;
            action = ", reopening logs";
            break;

        case ngx_signal_value(NGX_RECONFIGURE_SIGNAL):
        case ngx_signal_value(NGX_CHANGEBIN_SIGNAL):
        case SIGIO:
            action = ", ignoring";
            break;
        }

        break;
    }

    ngx_log_error(NGX_LOG_NOTICE, ngx_cycle->log, 0,
                  "signal %d (%s) received%s", signo, sig->signame, action);

    if (ignore) {
        ngx_log_error(NGX_LOG_CRIT, ngx_cycle->log, 0,
                      "the changing binary signal is ignored: "
                      "you should shutdown or terminate "
                      "before either old or new binary's process");
    }

    if (signo == SIGCHLD) {
        ngx_process_get_status();
    }

    ngx_set_errno(err);
}
</pre>


<p>创建worker子进程的函数是ngx_start_worker_processes。</p>

<pre>
static void
ngx_start_worker_processes(ngx_cycle_t *cycle, ngx_int_t n, ngx_int_t type)
{
    ngx_int_t      i;
    ngx_channel_t  ch;

    ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "start worker processes");

    ch.command = NGX_CMD_OPEN_CHANNEL; //传递给其他worker子进程的命令：打开通信管道

    //创建n个worker进程
    for (i = 0; i < n; i++) {

        //创建worker子进程并初始化相关资源和属性
        ngx_spawn_process(cycle, ngx_worker_process_cycle,
                          (void *) (intptr_t) i, "worker process", type);

        /*master父进程向所有已经创建的worker子进程（不包括本子进程）广播消息
        包括当前worker子进程的进程id、在进程表中的位置和管道句柄，这些worker子进程收到消息后，会更新这些消息到自己进程空间的进程表，以此实现两个worke子进程之间的通信。
        */
        ch.pid = ngx_processes[ngx_process_slot].pid;
        ch.slot = ngx_process_slot;
        ch.fd = ngx_processes[ngx_process_slot].channel[0];

        ngx_pass_open_channel(cycle, &ch);
    }
}
</pre>


<p>这里ngx_pass_open_channel，即遍历所有worker进程，跳过自己和异常的worker，把消息发送给各个worker进程。worker进程的管道可读事件捕捉函数是ngx_channel_handler(ngx_event_t *ev)，在这个函数中，会读取message，然后解析，并根据不同给的命令做不同的处理。</p>

<p>这里有一个关键的函数是ngx_pid_t ngx_spawn_process(ngx_cycle_t <em>cycle, ngx_spawn_proc_pt proc, void </em>data,char *name, ngx_int_t respawn)。proc是子进程的执行函数，data是其参数，name是进程名。</p>

<p>这个函数的任务：</p>

<ol>
<li>有一个ngx_processes全局数组，包含了所有的子进程，这里会fork出子进程并放入相应的位置，并设置这个进程的相关属性。</li>
<li>创建socketpair，并设置相关属性</li>
<li>子啊子进程中执行传递进来的函数。</li>
</ol>


<pre>
u_long     on;
ngx_pid_t  pid;
ngx_int_t  s; //fork的子进程在ngx_processes中的位置

//如果传递进来的respawn>0，说明是要替换进程ngx_processes[respawn]，可安全重用该进程表项。
if (respawn >= 0) {
   s = respawn;
} else {
   遍历进程表，找到空闲的slot
   for (s = 0; s < ngx_last_process; s++) {
        if (ngx_processes[s].pid == -1) {
                break;
            }
        }

        //达到最大进程限制报错
        if (s == NGX_MAX_PROCESSES) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, 0,
                          "no more than %d processes can be spawned",
                          NGX_MAX_PROCESSES);
            return NGX_INVALID_PID;
        }
    }
</pre>


<p></p>

<p>接下来创建一对socketpair句柄，然后初始化相关属性。</p>

<pre>
    if (respawn != NGX_PROCESS_DETACHED) { //NGX_PROCESS_DETACHED是热代码替换

        /* Solaris 9 still has no AF_LOCAL */

        //建立socketpair
        if (socketpair(AF_UNIX, SOCK_STREAM, 0, ngx_processes[s].channel) == -1)
        {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "socketpair() failed while spawning \"%s\"", name);
            return NGX_INVALID_PID;
        }

        。。。

        //设置非阻塞模式
        if (ngx_nonblocking(ngx_processes[s].channel[0]) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          ngx_nonblocking_n " failed while spawning \"%s\"",
                          name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        if (ngx_nonblocking(ngx_processes[s].channel[1]) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          ngx_nonblocking_n " failed while spawning \"%s\"",
                          name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        //打开异步模式
        on = 1;
        if (ioctl(ngx_processes[s].channel[0], FIOASYNC, &on) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "ioctl(FIOASYNC) failed while spawning \"%s\"", name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        //设置异步io所有者
        if (fcntl(ngx_processes[s].channel[0], F_SETOWN, ngx_pid) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "fcntl(F_SETOWN) failed while spawning \"%s\"", name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        //当exec后关闭句柄
        if (fcntl(ngx_processes[s].channel[0], F_SETFD, FD_CLOEXEC) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "fcntl(FD_CLOEXEC) failed while spawning \"%s\"",
                           name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        if (fcntl(ngx_processes[s].channel[1], F_SETFD, FD_CLOEXEC) == -1) {
            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                          "fcntl(FD_CLOEXEC) failed while spawning \"%s\"",
                           name);
            ngx_close_channel(ngx_processes[s].channel, cycle->log);
            return NGX_INVALID_PID;
        }

        //设置当前子进程的句柄
        ngx_channel = ngx_processes[s].channel[1];

    } else {
        ngx_processes[s].channel[0] = -1;
        ngx_processes[s].channel[1] = -1;
    }
</pre>


<p>接下来就是fork子进程，并设置进程相关参数。</p>

<pre>
    //设置进程在进程表中的slot
    ngx_process_slot = s;

    pid = fork();

    switch (pid) {

    case -1:
        ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno,
                      "fork() failed while spawning \"%s\"", name);
        ngx_close_channel(ngx_processes[s].channel, cycle->log);
        return NGX_INVALID_PID;

    case 0:
        //子进程，执行传递进来的子进程函数
        ngx_pid = ngx_getpid();
        proc(cycle, data);
        break;

    default:
        break;
    }

    ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "start %s %P", name, pid);

    ngx_processes[s].pid = pid;
    ngx_processes[s].exited = 0;

    if (respawn >= 0) { //使用原来的子进程即可
        return pid;
    }

    //初始化进程结构
    ngx_processes[s].proc = proc;
    ngx_processes[s].data = data;
    ngx_processes[s].name = name;
    ngx_processes[s].exiting = 0;

    switch (respawn) {

    case NGX_PROCESS_NORESPAWN:
        ngx_processes[s].respawn = 0;
        ngx_processes[s].just_spawn = 0;
        ngx_processes[s].detached = 0;
        break;

    case NGX_PROCESS_JUST_SPAWN:
        ngx_processes[s].respawn = 0;
        ngx_processes[s].just_spawn = 1;
        ngx_processes[s].detached = 0;
        break;

    case NGX_PROCESS_RESPAWN:
        ngx_processes[s].respawn = 1;
        ngx_processes[s].just_spawn = 0;
        ngx_processes[s].detached = 0;
        break;

    case NGX_PROCESS_JUST_RESPAWN:
        ngx_processes[s].respawn = 1;
        ngx_processes[s].just_spawn = 1;
        ngx_processes[s].detached = 0;
        break;

    case NGX_PROCESS_DETACHED:
        ngx_processes[s].respawn = 0;
        ngx_processes[s].just_spawn = 0;
        ngx_processes[s].detached = 1;
        break;
    }

    if (s == ngx_last_process) {
        ngx_last_process++;
    }   
</pre>


<p>最后看一下，worker进程执行的函数static void
ngx_worker_process_cycle(ngx_cycle_t <em>cycle, void </em>data)。</p>

<ol>
<li><p>调用ngx_worker_process_init初始化；</p>

<ul>
<li>设置ngx_process=NGX_PROCESS_WORKER</li>
<li>全局性的设置，包括执行环境、优先级、限制、setgid、setuid、信号初始化</li>
<li>调用所有模块的init_process钩子</li>
<li>关闭不使用的管道句柄，关闭当前的worker子进程的channel[0]句柄和继承来的其他进程的channel[1]句柄。使用其他进程的channel[0]句柄发送消息，使用本进程的channel[1]句柄监听事件。</li>
</ul>
</li>
<li><p>进行线程相关的操作。（如果有线程模式）</p></li>
<li>主循环处理各种状态，类似master进程的主循环。</li>
</ol>


<pre>   
for ( ;; ) {

        if (ngx_exiting) { //退出状态，关闭所有连接

            c = cycle->connections;

            for (i = 0; i < cycle->connection_n; i++) {

                /* THREAD: lock */

                if (c[i].fd != -1 && c[i].idle) {
                    c[i].close = 1;
                    c[i].read->handler(c[i].read);
                }
            }

            if (ngx_event_timer_rbtree.root == ngx_event_timer_rbtree.sentinel)
            {
                ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "exiting");

                ngx_worker_process_exit(cycle);
            }
        }

        ngx_log_debug0(NGX_LOG_DEBUG_EVENT, cycle->log, 0, "worker cycle");

        ngx_process_events_and_timers(cycle); //处理事件和计时

        if (ngx_terminate) { //收到NGX_CMD_TERMINATE命令，清理进城后退出，并调用所有模块的exit_process钩子。
            ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "exiting");

            ngx_worker_process_exit(cycle);
        }

        if (ngx_quit) {
            ngx_quit = 0;
            ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0,
                          "gracefully shutting down");
            ngx_setproctitle("worker process is shutting down");

            if (!ngx_exiting) {
                //关闭监听socket，并设置退出状态
                ngx_close_listening_sockets(cycle);
                ngx_exiting = 1;
            }
        }

        if (ngx_reopen) { //重新打开log
            ngx_reopen = 0;
            ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "reopening logs");
            ngx_reopen_files(cycle, -1);
        }
    }
</pre>


<p>总结一下，nginx的启动过程可以划分为两个部分，</p>

<ol>
<li>读取配置文件并设置全局的配置结构信息以及每个模块的配置结构信息，调用模块的 create_conf钩子和init_conf钩子。</li>
<li>创建进程和进程间通信机制，master进程负责管理各个worker子进程，通过 socketpair向子进程发送消息，各个worker子进程服务利用事件机制处理请求，通过socketpair与其他子进程通信（发送消息或者接收消息），进程启动的各个适当时机会调用模块的init_module钩子、init_process钩子、exit_process钩子和 exit_master钩子，init_master钩子没有被调用过。nginx的worker子进程继承了父进程的全局变量之后，子进程和父进程就会独立处理这些全局变量，有些全局量需要在父子进程之间同步就要通过通信方式了，比如 ngx_processes（进程表）的同步。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx负载均衡]]></title>
    <link href="http://www.rowkey.me/blog/2014/08/27/nginx-loabbalance/"/>
    <updated>2014-08-27T14:32:50+08:00</updated>
    <id>http://www.rowkey.me/blog/2014/08/27/nginx-loabbalance</id>
    <content type="html"><![CDATA[<h2>一、特点</h2>

<h3>1.1 应用情况</h3>

<p>Nginx做为一个强大的Web服务器软件，具有高性能、高并发性和低内存占用的特点。此外，其也能够提供强大的反向代理功能。俄罗斯大约有超过20%的虚拟主机采用Nginx作为反向代理服务器,在国内也有腾讯、新浪、网易等多家网站在使用Nginx作为反向代理服务器。据Netcraft统计，世界上最繁忙的网站中有11.48%使用Nginx作为其服务器或者代理服务器。基于反向代理的功能，Nginx作为负载均衡主要有以下几点理由：</p>

<ol>
<li><p>高并发连接</p></li>
<li><p>内存消耗少</p></li>
<li><p>配置文件非常简单</p></li>
<li><p>成本低廉</p></li>
<li><p>支持Rewrite重写规则</p></li>
<li><p>内置的健康检查功能</p></li>
<li><p>节省带宽</p></li>
<li><p>稳定性高</p></li>
</ol>


<!--more-->


<h3>1.2 架构</h3>

<p><img src="http://www.rowkey.me/images/blog_images/ngx_arch.jpg" alt="" /></p>

<p>nginx在启动后，会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程。工作进程以非特权用户运行。</p>

<p>master进程主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程。</p>

<p>worker进程则是处理基本的网络事件。多个worker进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。</p>

<p>开发模型：epoll和kqueue。</p>

<p>支持的事件机制：kqueue、epoll、rt signals、/dev/poll 、event ports、select以及poll。</p>

<p>支持的kqueue特性包括EV_CLEAR、EV_DISABLE、NOTE_LOWAT、EV_EOF，可用数据的数量，错误代码.</p>

<p>支持sendfile、sendfile64和sendfilev;文件AIO；DIRECTIO;支持Accept-filters和TCP_DEFER_ACCEP.</p>

<h3>1.3 性能</h3>

<p>Nginx的高并发，官方测试支持5万并发连接。实际生产环境能到2-3万并发连接数。10000个非活跃的HTTP keep-alive 连接仅占用约2.5MB内存。三万并发连接下，10个Nginx进程，消耗内存150M。淘宝tengine团队说测试结果是“24G内存机器上，处理并发请求可达200万”。</p>

<h2>二、负载均衡</h2>

<h3>2.1 协议支持</h3>

<p>Nginx工作在网络的7层，可以针对http应用本身来做分流策略。支持七层HTTP、HTTPS协议的负载均衡。对四层协议的支持需要第三方插件-yaoweibin的ngx_tcp_proxy_module实现了tcp upstream。</p>

<p><a href="https://github.com/yaoweibin/nginx_tcp_proxy_module">https://github.com/yaoweibin/nginx_tcp_proxy_module</a></p>

<p>此外，nginx本身也逐渐在完善对其他协议的支持：</p>

<ul>
<li><p>Nginx 1.3.13 开发版支持WebSocket代理。</p></li>
<li><p>Nginx 1.3.15开发版支持SPDY。</p></li>
</ul>


<h3>2.2 均衡策略</h3>

<p>nginx的负载均衡策略可以划分为两大类：内置策略和扩展策略。内置策略包含加权轮询和ip hash，在默认情况下这两种策略会编译进nginx内核，只需在nginx配置中指明参数即可。扩展策略有很多，如fair、通用hash、consistent hash等，默认不编译进nginx内核。</p>

<ol>
<li><p>加权轮询（weighted round robin）</p>

<p> 轮询的原理很简单，首先我们介绍一下轮询的基本流程。如下是处理一次请求的流程图：</p>

<p> <img src="http://www.rowkey.me/images/blog_images/ngx_wr_process.jpg" alt="" /></p>

<p> 图中有两点需要注意，第一，如果可以把加权轮询算法分为先深搜索和先广搜索，那么nginx采用的是先深搜索算法，即将首先将请求都分给高权重的机器，直到该机器的权值降到了比其他机器低，才开始将请求分给下一个高权重的机器；第二，当所有后端机器都down掉时，nginx会立即将所有机器的标志位清成初始状态，以避免造成所有的机器都处在timeout的状态，从而导致整个前端被夯住。</p></li>
<li><p>ip hash</p>

<p> ip hash是nginx内置的另一个负载均衡的策略，流程和轮询很类似，只是其中的算法和具体的策略有些变化，如下图所示：</p>

<p> <img src="http://www.rowkey.me/images/blog_images/ngx_iphash_process.jpg" alt="" /></p>

<p> ip hash算法的核心实现如下：</p>

<p> <pre>
 for(i = 0;i &lt; 3;i++){
     hash = (hash * 113 + iphp->addr[i]) % 6271;
 }</p>

<p> p = hash % iphp->rrp.peers->number;
 </pre></p>

<p> 从代码中可以看出，hash值既与ip有关又与后端机器的数量有关。经过测试，上述算法可以连续产生1045个互异的value，这是该算法的硬限制。对此nginx使用了保护机制，当经过20次hash仍然找不到可用的机器时，算法退化成轮询。因此，从本质上说，ip hash算法是一种变相的轮询算法，如果两个ip的初始hash值恰好相同，那么来自这两个ip的请求将永远落在同一台服务器上，这为均衡性埋下了很深的隐患。</p></li>
<li><p>fair</p>

<p> fair策略是扩展策略，默认不被编译进nginx内核。其原理是根据后端服务器的响应时间判断负载情况，从中选出负载最轻的机器进行分流。这种策略具有很强的自适应性，但是实际的网络环境往往不是那么简单，因此要慎用。</p></li>
<li><p>通用hash、一致性hash</p>

<p> 这两种也是扩展策略，在具体的实现上有些差别，通用hash比较简单，可以以nginx内置的变量为key进行hash，一致性hash采用了nginx内置的一致性hash环，可以支持memcache。</p></li>
</ol>


<h3>2.2 配置示例</h3>

<ol>
<li><p>HTTP</p>

<pre><code> http {

     upstream  www.s135.com  {

       server   192.168.1.2:80;

       server   192.168.1.3:80;

     }



     server{

       listen  80;

       server_name  www.s135.com;



       location / {

                proxy_pass        http://www.s135.com;

                proxy_set_header   Host             $host;

                proxy_set_header   X-Real-IP        $remote_addr;

                proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;

       }



       location /nginx_status {

                stub_status on;

                access_log off;

                allow 192.168.1.1;#设置为可访问该状态信息的ip

                deny all;

       }

     }

 }
</code></pre></li>
<li><p>TCP - ngx_tcp_proxy_module</p>

<pre><code> tcp {

     upstream cluster {

         # simple round-robin

         server 192.168.0.1:80;

         server 192.168.0.2:80;



         check interval=3000 rise=2 fall=5 timeout=1000;



         #check interval=3000 rise=2 fall=5 timeout=1000 type=ssl_hello;



         #check interval=3000 rise=2 fall=5 timeout=1000 type=http;

         #check_http_send "GET / HTTP/1.0\r\n\r\n";

         #check_http_expect_alive http_2xx http_3xx;

     }



     server {

         listen 8888;

         proxy_pass cluster;

     }

 }
</code></pre></li>
</ol>


<h2>三、动态负载均衡</h2>

<h3>3.1 自身监控</h3>

<p>内置了对后端服务器的健康检查功能。如果Nginx proxy后端的某台服务器宕机了，会把返回错误的请求重新提交到另一个节点，不会影响前端访问。它没有独立的健康检查模块，而是使用业务请求作为健康检查，这省去了独立健康检查线程，这是好处。坏处是，当业务复杂时，可能出现误判，例如后端响应超时，这可能是后端宕机，也可能是某个业务请求自身出现问题，跟后端无关。</p>

<h3>3.2 可扩展性</h3>

<p>Nginx属于典型的微内核设计，其内核非常简洁和优雅，同时具有非常高的可扩展性。如下图所示：</p>

<p><img src="http://www.rowkey.me/images/blog_images/ngx_micro.jpg" alt="" /></p>

<p>Nginx是纯C语言的实现，其可扩展性在于其模块化的设计。目前，Nginx已经有很多的第三方模块，大大扩展了自身的功能。nginx_lua_module可以将Lua语言嵌入到Nginx配置中，从而利用Lua极大增强了Nginx本身的编程能力，甚至可以不用配合其它脚本语言（如PHP或Python等），只靠Nginx本身就可以实现复杂业务的处理。</p>

<h3>3.3 配置修改</h3>

<p>nginx的配置架构如下图所示：</p>

<p><img src="http://www.rowkey.me/images/blog_images/ngx_config.jpg" alt="" /></p>

<p>Nginx支持热部署，几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。能够在不间断服务的情况下，对软件版本进行进行升级。Nginx的配置文件非常简单，风格跟程序一样通俗易懂，能够支持perl语法。使用nginx –s reload可以在运行时加载配置文件，便于运行时扩容/减容。重新加载配置时，master进程发送命令给当前正在运行的worker进程worker进程接到命令后会在处理完当前任务后退出。同时，master进程会启动新的worker进程来接管工作。</p>

<h2>四、优势和劣势</h2>

<h3>4.1 优势</h3>

<ol>
<li><p>可以很好地进行http 的头处理</p></li>
<li><p>对http协议以及https的良好支持</p></li>
<li><p>有足够的第三方插件供使用</p></li>
<li><p>支持热部署，更改后端是平滑的</p></li>
</ol>


<h3>4.2 劣势</h3>

<ol>
<li><p>缺少对session的支持</p></li>
<li><p>对四层tcp的支持不够好</p></li>
<li><p>post请求写文件系统，造成500 error</p></li>
<li><p>缺乏主动的后端服务器健康监测</p></li>
<li><p>默认的监控界面统计信息不全</p></li>
</ol>


<h2>五、Tengine</h2>

<h3>5.1 特性</h3>

<ol>
<li><p>继承Nginx-1.2.9的所有特性，100%兼容Nginx的配置；</p></li>
<li><p>动态模块加载（DSO）支持。加入一个模块不再需要重新编译整个Tengine；</p></li>
<li><p>输入过滤器机制支持。通过使用这种机制Web应用防火墙的编写更为方便；</p></li>
<li><p>动态脚本语言Lua支持。扩展功能非常高效简单；</p></li>
<li><p>支持管道（pipe）和syslog（本地和远端）形式的日志以及日志抽样；</p></li>
<li><p>组合多个CSS、JavaScript文件的访问请求变成一个请求；</p></li>
<li><p>更加强大的负载均衡能力，包括一致性hash模块、会话保持模块，还可以对后端的服务器进行主动健康检查，根据服务器状态自动上线下线；</p></li>
<li><p>自动根据CPU数目设置进程个数和绑定CPU亲缘性；</p></li>
<li><p>监控系统的负载和资源占用从而对系统进行保护；</p></li>
<li><p>显示对运维人员更友好的出错信息，便于定位出错机器；</p></li>
<li><p>更强大的防攻击（访问速度限制）模块；</p></li>
<li><p>更方便的命令行参数，如列出编译的模块列表、支持的指令等；</p></li>
<li><p>可以根据访问文件类型设置过期时间；</p></li>
</ol>


<h3>5.2 负载均衡</h3>

<p>负载均衡方面，Tengine主要有以下几个特点，基本上弥补了 nginx在负载均衡方面的欠缺：</p>

<ol>
<li><p>支持一致性Hash模块</p></li>
<li><p>会话保持模块</p></li>
<li><p>对后端服务器的主动健康检查。</p></li>
<li><p>增加了请求体不缓存到磁盘的机制</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[async源码分析]]></title>
    <link href="http://www.rowkey.me/blog/2014/08/22/node-async-analysis/"/>
    <updated>2014-08-22T16:08:28+08:00</updated>
    <id>http://www.rowkey.me/blog/2014/08/22/node-async-analysis</id>
    <content type="html"><![CDATA[<p>最近在使用到node js的async库的时候，对其waterfall的实现感觉很奇妙，于是看了一下源码：</p>

<pre>
    async.waterfall = function (tasks, callback) {
        callback = callback || function () {};
        if (!_isArray(tasks)) {
          var err = new Error('First argument to waterfall must be an array of functions');
          return callback(err);
        }
        if (!tasks.length) {
            return callback();
        }
        var wrapIterator = function (iterator) {
            return function (err) {
                if (err) {
                    callback.apply(null, arguments);
                    callback = function () {};
                }
                else {
                    var args = Array.prototype.slice.call(arguments, 1);
                    var next = iterator.next();
                    if (next) {
                        args.push(wrapIterator(next));
                    }
                    else {
                        args.push(callback);
                    }
                    async.setImmediate(function () {
                        iterator.apply(null, args);
                    });
                }
            };
        };
        wrapIterator(async.iterator(tasks))();
    };
 </pre>


<p></p>

<!-- more -->


<p></p>

<p>开始先对参数进行了检查，判断tasks是否是一个function数组。然后使用了一个内部函数wrapIterator封装了实现。wrapIterator的参数带出了async.iterator函数：</p>

<pre> 
    async.iterator = function (tasks) {
        var makeCallback = function (index) {
            var fn = function () {
                if (tasks.length) {
                    tasks[index].apply(null, arguments);
                }
                return fn.next(); //这个地方有必要么？？？
            };
            fn.next = function () {
                return (index < tasks.length - 1) ? makeCallback(index + 1): null;
            };
            return fn;
        };
        return makeCallback(0);
    };
</pre>


<p> <br/>
这个函数，其主要实现是其内部函数makeCallback。其功能就是迭代tasks，封装其中的每一个function,让其执行后返回下一个function,以此实现迭代。</p>

<p>接下来，再回到wrapIterator，此function是对iterator的封装。执行后返回的是一个匿名function。其明确的参数只有一个err。当err不为空的时候，直接执行callback function。否则从index为1开始取出参数列表，并把iterator的下一个function包装之后push到args中（如果没有下一个function了则push回调函数）。接下来，则执行当前的iterator，执行的参数是下一个iterator function（作为这一步的回调函数）以及参数（如果当前的iterator被调用时传递了其他参数）。这样在当前iterator中回调下一个iterator，依次迭代执行，直至执行完所有function和callback。</p>
]]></content>
  </entry>
  
</feed>
